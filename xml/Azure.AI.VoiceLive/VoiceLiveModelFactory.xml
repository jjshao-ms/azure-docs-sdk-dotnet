<Type Name="VoiceLiveModelFactory" FullName="Azure.AI.VoiceLive.VoiceLiveModelFactory">
  <TypeSignature Language="C#" Value="public static class VoiceLiveModelFactory" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi abstract sealed beforefieldinit VoiceLiveModelFactory extends System.Object" />
  <TypeSignature Language="DocId" Value="T:Azure.AI.VoiceLive.VoiceLiveModelFactory" />
  <TypeSignature Language="VB.NET" Value="Public Class VoiceLiveModelFactory" />
  <TypeSignature Language="F#" Value="type VoiceLiveModelFactory = class" />
  <AssemblyInfo>
    <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
    <AssemblyVersion>1.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary> A factory class for creating instances of the models for mocking. </summary>
    <remarks>To be added.</remarks>
  </Docs>
  <Members>
    <Member MemberName="AnimationOptions">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AnimationOptions AnimationOptions (string modelName = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.AnimationOutputType&gt; outputs = default, int? emotionDetectionIntervalMs = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AnimationOptions AnimationOptions(string modelName, class System.Collections.Generic.IEnumerable`1&lt;valuetype Azure.AI.VoiceLive.AnimationOutputType&gt; outputs, valuetype System.Nullable`1&lt;int32&gt; emotionDetectionIntervalMs) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AnimationOptions(System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.AnimationOutputType},System.Nullable{System.Int32})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AnimationOptions (Optional modelName As String = Nothing, Optional outputs As IEnumerable(Of AnimationOutputType) = Nothing, Optional emotionDetectionIntervalMs As Nullable(Of Integer) = Nothing) As AnimationOptions" />
      <MemberSignature Language="F#" Value="static member AnimationOptions : string * seq&lt;Azure.AI.VoiceLive.AnimationOutputType&gt; * Nullable&lt;int&gt; -&gt; Azure.AI.VoiceLive.AnimationOptions" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AnimationOptions (modelName, outputs, emotionDetectionIntervalMs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AnimationOptions</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="modelName" Type="System.String" />
        <Parameter Name="outputs" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.AnimationOutputType&gt;" />
        <Parameter Name="emotionDetectionIntervalMs" Type="System.Nullable&lt;System.Int32&gt;" />
      </Parameters>
      <Docs>
        <param name="modelName"> The name of the animation model to use. </param>
        <param name="outputs"> Set of output data types requested from the animation system. </param>
        <param name="emotionDetectionIntervalMs"> Interval for emotion detection in milliseconds. If not set, emotion detection is disabled. </param>
        <summary> Configuration for animation outputs including blendshapes, visemes, and emotion metadata. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AnimationOptions" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AssistantMessageItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AssistantMessageItem AssistantMessageItem (string id = default, Azure.AI.VoiceLive.ItemParamStatus? status = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.OutputTextContentPart&gt; content = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AssistantMessageItem AssistantMessageItem(string id, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.ItemParamStatus&gt; status, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.OutputTextContentPart&gt; content) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AssistantMessageItem(System.String,System.Nullable{Azure.AI.VoiceLive.ItemParamStatus},System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.OutputTextContentPart})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AssistantMessageItem (Optional id As String = Nothing, Optional status As Nullable(Of ItemParamStatus) = Nothing, Optional content As IEnumerable(Of OutputTextContentPart) = Nothing) As AssistantMessageItem" />
      <MemberSignature Language="F#" Value="static member AssistantMessageItem : string * Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt; * seq&lt;Azure.AI.VoiceLive.OutputTextContentPart&gt; -&gt; Azure.AI.VoiceLive.AssistantMessageItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AssistantMessageItem (id, status, content)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AssistantMessageItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="status" Type="System.Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt;" />
        <Parameter Name="content" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.OutputTextContentPart&gt;" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="status" />
        <param name="content" />
        <summary> The AssistantMessageItem. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AssistantMessageItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioEchoCancellation">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AudioEchoCancellation AudioEchoCancellation (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AudioEchoCancellation AudioEchoCancellation(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AudioEchoCancellation(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AudioEchoCancellation (Optional type As String = Nothing) As AudioEchoCancellation" />
      <MemberSignature Language="F#" Value="static member AudioEchoCancellation : string -&gt; Azure.AI.VoiceLive.AudioEchoCancellation" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AudioEchoCancellation type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AudioEchoCancellation</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type"> The type of echo cancellation model to use. </param>
        <summary> Echo cancellation configuration for server-side audio processing. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AudioEchoCancellation" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioInputTranscriptionSettings">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AudioInputTranscriptionSettings AudioInputTranscriptionSettings (Azure.AI.VoiceLive.AudioInputTranscriptionSettingsModel model = default, string language = default, System.Collections.Generic.IDictionary&lt;string,string&gt; customSpeech = default, System.Collections.Generic.IEnumerable&lt;string&gt; phraseList = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AudioInputTranscriptionSettings AudioInputTranscriptionSettings(valuetype Azure.AI.VoiceLive.AudioInputTranscriptionSettingsModel model, string language, class System.Collections.Generic.IDictionary`2&lt;string, string&gt; customSpeech, class System.Collections.Generic.IEnumerable`1&lt;string&gt; phraseList) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AudioInputTranscriptionSettings(Azure.AI.VoiceLive.AudioInputTranscriptionSettingsModel,System.String,System.Collections.Generic.IDictionary{System.String,System.String},System.Collections.Generic.IEnumerable{System.String})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AudioInputTranscriptionSettings (Optional model As AudioInputTranscriptionSettingsModel = Nothing, Optional language As String = Nothing, Optional customSpeech As IDictionary(Of String, String) = Nothing, Optional phraseList As IEnumerable(Of String) = Nothing) As AudioInputTranscriptionSettings" />
      <MemberSignature Language="F#" Value="static member AudioInputTranscriptionSettings : Azure.AI.VoiceLive.AudioInputTranscriptionSettingsModel * string * System.Collections.Generic.IDictionary&lt;string, string&gt; * seq&lt;string&gt; -&gt; Azure.AI.VoiceLive.AudioInputTranscriptionSettings" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AudioInputTranscriptionSettings (model, language, customSpeech, phraseList)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AudioInputTranscriptionSettings</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="model" Type="Azure.AI.VoiceLive.AudioInputTranscriptionSettingsModel" />
        <Parameter Name="language" Type="System.String" />
        <Parameter Name="customSpeech" Type="System.Collections.Generic.IDictionary&lt;System.String,System.String&gt;" />
        <Parameter Name="phraseList" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
      </Parameters>
      <Docs>
        <param name="model">
            The transcription model to use. Supported values:
            'whisper-1', 'gpt-4o-transcribe', 'gpt-4o-mini-transcribe',
            'azure-fast-transcription', 'azure-speech'.
            </param>
        <param name="language"> Optional BCP-47 language code (e.g., 'en-US'). </param>
        <param name="customSpeech"> Optional configuration for custom speech models. </param>
        <param name="phraseList"> Optional list of phrase hints to bias recognition. </param>
        <summary> Configuration for input audio transcription. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AudioInputTranscriptionSettings" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioNoiseReduction">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AudioNoiseReduction AudioNoiseReduction (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AudioNoiseReduction AudioNoiseReduction(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AudioNoiseReduction(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AudioNoiseReduction (Optional type As String = Nothing) As AudioNoiseReduction" />
      <MemberSignature Language="F#" Value="static member AudioNoiseReduction : string -&gt; Azure.AI.VoiceLive.AudioNoiseReduction" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AudioNoiseReduction type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AudioNoiseReduction</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type"> The type of noise reduction model. </param>
        <summary> Configuration for input audio noise reduction. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AudioNoiseReduction" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AvatarConfiguration">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AvatarConfiguration AvatarConfiguration (System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.IceServer&gt; iceServers = default, string character = default, string style = default, bool customized = false, Azure.AI.VoiceLive.VideoParams video = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AvatarConfiguration AvatarConfiguration(class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.IceServer&gt; iceServers, string character, string style, bool customized, class Azure.AI.VoiceLive.VideoParams video) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AvatarConfiguration(System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.IceServer},System.String,System.String,System.Boolean,Azure.AI.VoiceLive.VideoParams)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AvatarConfiguration (Optional iceServers As IEnumerable(Of IceServer) = Nothing, Optional character As String = Nothing, Optional style As String = Nothing, Optional customized As Boolean = false, Optional video As VideoParams = Nothing) As AvatarConfiguration" />
      <MemberSignature Language="F#" Value="static member AvatarConfiguration : seq&lt;Azure.AI.VoiceLive.IceServer&gt; * string * string * bool * Azure.AI.VoiceLive.VideoParams -&gt; Azure.AI.VoiceLive.AvatarConfiguration" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AvatarConfiguration (iceServers, character, style, customized, video)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AvatarConfiguration</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="iceServers" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.IceServer&gt;" />
        <Parameter Name="character" Type="System.String" />
        <Parameter Name="style" Type="System.String" />
        <Parameter Name="customized" Type="System.Boolean" />
        <Parameter Name="video" Type="Azure.AI.VoiceLive.VideoParams" />
      </Parameters>
      <Docs>
        <param name="iceServers"> Optional list of ICE servers to use for WebRTC connection establishment. </param>
        <param name="character"> The character name or ID used for the avatar. </param>
        <param name="style"> Optional avatar style, such as emotional tone or speaking style. </param>
        <param name="customized"> Indicates whether the avatar is customized or not. </param>
        <param name="video"> Optional video configuration including resolution, bitrate, and codec. </param>
        <summary> Configuration for avatar streaming and behavior during the session. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AvatarConfiguration" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureCustomVoice">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureCustomVoice AzureCustomVoice (string name = default, string endpointId = default, float? temperature = default, string customLexiconUri = default, System.Collections.Generic.IEnumerable&lt;string&gt; preferLocales = default, string locale = default, string style = default, string pitch = default, string rate = default, string volume = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureCustomVoice AzureCustomVoice(string name, string endpointId, valuetype System.Nullable`1&lt;float32&gt; temperature, string customLexiconUri, class System.Collections.Generic.IEnumerable`1&lt;string&gt; preferLocales, string locale, string style, string pitch, string rate, string volume) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureCustomVoice(System.String,System.String,System.Nullable{System.Single},System.String,System.Collections.Generic.IEnumerable{System.String},System.String,System.String,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureCustomVoice (Optional name As String = Nothing, Optional endpointId As String = Nothing, Optional temperature As Nullable(Of Single) = Nothing, Optional customLexiconUri As String = Nothing, Optional preferLocales As IEnumerable(Of String) = Nothing, Optional locale As String = Nothing, Optional style As String = Nothing, Optional pitch As String = Nothing, Optional rate As String = Nothing, Optional volume As String = Nothing) As AzureCustomVoice" />
      <MemberSignature Language="F#" Value="static member AzureCustomVoice : string * string * Nullable&lt;single&gt; * string * seq&lt;string&gt; * string * string * string * string * string -&gt; Azure.AI.VoiceLive.AzureCustomVoice" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureCustomVoice (name, endpointId, temperature, customLexiconUri, preferLocales, locale, style, pitch, rate, volume)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureCustomVoice</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="endpointId" Type="System.String" />
        <Parameter Name="temperature" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="customLexiconUri" Type="System.String" />
        <Parameter Name="preferLocales" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
        <Parameter Name="locale" Type="System.String" />
        <Parameter Name="style" Type="System.String" />
        <Parameter Name="pitch" Type="System.String" />
        <Parameter Name="rate" Type="System.String" />
        <Parameter Name="volume" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="name"> Voice name cannot be empty. </param>
        <param name="endpointId"> Endpoint ID cannot be empty. </param>
        <param name="temperature"> Temperature must be between 0.0 and 1.0. </param>
        <param name="customLexiconUri" />
        <param name="preferLocales" />
        <param name="locale" />
        <param name="style" />
        <param name="pitch" />
        <param name="rate" />
        <param name="volume" />
        <summary> Azure custom voice configuration (preferred). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureCustomVoice" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureMultilingualSemanticVad">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureMultilingualSemanticVad AzureMultilingualSemanticVad (float? threshold = default, int? prefixPaddingMs = default, int? silenceDurationMs = default, Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection = default, float? negThreshold = default, int? speechDurationMs = default, int? windowSize = default, int? distinctCiPhones = default, bool? requireVowel = default, bool? removeFillerWords = default, System.Collections.Generic.IEnumerable&lt;string&gt; languages = default, bool? autoTruncate = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureMultilingualSemanticVad AzureMultilingualSemanticVad(valuetype System.Nullable`1&lt;float32&gt; threshold, valuetype System.Nullable`1&lt;int32&gt; prefixPaddingMs, valuetype System.Nullable`1&lt;int32&gt; silenceDurationMs, class Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection, valuetype System.Nullable`1&lt;float32&gt; negThreshold, valuetype System.Nullable`1&lt;int32&gt; speechDurationMs, valuetype System.Nullable`1&lt;int32&gt; windowSize, valuetype System.Nullable`1&lt;int32&gt; distinctCiPhones, valuetype System.Nullable`1&lt;bool&gt; requireVowel, valuetype System.Nullable`1&lt;bool&gt; removeFillerWords, class System.Collections.Generic.IEnumerable`1&lt;string&gt; languages, valuetype System.Nullable`1&lt;bool&gt; autoTruncate) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureMultilingualSemanticVad(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Boolean})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureMultilingualSemanticVad (Optional threshold As Nullable(Of Single) = Nothing, Optional prefixPaddingMs As Nullable(Of Integer) = Nothing, Optional silenceDurationMs As Nullable(Of Integer) = Nothing, Optional endOfUtteranceDetection As EouDetection = Nothing, Optional negThreshold As Nullable(Of Single) = Nothing, Optional speechDurationMs As Nullable(Of Integer) = Nothing, Optional windowSize As Nullable(Of Integer) = Nothing, Optional distinctCiPhones As Nullable(Of Integer) = Nothing, Optional requireVowel As Nullable(Of Boolean) = Nothing, Optional removeFillerWords As Nullable(Of Boolean) = Nothing, Optional languages As IEnumerable(Of String) = Nothing, Optional autoTruncate As Nullable(Of Boolean) = Nothing) As AzureMultilingualSemanticVad" />
      <MemberSignature Language="F#" Value="static member AzureMultilingualSemanticVad : Nullable&lt;single&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Azure.AI.VoiceLive.EouDetection * Nullable&lt;single&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Nullable&lt;bool&gt; * Nullable&lt;bool&gt; * seq&lt;string&gt; * Nullable&lt;bool&gt; -&gt; Azure.AI.VoiceLive.AzureMultilingualSemanticVad" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureMultilingualSemanticVad (threshold, prefixPaddingMs, silenceDurationMs, endOfUtteranceDetection, negThreshold, speechDurationMs, windowSize, distinctCiPhones, requireVowel, removeFillerWords, languages, autoTruncate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureMultilingualSemanticVad</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="threshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="prefixPaddingMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="silenceDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="endOfUtteranceDetection" Type="Azure.AI.VoiceLive.EouDetection" />
        <Parameter Name="negThreshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="speechDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="windowSize" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="distinctCiPhones" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="requireVowel" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="removeFillerWords" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="languages" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
        <Parameter Name="autoTruncate" Type="System.Nullable&lt;System.Boolean&gt;" />
      </Parameters>
      <Docs>
        <param name="threshold" />
        <param name="prefixPaddingMs" />
        <param name="silenceDurationMs" />
        <param name="endOfUtteranceDetection" />
        <param name="negThreshold" />
        <param name="speechDurationMs" />
        <param name="windowSize" />
        <param name="distinctCiPhones" />
        <param name="requireVowel" />
        <param name="removeFillerWords" />
        <param name="languages" />
        <param name="autoTruncate" />
        <summary> Server Speech Detection (Azure semantic VAD). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureMultilingualSemanticVad" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzurePersonalVoice">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzurePersonalVoice AzurePersonalVoice (string name = default, float? temperature = default, Azure.AI.VoiceLive.AzurePersonalVoiceModel model = Azure.AI.VoiceLive.AzurePersonalVoiceModel.DragonLatestNeural);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzurePersonalVoice AzurePersonalVoice(string name, valuetype System.Nullable`1&lt;float32&gt; temperature, valuetype Azure.AI.VoiceLive.AzurePersonalVoiceModel model) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzurePersonalVoice(System.String,System.Nullable{System.Single},Azure.AI.VoiceLive.AzurePersonalVoiceModel)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzurePersonalVoice (Optional name As String = Nothing, Optional temperature As Nullable(Of Single) = Nothing, Optional model As AzurePersonalVoiceModel = Azure.AI.VoiceLive.AzurePersonalVoiceModel.DragonLatestNeural) As AzurePersonalVoice" />
      <MemberSignature Language="F#" Value="static member AzurePersonalVoice : string * Nullable&lt;single&gt; * Azure.AI.VoiceLive.AzurePersonalVoiceModel -&gt; Azure.AI.VoiceLive.AzurePersonalVoice" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzurePersonalVoice (name, temperature, model)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzurePersonalVoice</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="temperature" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="model" Type="Azure.AI.VoiceLive.AzurePersonalVoiceModel" />
      </Parameters>
      <Docs>
        <param name="name"> Voice name cannot be empty. </param>
        <param name="temperature"> Temperature must be between 0.0 and 1.0. </param>
        <param name="model"> Underlying neural model to use for personal voice. </param>
        <summary> Azure personal voice configuration. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzurePersonalVoice" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzurePlatformVoice">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzurePlatformVoice AzurePlatformVoice (string name = default, float? temperature = default, string customLexiconUrl = default, System.Collections.Generic.IEnumerable&lt;string&gt; preferLocales = default, string locale = default, string style = default, string pitch = default, string rate = default, string volume = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzurePlatformVoice AzurePlatformVoice(string name, valuetype System.Nullable`1&lt;float32&gt; temperature, string customLexiconUrl, class System.Collections.Generic.IEnumerable`1&lt;string&gt; preferLocales, string locale, string style, string pitch, string rate, string volume) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzurePlatformVoice(System.String,System.Nullable{System.Single},System.String,System.Collections.Generic.IEnumerable{System.String},System.String,System.String,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzurePlatformVoice (Optional name As String = Nothing, Optional temperature As Nullable(Of Single) = Nothing, Optional customLexiconUrl As String = Nothing, Optional preferLocales As IEnumerable(Of String) = Nothing, Optional locale As String = Nothing, Optional style As String = Nothing, Optional pitch As String = Nothing, Optional rate As String = Nothing, Optional volume As String = Nothing) As AzurePlatformVoice" />
      <MemberSignature Language="F#" Value="static member AzurePlatformVoice : string * Nullable&lt;single&gt; * string * seq&lt;string&gt; * string * string * string * string * string -&gt; Azure.AI.VoiceLive.AzurePlatformVoice" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzurePlatformVoice (name, temperature, customLexiconUrl, preferLocales, locale, style, pitch, rate, volume)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzurePlatformVoice</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="temperature" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="customLexiconUrl" Type="System.String" />
        <Parameter Name="preferLocales" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
        <Parameter Name="locale" Type="System.String" />
        <Parameter Name="style" Type="System.String" />
        <Parameter Name="pitch" Type="System.String" />
        <Parameter Name="rate" Type="System.String" />
        <Parameter Name="volume" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="name"> Voice name cannot be empty. </param>
        <param name="temperature"> Temperature must be between 0.0 and 1.0. </param>
        <param name="customLexiconUrl" />
        <param name="preferLocales" />
        <param name="locale" />
        <param name="style" />
        <param name="pitch" />
        <param name="rate" />
        <param name="volume" />
        <summary> Azure platform voice configuration (variant of standard). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzurePlatformVoice" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureSemanticDetection">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureSemanticDetection AzureSemanticDetection (float? threshold = default, float? timeout = default, float? secondaryThreshold = default, float? secondaryTimeout = default, bool? disableRules = default, float? srBoost = default, bool? extraImendCheck = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureSemanticDetection AzureSemanticDetection(valuetype System.Nullable`1&lt;float32&gt; threshold, valuetype System.Nullable`1&lt;float32&gt; timeout, valuetype System.Nullable`1&lt;float32&gt; secondaryThreshold, valuetype System.Nullable`1&lt;float32&gt; secondaryTimeout, valuetype System.Nullable`1&lt;bool&gt; disableRules, valuetype System.Nullable`1&lt;float32&gt; srBoost, valuetype System.Nullable`1&lt;bool&gt; extraImendCheck) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticDetection(System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Boolean},System.Nullable{System.Single},System.Nullable{System.Boolean})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureSemanticDetection (Optional threshold As Nullable(Of Single) = Nothing, Optional timeout As Nullable(Of Single) = Nothing, Optional secondaryThreshold As Nullable(Of Single) = Nothing, Optional secondaryTimeout As Nullable(Of Single) = Nothing, Optional disableRules As Nullable(Of Boolean) = Nothing, Optional srBoost As Nullable(Of Single) = Nothing, Optional extraImendCheck As Nullable(Of Boolean) = Nothing) As AzureSemanticDetection" />
      <MemberSignature Language="F#" Value="static member AzureSemanticDetection : Nullable&lt;single&gt; * Nullable&lt;single&gt; * Nullable&lt;single&gt; * Nullable&lt;single&gt; * Nullable&lt;bool&gt; * Nullable&lt;single&gt; * Nullable&lt;bool&gt; -&gt; Azure.AI.VoiceLive.AzureSemanticDetection" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticDetection (threshold, timeout, secondaryThreshold, secondaryTimeout, disableRules, srBoost, extraImendCheck)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureSemanticDetection</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="threshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="timeout" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="secondaryThreshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="secondaryTimeout" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="disableRules" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="srBoost" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="extraImendCheck" Type="System.Nullable&lt;System.Boolean&gt;" />
      </Parameters>
      <Docs>
        <param name="threshold" />
        <param name="timeout" />
        <param name="secondaryThreshold" />
        <param name="secondaryTimeout" />
        <param name="disableRules" />
        <param name="srBoost" />
        <param name="extraImendCheck" />
        <summary> Azure semantic end-of-utterance detection (default). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureSemanticDetection" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureSemanticDetectionEn">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureSemanticDetectionEn AzureSemanticDetectionEn (float? threshold = default, float? timeout = default, float? secondaryThreshold = default, float? secondaryTimeout = default, bool? disableRules = default, float? srBoost = default, bool? extraImendCheck = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureSemanticDetectionEn AzureSemanticDetectionEn(valuetype System.Nullable`1&lt;float32&gt; threshold, valuetype System.Nullable`1&lt;float32&gt; timeout, valuetype System.Nullable`1&lt;float32&gt; secondaryThreshold, valuetype System.Nullable`1&lt;float32&gt; secondaryTimeout, valuetype System.Nullable`1&lt;bool&gt; disableRules, valuetype System.Nullable`1&lt;float32&gt; srBoost, valuetype System.Nullable`1&lt;bool&gt; extraImendCheck) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticDetectionEn(System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Boolean},System.Nullable{System.Single},System.Nullable{System.Boolean})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureSemanticDetectionEn (Optional threshold As Nullable(Of Single) = Nothing, Optional timeout As Nullable(Of Single) = Nothing, Optional secondaryThreshold As Nullable(Of Single) = Nothing, Optional secondaryTimeout As Nullable(Of Single) = Nothing, Optional disableRules As Nullable(Of Boolean) = Nothing, Optional srBoost As Nullable(Of Single) = Nothing, Optional extraImendCheck As Nullable(Of Boolean) = Nothing) As AzureSemanticDetectionEn" />
      <MemberSignature Language="F#" Value="static member AzureSemanticDetectionEn : Nullable&lt;single&gt; * Nullable&lt;single&gt; * Nullable&lt;single&gt; * Nullable&lt;single&gt; * Nullable&lt;bool&gt; * Nullable&lt;single&gt; * Nullable&lt;bool&gt; -&gt; Azure.AI.VoiceLive.AzureSemanticDetectionEn" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticDetectionEn (threshold, timeout, secondaryThreshold, secondaryTimeout, disableRules, srBoost, extraImendCheck)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureSemanticDetectionEn</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="threshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="timeout" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="secondaryThreshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="secondaryTimeout" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="disableRules" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="srBoost" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="extraImendCheck" Type="System.Nullable&lt;System.Boolean&gt;" />
      </Parameters>
      <Docs>
        <param name="threshold" />
        <param name="timeout" />
        <param name="secondaryThreshold" />
        <param name="secondaryTimeout" />
        <param name="disableRules" />
        <param name="srBoost" />
        <param name="extraImendCheck" />
        <summary> Azure semantic end-of-utterance detection (English-optimized). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureSemanticDetectionEn" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureSemanticDetectionMultilingual">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureSemanticDetectionMultilingual AzureSemanticDetectionMultilingual (float? threshold = default, float? timeout = default, float? secondaryThreshold = default, float? secondaryTimeout = default, bool? disableRules = default, float? srBoost = default, bool? extraImendCheck = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureSemanticDetectionMultilingual AzureSemanticDetectionMultilingual(valuetype System.Nullable`1&lt;float32&gt; threshold, valuetype System.Nullable`1&lt;float32&gt; timeout, valuetype System.Nullable`1&lt;float32&gt; secondaryThreshold, valuetype System.Nullable`1&lt;float32&gt; secondaryTimeout, valuetype System.Nullable`1&lt;bool&gt; disableRules, valuetype System.Nullable`1&lt;float32&gt; srBoost, valuetype System.Nullable`1&lt;bool&gt; extraImendCheck) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticDetectionMultilingual(System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Boolean},System.Nullable{System.Single},System.Nullable{System.Boolean})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureSemanticDetectionMultilingual (Optional threshold As Nullable(Of Single) = Nothing, Optional timeout As Nullable(Of Single) = Nothing, Optional secondaryThreshold As Nullable(Of Single) = Nothing, Optional secondaryTimeout As Nullable(Of Single) = Nothing, Optional disableRules As Nullable(Of Boolean) = Nothing, Optional srBoost As Nullable(Of Single) = Nothing, Optional extraImendCheck As Nullable(Of Boolean) = Nothing) As AzureSemanticDetectionMultilingual" />
      <MemberSignature Language="F#" Value="static member AzureSemanticDetectionMultilingual : Nullable&lt;single&gt; * Nullable&lt;single&gt; * Nullable&lt;single&gt; * Nullable&lt;single&gt; * Nullable&lt;bool&gt; * Nullable&lt;single&gt; * Nullable&lt;bool&gt; -&gt; Azure.AI.VoiceLive.AzureSemanticDetectionMultilingual" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticDetectionMultilingual (threshold, timeout, secondaryThreshold, secondaryTimeout, disableRules, srBoost, extraImendCheck)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureSemanticDetectionMultilingual</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="threshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="timeout" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="secondaryThreshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="secondaryTimeout" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="disableRules" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="srBoost" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="extraImendCheck" Type="System.Nullable&lt;System.Boolean&gt;" />
      </Parameters>
      <Docs>
        <param name="threshold" />
        <param name="timeout" />
        <param name="secondaryThreshold" />
        <param name="secondaryTimeout" />
        <param name="disableRules" />
        <param name="srBoost" />
        <param name="extraImendCheck" />
        <summary> Azure semantic end-of-utterance detection (multilingual). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureSemanticDetectionMultilingual" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureSemanticVad">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureSemanticVad AzureSemanticVad (float? threshold = default, int? prefixPaddingMs = default, int? silenceDurationMs = default, Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection = default, float? negThreshold = default, int? speechDurationMs = default, int? windowSize = default, int? distinctCiPhones = default, bool? requireVowel = default, bool? removeFillerWords = default, System.Collections.Generic.IEnumerable&lt;string&gt; languages = default, bool? autoTruncate = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureSemanticVad AzureSemanticVad(valuetype System.Nullable`1&lt;float32&gt; threshold, valuetype System.Nullable`1&lt;int32&gt; prefixPaddingMs, valuetype System.Nullable`1&lt;int32&gt; silenceDurationMs, class Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection, valuetype System.Nullable`1&lt;float32&gt; negThreshold, valuetype System.Nullable`1&lt;int32&gt; speechDurationMs, valuetype System.Nullable`1&lt;int32&gt; windowSize, valuetype System.Nullable`1&lt;int32&gt; distinctCiPhones, valuetype System.Nullable`1&lt;bool&gt; requireVowel, valuetype System.Nullable`1&lt;bool&gt; removeFillerWords, class System.Collections.Generic.IEnumerable`1&lt;string&gt; languages, valuetype System.Nullable`1&lt;bool&gt; autoTruncate) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVad(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Boolean})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureSemanticVad (Optional threshold As Nullable(Of Single) = Nothing, Optional prefixPaddingMs As Nullable(Of Integer) = Nothing, Optional silenceDurationMs As Nullable(Of Integer) = Nothing, Optional endOfUtteranceDetection As EouDetection = Nothing, Optional negThreshold As Nullable(Of Single) = Nothing, Optional speechDurationMs As Nullable(Of Integer) = Nothing, Optional windowSize As Nullable(Of Integer) = Nothing, Optional distinctCiPhones As Nullable(Of Integer) = Nothing, Optional requireVowel As Nullable(Of Boolean) = Nothing, Optional removeFillerWords As Nullable(Of Boolean) = Nothing, Optional languages As IEnumerable(Of String) = Nothing, Optional autoTruncate As Nullable(Of Boolean) = Nothing) As AzureSemanticVad" />
      <MemberSignature Language="F#" Value="static member AzureSemanticVad : Nullable&lt;single&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Azure.AI.VoiceLive.EouDetection * Nullable&lt;single&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Nullable&lt;bool&gt; * Nullable&lt;bool&gt; * seq&lt;string&gt; * Nullable&lt;bool&gt; -&gt; Azure.AI.VoiceLive.AzureSemanticVad" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVad (threshold, prefixPaddingMs, silenceDurationMs, endOfUtteranceDetection, negThreshold, speechDurationMs, windowSize, distinctCiPhones, requireVowel, removeFillerWords, languages, autoTruncate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureSemanticVad</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="threshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="prefixPaddingMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="silenceDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="endOfUtteranceDetection" Type="Azure.AI.VoiceLive.EouDetection" />
        <Parameter Name="negThreshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="speechDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="windowSize" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="distinctCiPhones" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="requireVowel" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="removeFillerWords" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="languages" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
        <Parameter Name="autoTruncate" Type="System.Nullable&lt;System.Boolean&gt;" />
      </Parameters>
      <Docs>
        <param name="threshold" />
        <param name="prefixPaddingMs" />
        <param name="silenceDurationMs" />
        <param name="endOfUtteranceDetection" />
        <param name="negThreshold" />
        <param name="speechDurationMs" />
        <param name="windowSize" />
        <param name="distinctCiPhones" />
        <param name="requireVowel" />
        <param name="removeFillerWords" />
        <param name="languages" />
        <param name="autoTruncate" />
        <summary> Server Speech Detection (Azure semantic VAD, default variant). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureSemanticVad" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureSemanticVadEn">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureSemanticVadEn AzureSemanticVadEn (float? threshold = default, int? prefixPaddingMs = default, int? silenceDurationMs = default, Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection = default, float? negThreshold = default, int? speechDurationMs = default, int? windowSize = default, int? distinctCiPhones = default, bool? requireVowel = default, bool? removeFillerWords = default, System.Collections.Generic.IEnumerable&lt;string&gt; languages = default, bool? autoTruncate = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureSemanticVadEn AzureSemanticVadEn(valuetype System.Nullable`1&lt;float32&gt; threshold, valuetype System.Nullable`1&lt;int32&gt; prefixPaddingMs, valuetype System.Nullable`1&lt;int32&gt; silenceDurationMs, class Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection, valuetype System.Nullable`1&lt;float32&gt; negThreshold, valuetype System.Nullable`1&lt;int32&gt; speechDurationMs, valuetype System.Nullable`1&lt;int32&gt; windowSize, valuetype System.Nullable`1&lt;int32&gt; distinctCiPhones, valuetype System.Nullable`1&lt;bool&gt; requireVowel, valuetype System.Nullable`1&lt;bool&gt; removeFillerWords, class System.Collections.Generic.IEnumerable`1&lt;string&gt; languages, valuetype System.Nullable`1&lt;bool&gt; autoTruncate) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadEn(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Boolean})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureSemanticVadEn (Optional threshold As Nullable(Of Single) = Nothing, Optional prefixPaddingMs As Nullable(Of Integer) = Nothing, Optional silenceDurationMs As Nullable(Of Integer) = Nothing, Optional endOfUtteranceDetection As EouDetection = Nothing, Optional negThreshold As Nullable(Of Single) = Nothing, Optional speechDurationMs As Nullable(Of Integer) = Nothing, Optional windowSize As Nullable(Of Integer) = Nothing, Optional distinctCiPhones As Nullable(Of Integer) = Nothing, Optional requireVowel As Nullable(Of Boolean) = Nothing, Optional removeFillerWords As Nullable(Of Boolean) = Nothing, Optional languages As IEnumerable(Of String) = Nothing, Optional autoTruncate As Nullable(Of Boolean) = Nothing) As AzureSemanticVadEn" />
      <MemberSignature Language="F#" Value="static member AzureSemanticVadEn : Nullable&lt;single&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Azure.AI.VoiceLive.EouDetection * Nullable&lt;single&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Nullable&lt;bool&gt; * Nullable&lt;bool&gt; * seq&lt;string&gt; * Nullable&lt;bool&gt; -&gt; Azure.AI.VoiceLive.AzureSemanticVadEn" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadEn (threshold, prefixPaddingMs, silenceDurationMs, endOfUtteranceDetection, negThreshold, speechDurationMs, windowSize, distinctCiPhones, requireVowel, removeFillerWords, languages, autoTruncate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureSemanticVadEn</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="threshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="prefixPaddingMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="silenceDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="endOfUtteranceDetection" Type="Azure.AI.VoiceLive.EouDetection" />
        <Parameter Name="negThreshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="speechDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="windowSize" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="distinctCiPhones" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="requireVowel" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="removeFillerWords" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="languages" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
        <Parameter Name="autoTruncate" Type="System.Nullable&lt;System.Boolean&gt;" />
      </Parameters>
      <Docs>
        <param name="threshold" />
        <param name="prefixPaddingMs" />
        <param name="silenceDurationMs" />
        <param name="endOfUtteranceDetection" />
        <param name="negThreshold" />
        <param name="speechDurationMs" />
        <param name="windowSize" />
        <param name="distinctCiPhones" />
        <param name="requireVowel" />
        <param name="removeFillerWords" />
        <param name="languages" />
        <param name="autoTruncate" />
        <summary> Server Speech Detection (Azure semantic VAD, English-only). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureSemanticVadEn" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureSemanticVadServer">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureSemanticVadServer AzureSemanticVadServer (float? threshold = default, int? prefixPaddingMs = default, int? silenceDurationMs = default, Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection = default, float? negThreshold = default, int? speechDurationMs = default, int? windowSize = default, int? distinctCiPhones = default, bool? requireVowel = default, bool? removeFillerWords = default, System.Collections.Generic.IEnumerable&lt;string&gt; languages = default, bool? autoTruncate = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureSemanticVadServer AzureSemanticVadServer(valuetype System.Nullable`1&lt;float32&gt; threshold, valuetype System.Nullable`1&lt;int32&gt; prefixPaddingMs, valuetype System.Nullable`1&lt;int32&gt; silenceDurationMs, class Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection, valuetype System.Nullable`1&lt;float32&gt; negThreshold, valuetype System.Nullable`1&lt;int32&gt; speechDurationMs, valuetype System.Nullable`1&lt;int32&gt; windowSize, valuetype System.Nullable`1&lt;int32&gt; distinctCiPhones, valuetype System.Nullable`1&lt;bool&gt; requireVowel, valuetype System.Nullable`1&lt;bool&gt; removeFillerWords, class System.Collections.Generic.IEnumerable`1&lt;string&gt; languages, valuetype System.Nullable`1&lt;bool&gt; autoTruncate) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadServer(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Boolean})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureSemanticVadServer (Optional threshold As Nullable(Of Single) = Nothing, Optional prefixPaddingMs As Nullable(Of Integer) = Nothing, Optional silenceDurationMs As Nullable(Of Integer) = Nothing, Optional endOfUtteranceDetection As EouDetection = Nothing, Optional negThreshold As Nullable(Of Single) = Nothing, Optional speechDurationMs As Nullable(Of Integer) = Nothing, Optional windowSize As Nullable(Of Integer) = Nothing, Optional distinctCiPhones As Nullable(Of Integer) = Nothing, Optional requireVowel As Nullable(Of Boolean) = Nothing, Optional removeFillerWords As Nullable(Of Boolean) = Nothing, Optional languages As IEnumerable(Of String) = Nothing, Optional autoTruncate As Nullable(Of Boolean) = Nothing) As AzureSemanticVadServer" />
      <MemberSignature Language="F#" Value="static member AzureSemanticVadServer : Nullable&lt;single&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Azure.AI.VoiceLive.EouDetection * Nullable&lt;single&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Nullable&lt;bool&gt; * Nullable&lt;bool&gt; * seq&lt;string&gt; * Nullable&lt;bool&gt; -&gt; Azure.AI.VoiceLive.AzureSemanticVadServer" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadServer (threshold, prefixPaddingMs, silenceDurationMs, endOfUtteranceDetection, negThreshold, speechDurationMs, windowSize, distinctCiPhones, requireVowel, removeFillerWords, languages, autoTruncate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureSemanticVadServer</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="threshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="prefixPaddingMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="silenceDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="endOfUtteranceDetection" Type="Azure.AI.VoiceLive.EouDetection" />
        <Parameter Name="negThreshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="speechDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="windowSize" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="distinctCiPhones" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="requireVowel" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="removeFillerWords" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="languages" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
        <Parameter Name="autoTruncate" Type="System.Nullable&lt;System.Boolean&gt;" />
      </Parameters>
      <Docs>
        <param name="threshold" />
        <param name="prefixPaddingMs" />
        <param name="silenceDurationMs" />
        <param name="endOfUtteranceDetection" />
        <param name="negThreshold" />
        <param name="speechDurationMs" />
        <param name="windowSize" />
        <param name="distinctCiPhones" />
        <param name="requireVowel" />
        <param name="removeFillerWords" />
        <param name="languages" />
        <param name="autoTruncate" />
        <summary> Server Speech Detection (legacy `server_sd` alias). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureSemanticVadServer" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureStandardVoice">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureStandardVoice AzureStandardVoice (string name = default, float? temperature = default, string customLexiconUrl = default, System.Collections.Generic.IEnumerable&lt;string&gt; preferLocales = default, string locale = default, string style = default, string pitch = default, string rate = default, string volume = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureStandardVoice AzureStandardVoice(string name, valuetype System.Nullable`1&lt;float32&gt; temperature, string customLexiconUrl, class System.Collections.Generic.IEnumerable`1&lt;string&gt; preferLocales, string locale, string style, string pitch, string rate, string volume) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureStandardVoice(System.String,System.Nullable{System.Single},System.String,System.Collections.Generic.IEnumerable{System.String},System.String,System.String,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureStandardVoice (Optional name As String = Nothing, Optional temperature As Nullable(Of Single) = Nothing, Optional customLexiconUrl As String = Nothing, Optional preferLocales As IEnumerable(Of String) = Nothing, Optional locale As String = Nothing, Optional style As String = Nothing, Optional pitch As String = Nothing, Optional rate As String = Nothing, Optional volume As String = Nothing) As AzureStandardVoice" />
      <MemberSignature Language="F#" Value="static member AzureStandardVoice : string * Nullable&lt;single&gt; * string * seq&lt;string&gt; * string * string * string * string * string -&gt; Azure.AI.VoiceLive.AzureStandardVoice" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureStandardVoice (name, temperature, customLexiconUrl, preferLocales, locale, style, pitch, rate, volume)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureStandardVoice</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="temperature" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="customLexiconUrl" Type="System.String" />
        <Parameter Name="preferLocales" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
        <Parameter Name="locale" Type="System.String" />
        <Parameter Name="style" Type="System.String" />
        <Parameter Name="pitch" Type="System.String" />
        <Parameter Name="rate" Type="System.String" />
        <Parameter Name="volume" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="name"> Voice name cannot be empty. </param>
        <param name="temperature"> Temperature must be between 0.0 and 1.0. </param>
        <param name="customLexiconUrl" />
        <param name="preferLocales" />
        <param name="locale" />
        <param name="style" />
        <param name="pitch" />
        <param name="rate" />
        <param name="volume" />
        <summary> Azure standard voice configuration. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureStandardVoice" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureVoice">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureVoice AzureVoice (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureVoice AzureVoice(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureVoice(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureVoice (Optional type As String = Nothing) As AzureVoice" />
      <MemberSignature Language="F#" Value="static member AzureVoice : string -&gt; Azure.AI.VoiceLive.AzureVoice" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureVoice type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureVoice</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <summary>
            Base for Azure voice configurations.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureCustomVoice(System.String,System.String,System.Nullable{System.Single},System.String,System.Collections.Generic.IEnumerable{System.String},System.String,System.String,System.String,System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureStandardVoice(System.String,System.Nullable{System.Single},System.String,System.Collections.Generic.IEnumerable{System.String},System.String,System.String,System.String,System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzurePlatformVoice(System.String,System.Nullable{System.Single},System.String,System.Collections.Generic.IEnumerable{System.String},System.String,System.String,System.String,System.String,System.String)" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzurePersonalVoice(System.String,System.Nullable{System.Single},Azure.AI.VoiceLive.AzurePersonalVoiceModel)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureVoice" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="CachedTokenDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.CachedTokenDetails CachedTokenDetails (int textTokens = 0, int audioTokens = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.CachedTokenDetails CachedTokenDetails(int32 textTokens, int32 audioTokens) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.CachedTokenDetails(System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function CachedTokenDetails (Optional textTokens As Integer = 0, Optional audioTokens As Integer = 0) As CachedTokenDetails" />
      <MemberSignature Language="F#" Value="static member CachedTokenDetails : int * int -&gt; Azure.AI.VoiceLive.CachedTokenDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.CachedTokenDetails (textTokens, audioTokens)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.CachedTokenDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textTokens" Type="System.Int32" />
        <Parameter Name="audioTokens" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="textTokens"> Number of cached text tokens. </param>
        <param name="audioTokens"> Number of cached audio tokens. </param>
        <summary> Details of output token usage. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.CachedTokenDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ConversationRequestItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ConversationRequestItem ConversationRequestItem (string type = default, string id = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ConversationRequestItem ConversationRequestItem(string type, string id) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ConversationRequestItem(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ConversationRequestItem (Optional type As String = Nothing, Optional id As String = Nothing) As ConversationRequestItem" />
      <MemberSignature Language="F#" Value="static member ConversationRequestItem : string * string -&gt; Azure.AI.VoiceLive.ConversationRequestItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ConversationRequestItem (type, id)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ConversationRequestItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="id" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <param name="id" />
        <summary>
            Base for any response item; discriminated by `type`.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.MessageItem(System.String,System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.FunctionCallItem(System.String,System.String,System.String,System.String,System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.FunctionCallOutputItem(System.String,System.String,System.String,System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ConversationRequestItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="EmotionCandidate">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.EmotionCandidate EmotionCandidate (string emotion = default, float confidence = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.EmotionCandidate EmotionCandidate(string emotion, float32 confidence) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.EmotionCandidate(System.String,System.Single)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function EmotionCandidate (Optional emotion As String = Nothing, Optional confidence As Single = 0) As EmotionCandidate" />
      <MemberSignature Language="F#" Value="static member EmotionCandidate : string * single -&gt; Azure.AI.VoiceLive.EmotionCandidate" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.EmotionCandidate (emotion, confidence)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.EmotionCandidate</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="emotion" Type="System.String" />
        <Parameter Name="confidence" Type="System.Single" />
      </Parameters>
      <Docs>
        <param name="emotion" />
        <param name="confidence" />
        <summary> The EmotionCandidate. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.EmotionCandidate" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="EouDetection">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.EouDetection EouDetection (string model = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.EouDetection EouDetection(string model) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.EouDetection(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function EouDetection (Optional model As String = Nothing) As EouDetection" />
      <MemberSignature Language="F#" Value="static member EouDetection : string -&gt; Azure.AI.VoiceLive.EouDetection" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.EouDetection model" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.EouDetection</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="model" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="model" />
        <summary>
            Top-level union for end-of-utterance (EOU) semantic detection configuration.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticDetection(System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Boolean},System.Nullable{System.Single},System.Nullable{System.Boolean})" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticDetectionEn(System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Boolean},System.Nullable{System.Single},System.Nullable{System.Boolean})" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticDetectionMultilingual(System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Single},System.Nullable{System.Boolean},System.Nullable{System.Single},System.Nullable{System.Boolean})" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.EouDetection" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="FunctionCallItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.FunctionCallItem FunctionCallItem (string id = default, string name = default, string callId = default, string arguments = default, Azure.AI.VoiceLive.ItemParamStatus? status = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.FunctionCallItem FunctionCallItem(string id, string name, string callId, string arguments, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.ItemParamStatus&gt; status) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.FunctionCallItem(System.String,System.String,System.String,System.String,System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function FunctionCallItem (Optional id As String = Nothing, Optional name As String = Nothing, Optional callId As String = Nothing, Optional arguments As String = Nothing, Optional status As Nullable(Of ItemParamStatus) = Nothing) As FunctionCallItem" />
      <MemberSignature Language="F#" Value="static member FunctionCallItem : string * string * string * string * Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt; -&gt; Azure.AI.VoiceLive.FunctionCallItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.FunctionCallItem (id, name, callId, arguments, status)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.FunctionCallItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="callId" Type="System.String" />
        <Parameter Name="arguments" Type="System.String" />
        <Parameter Name="status" Type="System.Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt;" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="name" />
        <param name="callId" />
        <param name="arguments" />
        <param name="status" />
        <summary> The FunctionCallItem. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.FunctionCallItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="FunctionCallOutputItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.FunctionCallOutputItem FunctionCallOutputItem (string id = default, string callId = default, string output = default, Azure.AI.VoiceLive.ItemParamStatus? status = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.FunctionCallOutputItem FunctionCallOutputItem(string id, string callId, string output, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.ItemParamStatus&gt; status) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.FunctionCallOutputItem(System.String,System.String,System.String,System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function FunctionCallOutputItem (Optional id As String = Nothing, Optional callId As String = Nothing, Optional output As String = Nothing, Optional status As Nullable(Of ItemParamStatus) = Nothing) As FunctionCallOutputItem" />
      <MemberSignature Language="F#" Value="static member FunctionCallOutputItem : string * string * string * Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt; -&gt; Azure.AI.VoiceLive.FunctionCallOutputItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.FunctionCallOutputItem (id, callId, output, status)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.FunctionCallOutputItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="callId" Type="System.String" />
        <Parameter Name="output" Type="System.String" />
        <Parameter Name="status" Type="System.Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt;" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="callId" />
        <param name="output" />
        <param name="status" />
        <summary> The FunctionCallOutputItem. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.FunctionCallOutputItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="IceServer">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.IceServer IceServer (System.Collections.Generic.IEnumerable&lt;Uri&gt; uris = default, string username = default, string credential = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.IceServer IceServer(class System.Collections.Generic.IEnumerable`1&lt;class System.Uri&gt; uris, string username, string credential) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.IceServer(System.Collections.Generic.IEnumerable{System.Uri},System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function IceServer (Optional uris As IEnumerable(Of Uri) = Nothing, Optional username As String = Nothing, Optional credential As String = Nothing) As IceServer" />
      <MemberSignature Language="F#" Value="static member IceServer : seq&lt;Uri&gt; * string * string -&gt; Azure.AI.VoiceLive.IceServer" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.IceServer (uris, username, credential)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.IceServer</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="uris" Type="System.Collections.Generic.IEnumerable&lt;System.Uri&gt;" />
        <Parameter Name="username" Type="System.String" />
        <Parameter Name="credential" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="uris"> List of ICE server URLs (e.g., TURN or STUN endpoints). </param>
        <param name="username"> Optional username used for authentication with the ICE server. </param>
        <param name="credential"> Optional credential (e.g., password or token) used for authentication. </param>
        <summary> ICE server configuration for WebRTC connection negotiation. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.IceServer" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="InputAudio">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.InputAudio InputAudio (string model = default, System.Collections.Generic.IEnumerable&lt;string&gt; phraseList = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.InputAudio InputAudio(string model, class System.Collections.Generic.IEnumerable`1&lt;string&gt; phraseList) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.InputAudio(System.String,System.Collections.Generic.IEnumerable{System.String})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function InputAudio (Optional model As String = Nothing, Optional phraseList As IEnumerable(Of String) = Nothing) As InputAudio" />
      <MemberSignature Language="F#" Value="static member InputAudio : string * seq&lt;string&gt; -&gt; Azure.AI.VoiceLive.InputAudio" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.InputAudio (model, phraseList)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.InputAudio</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="model" Type="System.String" />
        <Parameter Name="phraseList" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
      </Parameters>
      <Docs>
        <param name="model"> The name of the model to use for input audio (currently only 'azure-standard' is supported). </param>
        <param name="phraseList"> Optional list of phrases to bias the speech recognition engine. </param>
        <summary> Configuration for client audio input. Used to specify the audio model and optional phrase list. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.InputAudio" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="InputAudioContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.InputAudioContentPart InputAudioContentPart (string audio = default, string transcript = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.InputAudioContentPart InputAudioContentPart(string audio, string transcript) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.InputAudioContentPart(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function InputAudioContentPart (Optional audio As String = Nothing, Optional transcript As String = Nothing) As InputAudioContentPart" />
      <MemberSignature Language="F#" Value="static member InputAudioContentPart : string * string -&gt; Azure.AI.VoiceLive.InputAudioContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.InputAudioContentPart (audio, transcript)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.InputAudioContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audio" Type="System.String" />
        <Parameter Name="transcript" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="audio" />
        <param name="transcript" />
        <summary> The InputAudioContentPart. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.InputAudioContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="InputTextContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.InputTextContentPart InputTextContentPart (string text = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.InputTextContentPart InputTextContentPart(string text) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.InputTextContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function InputTextContentPart (Optional text As String = Nothing) As InputTextContentPart" />
      <MemberSignature Language="F#" Value="static member InputTextContentPart : string -&gt; Azure.AI.VoiceLive.InputTextContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.InputTextContentPart text" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.InputTextContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="text" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="text" />
        <summary> The InputTextContentPart. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.InputTextContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="InputTokenDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.InputTokenDetails InputTokenDetails (int cachedTokens = 0, int textTokens = 0, int audioTokens = 0, Azure.AI.VoiceLive.CachedTokenDetails cachedTokensDetails = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.InputTokenDetails InputTokenDetails(int32 cachedTokens, int32 textTokens, int32 audioTokens, class Azure.AI.VoiceLive.CachedTokenDetails cachedTokensDetails) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.InputTokenDetails(System.Int32,System.Int32,System.Int32,Azure.AI.VoiceLive.CachedTokenDetails)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function InputTokenDetails (Optional cachedTokens As Integer = 0, Optional textTokens As Integer = 0, Optional audioTokens As Integer = 0, Optional cachedTokensDetails As CachedTokenDetails = Nothing) As InputTokenDetails" />
      <MemberSignature Language="F#" Value="static member InputTokenDetails : int * int * int * Azure.AI.VoiceLive.CachedTokenDetails -&gt; Azure.AI.VoiceLive.InputTokenDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.InputTokenDetails (cachedTokens, textTokens, audioTokens, cachedTokensDetails)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.InputTokenDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="cachedTokens" Type="System.Int32" />
        <Parameter Name="textTokens" Type="System.Int32" />
        <Parameter Name="audioTokens" Type="System.Int32" />
        <Parameter Name="cachedTokensDetails" Type="Azure.AI.VoiceLive.CachedTokenDetails" />
      </Parameters>
      <Docs>
        <param name="cachedTokens"> Number of cached tokens used in the input. </param>
        <param name="textTokens"> Number of text tokens used in the input. </param>
        <param name="audioTokens"> Number of audio tokens used in the input. </param>
        <param name="cachedTokensDetails"> Details of cached token usage. </param>
        <summary> Details of input token usage. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.InputTokenDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="LlmVoice">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.LlmVoice LlmVoice (string type = default, Azure.AI.VoiceLive.LlmVoiceName name = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.LlmVoice LlmVoice(string type, valuetype Azure.AI.VoiceLive.LlmVoiceName name) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.LlmVoice(System.String,Azure.AI.VoiceLive.LlmVoiceName)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function LlmVoice (Optional type As String = Nothing, Optional name As LlmVoiceName = Nothing) As LlmVoice" />
      <MemberSignature Language="F#" Value="static member LlmVoice : string * Azure.AI.VoiceLive.LlmVoiceName -&gt; Azure.AI.VoiceLive.LlmVoice" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.LlmVoice (type, name)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.LlmVoice</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="name" Type="Azure.AI.VoiceLive.LlmVoiceName" />
      </Parameters>
      <Docs>
        <param name="type" />
        <param name="name" />
        <summary> Voice configuration for LLM (Large Language Model) voices. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.LlmVoice" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="LogProbProperties">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.LogProbProperties LogProbProperties (string token = default, float logprob = 0, BinaryData bytes = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.LogProbProperties LogProbProperties(string token, float32 logprob, class System.BinaryData bytes) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.LogProbProperties(System.String,System.Single,System.BinaryData)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function LogProbProperties (Optional token As String = Nothing, Optional logprob As Single = 0, Optional bytes As BinaryData = Nothing) As LogProbProperties" />
      <MemberSignature Language="F#" Value="static member LogProbProperties : string * single * BinaryData -&gt; Azure.AI.VoiceLive.LogProbProperties" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.LogProbProperties (token, logprob, bytes)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.LogProbProperties</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="token" Type="System.String" />
        <Parameter Name="logprob" Type="System.Single" />
        <Parameter Name="bytes" Type="System.BinaryData" />
      </Parameters>
      <Docs>
        <param name="token"> The token that was used to generate the log probability. </param>
        <param name="logprob"> The log probability of the token. </param>
        <param name="bytes"> The bytes that were used to generate the log probability. </param>
        <summary> A single log probability entry for a token. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.LogProbProperties" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="MessageItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.MessageItem MessageItem (string id = default, Azure.AI.VoiceLive.ItemParamStatus? status = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.MessageItem MessageItem(string id, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.ItemParamStatus&gt; status) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.MessageItem(System.String,System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function MessageItem (Optional id As String = Nothing, Optional status As Nullable(Of ItemParamStatus) = Nothing) As MessageItem" />
      <MemberSignature Language="F#" Value="static member MessageItem : string * Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt; -&gt; Azure.AI.VoiceLive.MessageItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.MessageItem (id, status)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.MessageItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="status" Type="System.Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt;" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="status" />
        <summary> The MessageItem. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.MessageItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="NoTurnDetection">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.NoTurnDetection NoTurnDetection ();" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.NoTurnDetection NoTurnDetection() cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.NoTurnDetection" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function NoTurnDetection () As NoTurnDetection" />
      <MemberSignature Language="F#" Value="static member NoTurnDetection : unit -&gt; Azure.AI.VoiceLive.NoTurnDetection" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.NoTurnDetection " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.NoTurnDetection</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary> Disables turn detection. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.NoTurnDetection" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="OpenAIVoice">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.OpenAIVoice OpenAIVoice (string type = default, Azure.AI.VoiceLive.OAIVoice name = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.OpenAIVoice OpenAIVoice(string type, valuetype Azure.AI.VoiceLive.OAIVoice name) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.OpenAIVoice(System.String,Azure.AI.VoiceLive.OAIVoice)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function OpenAIVoice (Optional type As String = Nothing, Optional name As OAIVoice = Nothing) As OpenAIVoice" />
      <MemberSignature Language="F#" Value="static member OpenAIVoice : string * Azure.AI.VoiceLive.OAIVoice -&gt; Azure.AI.VoiceLive.OpenAIVoice" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.OpenAIVoice (type, name)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.OpenAIVoice</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="name" Type="Azure.AI.VoiceLive.OAIVoice" />
      </Parameters>
      <Docs>
        <param name="type" />
        <param name="name" />
        <summary>
            OpenAI voice configuration with explicit type field.
            
            This provides a unified interface for OpenAI voices, complementing the
            existing string-based OAIVoice for backward compatibility.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.OpenAIVoice" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="OutputTextContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.OutputTextContentPart OutputTextContentPart (string type = default, string text = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.OutputTextContentPart OutputTextContentPart(string type, string text) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.OutputTextContentPart(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function OutputTextContentPart (Optional type As String = Nothing, Optional text As String = Nothing) As OutputTextContentPart" />
      <MemberSignature Language="F#" Value="static member OutputTextContentPart : string * string -&gt; Azure.AI.VoiceLive.OutputTextContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.OutputTextContentPart (type, text)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.OutputTextContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="text" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <param name="text" />
        <summary> Output text content part. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.OutputTextContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="OutputTokenDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.OutputTokenDetails OutputTokenDetails (int textTokens = 0, int audioTokens = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.OutputTokenDetails OutputTokenDetails(int32 textTokens, int32 audioTokens) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.OutputTokenDetails(System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function OutputTokenDetails (Optional textTokens As Integer = 0, Optional audioTokens As Integer = 0) As OutputTokenDetails" />
      <MemberSignature Language="F#" Value="static member OutputTokenDetails : int * int -&gt; Azure.AI.VoiceLive.OutputTokenDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.OutputTokenDetails (textTokens, audioTokens)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.OutputTokenDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textTokens" Type="System.Int32" />
        <Parameter Name="audioTokens" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="textTokens"> Number of text tokens generated in the output. </param>
        <param name="audioTokens"> Number of audio tokens generated in the output. </param>
        <summary> Details of output token usage. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.OutputTokenDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="RequestAudioContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.RequestAudioContentPart RequestAudioContentPart (string transcript = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.RequestAudioContentPart RequestAudioContentPart(string transcript) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.RequestAudioContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function RequestAudioContentPart (Optional transcript As String = Nothing) As RequestAudioContentPart" />
      <MemberSignature Language="F#" Value="static member RequestAudioContentPart : string -&gt; Azure.AI.VoiceLive.RequestAudioContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.RequestAudioContentPart transcript" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.RequestAudioContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="transcript" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="transcript" />
        <summary> The RequestAudioContentPart. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.RequestAudioContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="RequestTextContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.RequestTextContentPart RequestTextContentPart (string text = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.RequestTextContentPart RequestTextContentPart(string text) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.RequestTextContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function RequestTextContentPart (Optional text As String = Nothing) As RequestTextContentPart" />
      <MemberSignature Language="F#" Value="static member RequestTextContentPart : string -&gt; Azure.AI.VoiceLive.RequestTextContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.RequestTextContentPart text" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.RequestTextContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="text" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="text" />
        <summary> The RequestTextContentPart. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.RequestTextContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="RespondingAgentOptions">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.RespondingAgentOptions RespondingAgentOptions (string type = default, string name = default, string description = default, string agentId = default, string threadId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.RespondingAgentOptions RespondingAgentOptions(string type, string name, string description, string agentId, string threadId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.RespondingAgentOptions(System.String,System.String,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function RespondingAgentOptions (Optional type As String = Nothing, Optional name As String = Nothing, Optional description As String = Nothing, Optional agentId As String = Nothing, Optional threadId As String = Nothing) As RespondingAgentOptions" />
      <MemberSignature Language="F#" Value="static member RespondingAgentOptions : string * string * string * string * string -&gt; Azure.AI.VoiceLive.RespondingAgentOptions" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.RespondingAgentOptions (type, name, description, agentId, threadId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.RespondingAgentOptions</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="description" Type="System.String" />
        <Parameter Name="agentId" Type="System.String" />
        <Parameter Name="threadId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <param name="name" />
        <param name="description" />
        <param name="agentId" />
        <param name="threadId" />
        <summary> The RespondingAgentOptions. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.RespondingAgentOptions" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseAudioContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseAudioContentPart ResponseAudioContentPart (string transcript = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseAudioContentPart ResponseAudioContentPart(string transcript) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseAudioContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseAudioContentPart (Optional transcript As String = Nothing) As ResponseAudioContentPart" />
      <MemberSignature Language="F#" Value="static member ResponseAudioContentPart : string -&gt; Azure.AI.VoiceLive.ResponseAudioContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseAudioContentPart transcript" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseAudioContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="transcript" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="transcript" />
        <summary> The ResponseAudioContentPart. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseAudioContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseCancelledDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseCancelledDetails ResponseCancelledDetails (Azure.AI.VoiceLive.ResponseCancelledDetailsReason reason = Azure.AI.VoiceLive.ResponseCancelledDetailsReason.TurnDetected);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseCancelledDetails ResponseCancelledDetails(valuetype Azure.AI.VoiceLive.ResponseCancelledDetailsReason reason) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseCancelledDetails(Azure.AI.VoiceLive.ResponseCancelledDetailsReason)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseCancelledDetails (Optional reason As ResponseCancelledDetailsReason = Azure.AI.VoiceLive.ResponseCancelledDetailsReason.TurnDetected) As ResponseCancelledDetails" />
      <MemberSignature Language="F#" Value="static member ResponseCancelledDetails : Azure.AI.VoiceLive.ResponseCancelledDetailsReason -&gt; Azure.AI.VoiceLive.ResponseCancelledDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseCancelledDetails reason" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseCancelledDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="reason" Type="Azure.AI.VoiceLive.ResponseCancelledDetailsReason" />
      </Parameters>
      <Docs>
        <param name="reason" />
        <summary> Details for a cancelled response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseCancelledDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseFailedDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseFailedDetails ResponseFailedDetails (BinaryData error = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseFailedDetails ResponseFailedDetails(class System.BinaryData error) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFailedDetails(System.BinaryData)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseFailedDetails (Optional error As BinaryData = Nothing) As ResponseFailedDetails" />
      <MemberSignature Language="F#" Value="static member ResponseFailedDetails : BinaryData -&gt; Azure.AI.VoiceLive.ResponseFailedDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFailedDetails error" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseFailedDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="error" Type="System.BinaryData" />
      </Parameters>
      <Docs>
        <param name="error" />
        <summary> Details for a failed response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseFailedDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseFunctionCallItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseFunctionCallItem ResponseFunctionCallItem (string id = default, string object = default, string name = default, string callId = default, string arguments = default, Azure.AI.VoiceLive.VoiceLiveResponseItemStatus status = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseFunctionCallItem ResponseFunctionCallItem(string id, string object, string name, string callId, string arguments, valuetype Azure.AI.VoiceLive.VoiceLiveResponseItemStatus status) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFunctionCallItem(System.String,System.String,System.String,System.String,System.String,Azure.AI.VoiceLive.VoiceLiveResponseItemStatus)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseFunctionCallItem (Optional id As String = Nothing, Optional object As String = Nothing, Optional name As String = Nothing, Optional callId As String = Nothing, Optional arguments As String = Nothing, Optional status As VoiceLiveResponseItemStatus = Nothing) As ResponseFunctionCallItem" />
      <MemberSignature Language="F#" Value="static member ResponseFunctionCallItem : string * string * string * string * string * Azure.AI.VoiceLive.VoiceLiveResponseItemStatus -&gt; Azure.AI.VoiceLive.ResponseFunctionCallItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFunctionCallItem (id, object, name, callId, arguments, status)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseFunctionCallItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="object" Type="System.String" />
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="callId" Type="System.String" />
        <Parameter Name="arguments" Type="System.String" />
        <Parameter Name="status" Type="Azure.AI.VoiceLive.VoiceLiveResponseItemStatus" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="object" />
        <param name="name" />
        <param name="callId" />
        <param name="arguments" />
        <param name="status" />
        <summary> The ResponseFunctionCallItem. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseFunctionCallItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseFunctionCallOutputItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseFunctionCallOutputItem ResponseFunctionCallOutputItem (string id = default, string object = default, string callId = default, string output = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseFunctionCallOutputItem ResponseFunctionCallOutputItem(string id, string object, string callId, string output) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFunctionCallOutputItem(System.String,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseFunctionCallOutputItem (Optional id As String = Nothing, Optional object As String = Nothing, Optional callId As String = Nothing, Optional output As String = Nothing) As ResponseFunctionCallOutputItem" />
      <MemberSignature Language="F#" Value="static member ResponseFunctionCallOutputItem : string * string * string * string -&gt; Azure.AI.VoiceLive.ResponseFunctionCallOutputItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFunctionCallOutputItem (id, object, callId, output)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseFunctionCallOutputItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="object" Type="System.String" />
        <Parameter Name="callId" Type="System.String" />
        <Parameter Name="output" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="object" />
        <param name="callId" />
        <param name="output" />
        <summary> The ResponseFunctionCallOutputItem. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseFunctionCallOutputItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseIncompleteDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseIncompleteDetails ResponseIncompleteDetails (Azure.AI.VoiceLive.ResponseIncompleteDetailsReason reason = Azure.AI.VoiceLive.ResponseIncompleteDetailsReason.MaxOutputTokens);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseIncompleteDetails ResponseIncompleteDetails(valuetype Azure.AI.VoiceLive.ResponseIncompleteDetailsReason reason) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseIncompleteDetails(Azure.AI.VoiceLive.ResponseIncompleteDetailsReason)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseIncompleteDetails (Optional reason As ResponseIncompleteDetailsReason = Azure.AI.VoiceLive.ResponseIncompleteDetailsReason.MaxOutputTokens) As ResponseIncompleteDetails" />
      <MemberSignature Language="F#" Value="static member ResponseIncompleteDetails : Azure.AI.VoiceLive.ResponseIncompleteDetailsReason -&gt; Azure.AI.VoiceLive.ResponseIncompleteDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseIncompleteDetails reason" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseIncompleteDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="reason" Type="Azure.AI.VoiceLive.ResponseIncompleteDetailsReason" />
      </Parameters>
      <Docs>
        <param name="reason" />
        <summary> Details for an incomplete response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseIncompleteDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseItem ResponseItem (string type = default, string id = default, string object = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseItem ResponseItem(string type, string id, string object) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseItem(System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseItem (Optional type As String = Nothing, Optional id As String = Nothing, Optional object As String = Nothing) As ResponseItem" />
      <MemberSignature Language="F#" Value="static member ResponseItem : string * string * string -&gt; Azure.AI.VoiceLive.ResponseItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseItem (type, id, object)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="object" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <param name="id" />
        <param name="object" />
        <summary>
            The ResponseItem.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseMessageItem(System.String,System.String,Azure.AI.VoiceLive.ResponseMessageRole,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.VoiceLiveContentPart},Azure.AI.VoiceLive.VoiceLiveResponseItemStatus)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFunctionCallItem(System.String,System.String,System.String,System.String,System.String,Azure.AI.VoiceLive.VoiceLiveResponseItemStatus)" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFunctionCallOutputItem(System.String,System.String,System.String,System.String)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseMessageItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseMessageItem ResponseMessageItem (string id = default, string object = default, Azure.AI.VoiceLive.ResponseMessageRole role = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.VoiceLiveContentPart&gt; content = default, Azure.AI.VoiceLive.VoiceLiveResponseItemStatus status = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseMessageItem ResponseMessageItem(string id, string object, valuetype Azure.AI.VoiceLive.ResponseMessageRole role, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.VoiceLiveContentPart&gt; content, valuetype Azure.AI.VoiceLive.VoiceLiveResponseItemStatus status) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseMessageItem(System.String,System.String,Azure.AI.VoiceLive.ResponseMessageRole,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.VoiceLiveContentPart},Azure.AI.VoiceLive.VoiceLiveResponseItemStatus)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseMessageItem (Optional id As String = Nothing, Optional object As String = Nothing, Optional role As ResponseMessageRole = Nothing, Optional content As IEnumerable(Of VoiceLiveContentPart) = Nothing, Optional status As VoiceLiveResponseItemStatus = Nothing) As ResponseMessageItem" />
      <MemberSignature Language="F#" Value="static member ResponseMessageItem : string * string * Azure.AI.VoiceLive.ResponseMessageRole * seq&lt;Azure.AI.VoiceLive.VoiceLiveContentPart&gt; * Azure.AI.VoiceLive.VoiceLiveResponseItemStatus -&gt; Azure.AI.VoiceLive.ResponseMessageItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseMessageItem (id, object, role, content, status)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseMessageItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="object" Type="System.String" />
        <Parameter Name="role" Type="Azure.AI.VoiceLive.ResponseMessageRole" />
        <Parameter Name="content" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.VoiceLiveContentPart&gt;" />
        <Parameter Name="status" Type="Azure.AI.VoiceLive.VoiceLiveResponseItemStatus" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="object" />
        <param name="role" />
        <param name="content" />
        <param name="status" />
        <summary> The ResponseMessageItem. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseMessageItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseStatusDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseStatusDetails ResponseStatusDetails (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseStatusDetails ResponseStatusDetails(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseStatusDetails(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseStatusDetails (Optional type As String = Nothing) As ResponseStatusDetails" />
      <MemberSignature Language="F#" Value="static member ResponseStatusDetails : string -&gt; Azure.AI.VoiceLive.ResponseStatusDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseStatusDetails type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseStatusDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <summary>
            Base for all non-success response details.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseCancelledDetails(Azure.AI.VoiceLive.ResponseCancelledDetailsReason)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseIncompleteDetails(Azure.AI.VoiceLive.ResponseIncompleteDetailsReason)" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFailedDetails(System.BinaryData)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseStatusDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseTextContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseTextContentPart ResponseTextContentPart (string text = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseTextContentPart ResponseTextContentPart(string text) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseTextContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseTextContentPart (Optional text As String = Nothing) As ResponseTextContentPart" />
      <MemberSignature Language="F#" Value="static member ResponseTextContentPart : string -&gt; Azure.AI.VoiceLive.ResponseTextContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseTextContentPart text" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseTextContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="text" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="text" />
        <summary> The ResponseTextContentPart. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseTextContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseTokenStatistics">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseTokenStatistics ResponseTokenStatistics (int totalTokens = 0, int inputTokens = 0, int outputTokens = 0, Azure.AI.VoiceLive.InputTokenDetails inputTokenDetails = default, Azure.AI.VoiceLive.OutputTokenDetails outputTokenDetails = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseTokenStatistics ResponseTokenStatistics(int32 totalTokens, int32 inputTokens, int32 outputTokens, class Azure.AI.VoiceLive.InputTokenDetails inputTokenDetails, class Azure.AI.VoiceLive.OutputTokenDetails outputTokenDetails) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseTokenStatistics(System.Int32,System.Int32,System.Int32,Azure.AI.VoiceLive.InputTokenDetails,Azure.AI.VoiceLive.OutputTokenDetails)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseTokenStatistics (Optional totalTokens As Integer = 0, Optional inputTokens As Integer = 0, Optional outputTokens As Integer = 0, Optional inputTokenDetails As InputTokenDetails = Nothing, Optional outputTokenDetails As OutputTokenDetails = Nothing) As ResponseTokenStatistics" />
      <MemberSignature Language="F#" Value="static member ResponseTokenStatistics : int * int * int * Azure.AI.VoiceLive.InputTokenDetails * Azure.AI.VoiceLive.OutputTokenDetails -&gt; Azure.AI.VoiceLive.ResponseTokenStatistics" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseTokenStatistics (totalTokens, inputTokens, outputTokens, inputTokenDetails, outputTokenDetails)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseTokenStatistics</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="totalTokens" Type="System.Int32" />
        <Parameter Name="inputTokens" Type="System.Int32" />
        <Parameter Name="outputTokens" Type="System.Int32" />
        <Parameter Name="inputTokenDetails" Type="Azure.AI.VoiceLive.InputTokenDetails" />
        <Parameter Name="outputTokenDetails" Type="Azure.AI.VoiceLive.OutputTokenDetails" />
      </Parameters>
      <Docs>
        <param name="totalTokens"> Total number of tokens (input + output). </param>
        <param name="inputTokens"> Number of input tokens. </param>
        <param name="outputTokens"> Number of output tokens. </param>
        <param name="inputTokenDetails"> Detailed breakdown of input tokens. </param>
        <param name="outputTokenDetails"> Detailed breakdown of output tokens. </param>
        <summary> Overall usage statistics for a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseTokenStatistics" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ServerVad">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ServerVad ServerVad (float? threshold = default, int? prefixPaddingMs = default, int? silenceDurationMs = default, Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection = default, bool? autoTruncate = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ServerVad ServerVad(valuetype System.Nullable`1&lt;float32&gt; threshold, valuetype System.Nullable`1&lt;int32&gt; prefixPaddingMs, valuetype System.Nullable`1&lt;int32&gt; silenceDurationMs, class Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection, valuetype System.Nullable`1&lt;bool&gt; autoTruncate) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ServerVad(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Boolean})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ServerVad (Optional threshold As Nullable(Of Single) = Nothing, Optional prefixPaddingMs As Nullable(Of Integer) = Nothing, Optional silenceDurationMs As Nullable(Of Integer) = Nothing, Optional endOfUtteranceDetection As EouDetection = Nothing, Optional autoTruncate As Nullable(Of Boolean) = Nothing) As ServerVad" />
      <MemberSignature Language="F#" Value="static member ServerVad : Nullable&lt;single&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Azure.AI.VoiceLive.EouDetection * Nullable&lt;bool&gt; -&gt; Azure.AI.VoiceLive.ServerVad" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ServerVad (threshold, prefixPaddingMs, silenceDurationMs, endOfUtteranceDetection, autoTruncate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ServerVad</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="threshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="prefixPaddingMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="silenceDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="endOfUtteranceDetection" Type="Azure.AI.VoiceLive.EouDetection" />
        <Parameter Name="autoTruncate" Type="System.Nullable&lt;System.Boolean&gt;" />
      </Parameters>
      <Docs>
        <param name="threshold" />
        <param name="prefixPaddingMs" />
        <param name="silenceDurationMs" />
        <param name="endOfUtteranceDetection" />
        <param name="autoTruncate" />
        <summary> Base model for VAD-based turn detection. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ServerVad" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdate">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdate SessionUpdate (string type = default, string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdate SessionUpdate(string type, string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdate(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdate (Optional type As String = Nothing, Optional eventId As String = Nothing) As SessionUpdate" />
      <MemberSignature Language="F#" Value="static member SessionUpdate : string * string -&gt; Azure.AI.VoiceLive.SessionUpdate" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdate (type, eventId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdate</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type"> The type of event. </param>
        <param name="eventId" />
        <summary>
            A voicelive server event.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionAvatarConnecting(System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionCreated(System.String,Azure.AI.VoiceLive.VoiceLiveSessionResponse)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionUpdated(System.String,Azure.AI.VoiceLive.VoiceLiveSessionResponse)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateError(System.String,Azure.AI.VoiceLive.SessionUpdateErrorDetails)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseTextDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.BinaryData)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemCreated(System.String,System.String,Azure.AI.VoiceLive.ResponseItem)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemDeleted(System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemRetrieved(Azure.AI.VoiceLive.ResponseItem,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemTruncated(System.String,System.Int32,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionCompleted(System.String,System.String,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionDelta(System.String,System.String,System.Nullable{System.Int32},System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.LogProbProperties})" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionFailed(System.String,System.String,System.Int32,Azure.AI.VoiceLive.VoiceLiveErrorDetails)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferCommitted(System.String,System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferCleared(System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferSpeechStarted(System.String,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferSpeechStopped(System.String,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseCreated(System.String,Azure.AI.VoiceLive.VoiceLiveResponse)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseDone(System.String,Azure.AI.VoiceLive.VoiceLiveResponse)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseOutputItemAdded(System.String,System.String,System.Int32,Azure.AI.VoiceLive.ResponseItem)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseOutputItemDone(System.String,System.String,System.Int32,Azure.AI.VoiceLive.ResponseItem)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseContentPartAdded(System.String,System.String,System.String,System.Int32,System.Int32,Azure.AI.VoiceLive.VoiceLiveContentPart)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseContentPartDone(System.String,System.String,System.String,System.Int32,System.Int32,Azure.AI.VoiceLive.VoiceLiveContentPart)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseTextDone(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTranscriptDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTranscriptDone(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioDone(System.String,System.String,System.String,System.Int32,System.Int32)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseFunctionCallArgumentsDelta(System.String,System.String,System.String,System.Int32,System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseFunctionCallArgumentsDone(System.String,System.String,System.String,System.Int32,System.String,System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationBlendshapeDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.BinaryData,System.Int32)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationBlendshapeDone(System.String,System.String,System.String,System.Int32)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseEmotionHypothesis(System.String,System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.EmotionCandidate},System.Int32,System.Int32,System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTimestampDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.Int32,System.Int32,System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTimestampDone(System.String,System.String,System.String,System.Int32,System.Int32)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationVisemeDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.Int32,System.Int32)" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationVisemeDone(System.String,System.String,System.String,System.Int32,System.Int32)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdate" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemCreated">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemCreated SessionUpdateConversationItemCreated (string eventId = default, string previousItemId = default, Azure.AI.VoiceLive.ResponseItem item = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemCreated SessionUpdateConversationItemCreated(string eventId, string previousItemId, class Azure.AI.VoiceLive.ResponseItem item) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemCreated(System.String,System.String,Azure.AI.VoiceLive.ResponseItem)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemCreated (Optional eventId As String = Nothing, Optional previousItemId As String = Nothing, Optional item As ResponseItem = Nothing) As SessionUpdateConversationItemCreated" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemCreated : string * string * Azure.AI.VoiceLive.ResponseItem -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemCreated" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemCreated (eventId, previousItemId, item)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemCreated</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="previousItemId" Type="System.String" />
        <Parameter Name="item" Type="Azure.AI.VoiceLive.ResponseItem" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="previousItemId">
            The ID of the preceding item in the Conversation context, allows the
            client to understand the order of the conversation.
            </param>
        <param name="item" />
        <summary>
            Returned when a conversation item is created. There are several scenarios that produce this event:
              - The server is generating a Response, which if successful will produce
                either one or two Items, which will be of type `message`
                (role `assistant`) or type `function_call`.
              - The input audio buffer has been committed, either by the client or the
                server (in `server_vad` mode). The server will take the content of the
                input audio buffer and add it to a new user message Item.
              - The client has sent a `conversation.item.create` event to add a new Item
                to the Conversation.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemCreated" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemDeleted">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemDeleted SessionUpdateConversationItemDeleted (string itemId = default, string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemDeleted SessionUpdateConversationItemDeleted(string itemId, string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemDeleted(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemDeleted (Optional itemId As String = Nothing, Optional eventId As String = Nothing) As SessionUpdateConversationItemDeleted" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemDeleted : string * string -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemDeleted" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemDeleted (itemId, eventId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemDeleted</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="itemId"> The ID of the item that was deleted. </param>
        <param name="eventId" />
        <summary>
            Returned when an item in the conversation is deleted by the client with a
            `conversation.item.delete` event. This event is used to synchronize the
            server's understanding of the conversation history with the client's view.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemDeleted" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemInputAudioTranscriptionCompleted">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionCompleted SessionUpdateConversationItemInputAudioTranscriptionCompleted (string eventId = default, string itemId = default, int contentIndex = 0, string transcript = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionCompleted SessionUpdateConversationItemInputAudioTranscriptionCompleted(string eventId, string itemId, int32 contentIndex, string transcript) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionCompleted(System.String,System.String,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemInputAudioTranscriptionCompleted (Optional eventId As String = Nothing, Optional itemId As String = Nothing, Optional contentIndex As Integer = 0, Optional transcript As String = Nothing) As SessionUpdateConversationItemInputAudioTranscriptionCompleted" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemInputAudioTranscriptionCompleted : string * string * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionCompleted" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionCompleted (eventId, itemId, contentIndex, transcript)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionCompleted</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="transcript" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="itemId"> The ID of the user message item containing the audio. </param>
        <param name="contentIndex"> The index of the content part containing the audio. </param>
        <param name="transcript"> The transcribed text. </param>
        <summary>
            This event is the output of audio transcription for user audio written to the
            user audio buffer. Transcription begins when the input audio buffer is
            committed by the client or server (in `server_vad` mode). Transcription runs
            asynchronously with Response creation, so this event may come before or after
            the Response events.
            
            VoiceLive API models accept audio natively, and thus input transcription is a
            separate process run on a separate ASR (Automatic Speech Recognition) model.
            The transcript may diverge somewhat from the model's interpretation, and
            should be treated as a rough guide.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionCompleted" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemInputAudioTranscriptionDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionDelta SessionUpdateConversationItemInputAudioTranscriptionDelta (string eventId = default, string itemId = default, int? contentIndex = default, string delta = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.LogProbProperties&gt; logprobs = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionDelta SessionUpdateConversationItemInputAudioTranscriptionDelta(string eventId, string itemId, valuetype System.Nullable`1&lt;int32&gt; contentIndex, string delta, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.LogProbProperties&gt; logprobs) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionDelta(System.String,System.String,System.Nullable{System.Int32},System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.LogProbProperties})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemInputAudioTranscriptionDelta (Optional eventId As String = Nothing, Optional itemId As String = Nothing, Optional contentIndex As Nullable(Of Integer) = Nothing, Optional delta As String = Nothing, Optional logprobs As IEnumerable(Of LogProbProperties) = Nothing) As SessionUpdateConversationItemInputAudioTranscriptionDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemInputAudioTranscriptionDelta : string * string * Nullable&lt;int&gt; * string * seq&lt;Azure.AI.VoiceLive.LogProbProperties&gt; -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionDelta (eventId, itemId, contentIndex, delta, logprobs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="contentIndex" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="delta" Type="System.String" />
        <Parameter Name="logprobs" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.LogProbProperties&gt;" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="itemId"> The ID of the item. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="delta"> The text delta. </param>
        <param name="logprobs"> The log probabilities of the transcription. </param>
        <summary> Returned when the text value of an input audio transcription content part is updated. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemInputAudioTranscriptionFailed">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionFailed SessionUpdateConversationItemInputAudioTranscriptionFailed (string eventId = default, string itemId = default, int contentIndex = 0, Azure.AI.VoiceLive.VoiceLiveErrorDetails error = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionFailed SessionUpdateConversationItemInputAudioTranscriptionFailed(string eventId, string itemId, int32 contentIndex, class Azure.AI.VoiceLive.VoiceLiveErrorDetails error) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionFailed(System.String,System.String,System.Int32,Azure.AI.VoiceLive.VoiceLiveErrorDetails)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemInputAudioTranscriptionFailed (Optional eventId As String = Nothing, Optional itemId As String = Nothing, Optional contentIndex As Integer = 0, Optional error As VoiceLiveErrorDetails = Nothing) As SessionUpdateConversationItemInputAudioTranscriptionFailed" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemInputAudioTranscriptionFailed : string * string * int * Azure.AI.VoiceLive.VoiceLiveErrorDetails -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionFailed" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionFailed (eventId, itemId, contentIndex, error)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionFailed</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="error" Type="Azure.AI.VoiceLive.VoiceLiveErrorDetails" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="itemId"> The ID of the user message item. </param>
        <param name="contentIndex"> The index of the content part containing the audio. </param>
        <param name="error"> Details of the transcription error. </param>
        <summary>
            Returned when input audio transcription is configured, and a transcription
            request for a user message failed. These events are separate from other
            `error` events so that the client can identify the related Item.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionFailed" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemRetrieved">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemRetrieved SessionUpdateConversationItemRetrieved (Azure.AI.VoiceLive.ResponseItem item = default, string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemRetrieved SessionUpdateConversationItemRetrieved(class Azure.AI.VoiceLive.ResponseItem item, string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemRetrieved(Azure.AI.VoiceLive.ResponseItem,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemRetrieved (Optional item As ResponseItem = Nothing, Optional eventId As String = Nothing) As SessionUpdateConversationItemRetrieved" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemRetrieved : Azure.AI.VoiceLive.ResponseItem * string -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemRetrieved" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemRetrieved (item, eventId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemRetrieved</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="item" Type="Azure.AI.VoiceLive.ResponseItem" />
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="item" />
        <param name="eventId" />
        <summary> Returned when a conversation item is retrieved with `conversation.item.retrieve`. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemRetrieved" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemTruncated">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemTruncated SessionUpdateConversationItemTruncated (string itemId = default, int contentIndex = 0, int audioEndMs = 0, string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemTruncated SessionUpdateConversationItemTruncated(string itemId, int32 contentIndex, int32 audioEndMs, string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemTruncated(System.String,System.Int32,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemTruncated (Optional itemId As String = Nothing, Optional contentIndex As Integer = 0, Optional audioEndMs As Integer = 0, Optional eventId As String = Nothing) As SessionUpdateConversationItemTruncated" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemTruncated : string * int * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemTruncated" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemTruncated (itemId, contentIndex, audioEndMs, eventId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemTruncated</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="audioEndMs" Type="System.Int32" />
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="itemId"> The ID of the assistant message item that was truncated. </param>
        <param name="contentIndex"> The index of the content part that was truncated. </param>
        <param name="audioEndMs"> The duration up to which the audio was truncated, in milliseconds. </param>
        <param name="eventId" />
        <summary>
            Returned when an earlier assistant audio message item is truncated by the
            client with a `conversation.item.truncate` event. This event is used to
            synchronize the server's understanding of the audio with the client's playback.
            
            This action will truncate the audio and remove the server-side text transcript
            to ensure there is no text in the context that hasn't been heard by the user.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemTruncated" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateError">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateError SessionUpdateError (string eventId = default, Azure.AI.VoiceLive.SessionUpdateErrorDetails error = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateError SessionUpdateError(string eventId, class Azure.AI.VoiceLive.SessionUpdateErrorDetails error) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateError(System.String,Azure.AI.VoiceLive.SessionUpdateErrorDetails)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateError (Optional eventId As String = Nothing, Optional error As SessionUpdateErrorDetails = Nothing) As SessionUpdateError" />
      <MemberSignature Language="F#" Value="static member SessionUpdateError : string * Azure.AI.VoiceLive.SessionUpdateErrorDetails -&gt; Azure.AI.VoiceLive.SessionUpdateError" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateError (eventId, error)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateError</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="error" Type="Azure.AI.VoiceLive.SessionUpdateErrorDetails" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="error"> Details of the error. </param>
        <summary>
            Returned when an error occurs, which could be a client problem or a server
            problem. Most errors are recoverable and the session will stay open, we
            recommend to implementors to monitor and log error messages by default.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateError" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateErrorDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateErrorDetails SessionUpdateErrorDetails (string type = default, string code = default, string message = default, string param = default, string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateErrorDetails SessionUpdateErrorDetails(string type, string code, string message, string param, string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateErrorDetails(System.String,System.String,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateErrorDetails (Optional type As String = Nothing, Optional code As String = Nothing, Optional message As String = Nothing, Optional param As String = Nothing, Optional eventId As String = Nothing) As SessionUpdateErrorDetails" />
      <MemberSignature Language="F#" Value="static member SessionUpdateErrorDetails : string * string * string * string * string -&gt; Azure.AI.VoiceLive.SessionUpdateErrorDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateErrorDetails (type, code, message, param, eventId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateErrorDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="code" Type="System.String" />
        <Parameter Name="message" Type="System.String" />
        <Parameter Name="param" Type="System.String" />
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type"> The type of error (e.g., "invalid_request_error", "server_error"). </param>
        <param name="code"> Error code, if any. </param>
        <param name="message"> A human-readable error message. </param>
        <param name="param"> Parameter related to the error, if any. </param>
        <param name="eventId"> The event_id of the client event that caused the error, if applicable. </param>
        <summary> Details of the error. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateErrorDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateInputAudioBufferCleared">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCleared SessionUpdateInputAudioBufferCleared (string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCleared SessionUpdateInputAudioBufferCleared(string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferCleared(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateInputAudioBufferCleared (Optional eventId As String = Nothing) As SessionUpdateInputAudioBufferCleared" />
      <MemberSignature Language="F#" Value="static member SessionUpdateInputAudioBufferCleared : string -&gt; Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCleared" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferCleared eventId" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCleared</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <summary>
            Returned when the input audio buffer is cleared by the client with a
            `input_audio_buffer.clear` event.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCleared" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateInputAudioBufferCommitted">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCommitted SessionUpdateInputAudioBufferCommitted (string eventId = default, string previousItemId = default, string itemId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCommitted SessionUpdateInputAudioBufferCommitted(string eventId, string previousItemId, string itemId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferCommitted(System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateInputAudioBufferCommitted (Optional eventId As String = Nothing, Optional previousItemId As String = Nothing, Optional itemId As String = Nothing) As SessionUpdateInputAudioBufferCommitted" />
      <MemberSignature Language="F#" Value="static member SessionUpdateInputAudioBufferCommitted : string * string * string -&gt; Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCommitted" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferCommitted (eventId, previousItemId, itemId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCommitted</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="previousItemId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="previousItemId"> The ID of the preceding item after which the new item will be inserted. </param>
        <param name="itemId"> The ID of the user message item that will be created. </param>
        <summary>
            Returned when an input audio buffer is committed, either by the client or
            automatically in server VAD mode. The `item_id` property is the ID of the user
            message item that will be created, thus a `conversation.item.created` event
            will also be sent to the client.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCommitted" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateInputAudioBufferSpeechStarted">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStarted SessionUpdateInputAudioBufferSpeechStarted (string eventId = default, int audioStartMs = 0, string itemId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStarted SessionUpdateInputAudioBufferSpeechStarted(string eventId, int32 audioStartMs, string itemId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferSpeechStarted(System.String,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateInputAudioBufferSpeechStarted (Optional eventId As String = Nothing, Optional audioStartMs As Integer = 0, Optional itemId As String = Nothing) As SessionUpdateInputAudioBufferSpeechStarted" />
      <MemberSignature Language="F#" Value="static member SessionUpdateInputAudioBufferSpeechStarted : string * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStarted" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferSpeechStarted (eventId, audioStartMs, itemId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStarted</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="audioStartMs" Type="System.Int32" />
        <Parameter Name="itemId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="audioStartMs" />
        <param name="itemId"> The ID of the user message item that will be created when speech stops. </param>
        <summary>
            Sent by the server when in `server_vad` mode to indicate that speech has been
            detected in the audio buffer. This can happen any time audio is added to the
            buffer (unless speech is already detected). The client may want to use this
            event to interrupt audio playback or provide visual feedback to the user.
            
            The client should expect to receive a `input_audio_buffer.speech_stopped` event
            when speech stops. The `item_id` property is the ID of the user message item
            that will be created when speech stops and will also be included in the
            `input_audio_buffer.speech_stopped` event (unless the client manually commits
            the audio buffer during VAD activation).
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStarted" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateInputAudioBufferSpeechStopped">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStopped SessionUpdateInputAudioBufferSpeechStopped (string eventId = default, int audioEndMs = 0, string itemId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStopped SessionUpdateInputAudioBufferSpeechStopped(string eventId, int32 audioEndMs, string itemId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferSpeechStopped(System.String,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateInputAudioBufferSpeechStopped (Optional eventId As String = Nothing, Optional audioEndMs As Integer = 0, Optional itemId As String = Nothing) As SessionUpdateInputAudioBufferSpeechStopped" />
      <MemberSignature Language="F#" Value="static member SessionUpdateInputAudioBufferSpeechStopped : string * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStopped" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferSpeechStopped (eventId, audioEndMs, itemId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStopped</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="audioEndMs" Type="System.Int32" />
        <Parameter Name="itemId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="audioEndMs">
            Milliseconds since the session started when speech stopped. This will
            correspond to the end of audio sent to the model, and thus includes the
            `min_silence_duration_ms` configured in the Session.
            </param>
        <param name="itemId"> The ID of the user message item that will be created. </param>
        <summary>
            Returned in `server_vad` mode when the server detects the end of speech in
            the audio buffer. The server will also send an `conversation.item.created`
            event with the user message item that is created from the audio buffer.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStopped" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAnimationBlendshapeDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDelta SessionUpdateResponseAnimationBlendshapeDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, BinaryData frames = default, int frameIndex = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDelta SessionUpdateResponseAnimationBlendshapeDelta(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, class System.BinaryData frames, int32 frameIndex) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationBlendshapeDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.BinaryData,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAnimationBlendshapeDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional frames As BinaryData = Nothing, Optional frameIndex As Integer = 0) As SessionUpdateResponseAnimationBlendshapeDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAnimationBlendshapeDelta : string * string * string * int * int * BinaryData * int -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationBlendshapeDelta (eventId, responseId, itemId, outputIndex, contentIndex, frames, frameIndex)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="frames" Type="System.BinaryData" />
        <Parameter Name="frameIndex" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId" />
        <param name="itemId" />
        <param name="outputIndex" />
        <param name="contentIndex" />
        <param name="frames" />
        <param name="frameIndex" />
        <summary> Represents a delta update of blendshape animation frames for a specific output of a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAnimationBlendshapeDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDone SessionUpdateResponseAnimationBlendshapeDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDone SessionUpdateResponseAnimationBlendshapeDone(string eventId, string responseId, string itemId, int32 outputIndex) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationBlendshapeDone(System.String,System.String,System.String,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAnimationBlendshapeDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0) As SessionUpdateResponseAnimationBlendshapeDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAnimationBlendshapeDone : string * string * string * int -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationBlendshapeDone (eventId, responseId, itemId, outputIndex)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId" />
        <param name="itemId" />
        <param name="outputIndex" />
        <summary> Indicates the completion of blendshape animation processing for a specific output of a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAnimationVisemeDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDelta SessionUpdateResponseAnimationVisemeDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, int audioOffsetMs = 0, int visemeId = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDelta SessionUpdateResponseAnimationVisemeDelta(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, int32 audioOffsetMs, int32 visemeId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationVisemeDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAnimationVisemeDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional audioOffsetMs As Integer = 0, Optional visemeId As Integer = 0) As SessionUpdateResponseAnimationVisemeDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAnimationVisemeDelta : string * string * string * int * int * int * int -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationVisemeDelta (eventId, responseId, itemId, outputIndex, contentIndex, audioOffsetMs, visemeId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="audioOffsetMs" Type="System.Int32" />
        <Parameter Name="visemeId" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId" />
        <param name="itemId" />
        <param name="outputIndex" />
        <param name="contentIndex" />
        <param name="audioOffsetMs" />
        <param name="visemeId" />
        <summary> Represents a viseme ID delta update for animation based on audio. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAnimationVisemeDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDone SessionUpdateResponseAnimationVisemeDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDone SessionUpdateResponseAnimationVisemeDone(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationVisemeDone(System.String,System.String,System.String,System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAnimationVisemeDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0) As SessionUpdateResponseAnimationVisemeDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAnimationVisemeDone : string * string * string * int * int -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationVisemeDone (eventId, responseId, itemId, outputIndex, contentIndex)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId" />
        <param name="itemId" />
        <param name="outputIndex" />
        <param name="contentIndex" />
        <summary> Indicates completion of viseme animation delivery for a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAudioDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAudioDelta SessionUpdateResponseAudioDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, BinaryData delta = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAudioDelta SessionUpdateResponseAudioDelta(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, class System.BinaryData delta) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.BinaryData)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAudioDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional delta As BinaryData = Nothing) As SessionUpdateResponseAudioDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAudioDelta : string * string * string * int * int * BinaryData -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAudioDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioDelta (eventId, responseId, itemId, outputIndex, contentIndex, delta)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAudioDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="delta" Type="System.BinaryData" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="delta"> Base64-encoded audio data delta. </param>
        <summary> Returned when the model-generated audio is updated. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAudioDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAudioDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAudioDone SessionUpdateResponseAudioDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAudioDone SessionUpdateResponseAudioDone(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioDone(System.String,System.String,System.String,System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAudioDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0) As SessionUpdateResponseAudioDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAudioDone : string * string * string * int * int -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAudioDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioDone (eventId, responseId, itemId, outputIndex, contentIndex)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAudioDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <summary>
            Returned when the model-generated audio is done. Also emitted when a Response
            is interrupted, incomplete, or cancelled.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAudioDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAudioTimestampDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDelta SessionUpdateResponseAudioTimestampDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, int audioOffsetMs = 0, int audioDurationMs = 0, string text = default, string timestampType = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDelta SessionUpdateResponseAudioTimestampDelta(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, int32 audioOffsetMs, int32 audioDurationMs, string text, string timestampType) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTimestampDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.Int32,System.Int32,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAudioTimestampDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional audioOffsetMs As Integer = 0, Optional audioDurationMs As Integer = 0, Optional text As String = Nothing, Optional timestampType As String = Nothing) As SessionUpdateResponseAudioTimestampDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAudioTimestampDelta : string * string * string * int * int * int * int * string * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTimestampDelta (eventId, responseId, itemId, outputIndex, contentIndex, audioOffsetMs, audioDurationMs, text, timestampType)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="audioOffsetMs" Type="System.Int32" />
        <Parameter Name="audioDurationMs" Type="System.Int32" />
        <Parameter Name="text" Type="System.String" />
        <Parameter Name="timestampType" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId" />
        <param name="itemId" />
        <param name="outputIndex" />
        <param name="contentIndex" />
        <param name="audioOffsetMs" />
        <param name="audioDurationMs" />
        <param name="text" />
        <param name="timestampType" />
        <summary> Represents a word-level audio timestamp delta for a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAudioTimestampDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDone SessionUpdateResponseAudioTimestampDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDone SessionUpdateResponseAudioTimestampDone(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTimestampDone(System.String,System.String,System.String,System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAudioTimestampDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0) As SessionUpdateResponseAudioTimestampDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAudioTimestampDone : string * string * string * int * int -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTimestampDone (eventId, responseId, itemId, outputIndex, contentIndex)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId" />
        <param name="itemId" />
        <param name="outputIndex" />
        <param name="contentIndex" />
        <summary> Indicates completion of audio timestamp delivery for a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAudioTranscriptDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDelta SessionUpdateResponseAudioTranscriptDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, string delta = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDelta SessionUpdateResponseAudioTranscriptDelta(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, string delta) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTranscriptDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAudioTranscriptDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional delta As String = Nothing) As SessionUpdateResponseAudioTranscriptDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAudioTranscriptDelta : string * string * string * int * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTranscriptDelta (eventId, responseId, itemId, outputIndex, contentIndex, delta)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="delta" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="delta"> The transcript delta. </param>
        <summary> Returned when the model-generated transcription of audio output is updated. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAudioTranscriptDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDone SessionUpdateResponseAudioTranscriptDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, string transcript = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDone SessionUpdateResponseAudioTranscriptDone(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, string transcript) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTranscriptDone(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAudioTranscriptDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional transcript As String = Nothing) As SessionUpdateResponseAudioTranscriptDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAudioTranscriptDone : string * string * string * int * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTranscriptDone (eventId, responseId, itemId, outputIndex, contentIndex, transcript)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="transcript" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="transcript"> The final transcript of the audio. </param>
        <summary>
            Returned when the model-generated transcription of audio output is done
            streaming. Also emitted when a Response is interrupted, incomplete, or
            cancelled.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseContentPartAdded">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseContentPartAdded SessionUpdateResponseContentPartAdded (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, Azure.AI.VoiceLive.VoiceLiveContentPart part = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseContentPartAdded SessionUpdateResponseContentPartAdded(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, class Azure.AI.VoiceLive.VoiceLiveContentPart part) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseContentPartAdded(System.String,System.String,System.String,System.Int32,System.Int32,Azure.AI.VoiceLive.VoiceLiveContentPart)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseContentPartAdded (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional part As VoiceLiveContentPart = Nothing) As SessionUpdateResponseContentPartAdded" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseContentPartAdded : string * string * string * int * int * Azure.AI.VoiceLive.VoiceLiveContentPart -&gt; Azure.AI.VoiceLive.SessionUpdateResponseContentPartAdded" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseContentPartAdded (eventId, responseId, itemId, outputIndex, contentIndex, part)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseContentPartAdded</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="part" Type="Azure.AI.VoiceLive.VoiceLiveContentPart" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item to which the content part was added. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="part"> The content part that was added. </param>
        <summary>
            Returned when a new content part is added to an assistant message item during
            response generation.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseContentPartAdded" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseContentPartDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseContentPartDone SessionUpdateResponseContentPartDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, Azure.AI.VoiceLive.VoiceLiveContentPart part = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseContentPartDone SessionUpdateResponseContentPartDone(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, class Azure.AI.VoiceLive.VoiceLiveContentPart part) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseContentPartDone(System.String,System.String,System.String,System.Int32,System.Int32,Azure.AI.VoiceLive.VoiceLiveContentPart)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseContentPartDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional part As VoiceLiveContentPart = Nothing) As SessionUpdateResponseContentPartDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseContentPartDone : string * string * string * int * int * Azure.AI.VoiceLive.VoiceLiveContentPart -&gt; Azure.AI.VoiceLive.SessionUpdateResponseContentPartDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseContentPartDone (eventId, responseId, itemId, outputIndex, contentIndex, part)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseContentPartDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="part" Type="Azure.AI.VoiceLive.VoiceLiveContentPart" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="part"> The content part that is done. </param>
        <summary>
            Returned when a content part is done streaming in an assistant message item.
            Also emitted when a Response is interrupted, incomplete, or cancelled.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseContentPartDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseCreated">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseCreated SessionUpdateResponseCreated (string eventId = default, Azure.AI.VoiceLive.VoiceLiveResponse response = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseCreated SessionUpdateResponseCreated(string eventId, class Azure.AI.VoiceLive.VoiceLiveResponse response) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseCreated(System.String,Azure.AI.VoiceLive.VoiceLiveResponse)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseCreated (Optional eventId As String = Nothing, Optional response As VoiceLiveResponse = Nothing) As SessionUpdateResponseCreated" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseCreated : string * Azure.AI.VoiceLive.VoiceLiveResponse -&gt; Azure.AI.VoiceLive.SessionUpdateResponseCreated" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseCreated (eventId, response)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseCreated</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="response" Type="Azure.AI.VoiceLive.VoiceLiveResponse" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="response" />
        <summary>
            Returned when a new Response is created. The first event of response creation,
            where the response is in an initial state of `in_progress`.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseCreated" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseDone SessionUpdateResponseDone (string eventId = default, Azure.AI.VoiceLive.VoiceLiveResponse response = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseDone SessionUpdateResponseDone(string eventId, class Azure.AI.VoiceLive.VoiceLiveResponse response) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseDone(System.String,Azure.AI.VoiceLive.VoiceLiveResponse)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseDone (Optional eventId As String = Nothing, Optional response As VoiceLiveResponse = Nothing) As SessionUpdateResponseDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseDone : string * Azure.AI.VoiceLive.VoiceLiveResponse -&gt; Azure.AI.VoiceLive.SessionUpdateResponseDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseDone (eventId, response)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="response" Type="Azure.AI.VoiceLive.VoiceLiveResponse" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="response" />
        <summary>
            Returned when a Response is done streaming. Always emitted, no matter the
            final state. The Response object included in the `response.done` event will
            include all output Items in the Response but will omit the raw audio data.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseEmotionHypothesis">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseEmotionHypothesis SessionUpdateResponseEmotionHypothesis (string eventId = default, string emotion = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.EmotionCandidate&gt; candidates = default, int audioOffsetMs = 0, int audioDurationMs = 0, string responseId = default, string itemId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseEmotionHypothesis SessionUpdateResponseEmotionHypothesis(string eventId, string emotion, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.EmotionCandidate&gt; candidates, int32 audioOffsetMs, int32 audioDurationMs, string responseId, string itemId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseEmotionHypothesis(System.String,System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.EmotionCandidate},System.Int32,System.Int32,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseEmotionHypothesis (Optional eventId As String = Nothing, Optional emotion As String = Nothing, Optional candidates As IEnumerable(Of EmotionCandidate) = Nothing, Optional audioOffsetMs As Integer = 0, Optional audioDurationMs As Integer = 0, Optional responseId As String = Nothing, Optional itemId As String = Nothing) As SessionUpdateResponseEmotionHypothesis" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseEmotionHypothesis : string * string * seq&lt;Azure.AI.VoiceLive.EmotionCandidate&gt; * int * int * string * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseEmotionHypothesis" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseEmotionHypothesis (eventId, emotion, candidates, audioOffsetMs, audioDurationMs, responseId, itemId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseEmotionHypothesis</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="emotion" Type="System.String" />
        <Parameter Name="candidates" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.EmotionCandidate&gt;" />
        <Parameter Name="audioOffsetMs" Type="System.Int32" />
        <Parameter Name="audioDurationMs" Type="System.Int32" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="emotion" />
        <param name="candidates" />
        <param name="audioOffsetMs" />
        <param name="audioDurationMs" />
        <param name="responseId" />
        <param name="itemId" />
        <summary> Represents an emotion hypothesis detected from response audio with multiple candidates. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseEmotionHypothesis" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseFunctionCallArgumentsDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDelta SessionUpdateResponseFunctionCallArgumentsDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, string callId = default, string delta = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDelta SessionUpdateResponseFunctionCallArgumentsDelta(string eventId, string responseId, string itemId, int32 outputIndex, string callId, string delta) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseFunctionCallArgumentsDelta(System.String,System.String,System.String,System.Int32,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseFunctionCallArgumentsDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional callId As String = Nothing, Optional delta As String = Nothing) As SessionUpdateResponseFunctionCallArgumentsDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseFunctionCallArgumentsDelta : string * string * string * int * string * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseFunctionCallArgumentsDelta (eventId, responseId, itemId, outputIndex, callId, delta)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="callId" Type="System.String" />
        <Parameter Name="delta" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the function call item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="callId"> The ID of the function call. </param>
        <param name="delta"> The arguments delta as a JSON string. </param>
        <summary> Returned when the model-generated function call arguments are updated. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseFunctionCallArgumentsDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDone SessionUpdateResponseFunctionCallArgumentsDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, string callId = default, string arguments = default, string name = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDone SessionUpdateResponseFunctionCallArgumentsDone(string eventId, string responseId, string itemId, int32 outputIndex, string callId, string arguments, string name) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseFunctionCallArgumentsDone(System.String,System.String,System.String,System.Int32,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseFunctionCallArgumentsDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional callId As String = Nothing, Optional arguments As String = Nothing, Optional name As String = Nothing) As SessionUpdateResponseFunctionCallArgumentsDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseFunctionCallArgumentsDone : string * string * string * int * string * string * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseFunctionCallArgumentsDone (eventId, responseId, itemId, outputIndex, callId, arguments, name)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="callId" Type="System.String" />
        <Parameter Name="arguments" Type="System.String" />
        <Parameter Name="name" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the function call item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="callId"> The ID of the function call. </param>
        <param name="arguments"> The final arguments as a JSON string. </param>
        <param name="name"> The name of the function call. </param>
        <summary>
            Returned when the model-generated function call arguments are done streaming.
            Also emitted when a Response is interrupted, incomplete, or cancelled.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseOutputItemAdded">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseOutputItemAdded SessionUpdateResponseOutputItemAdded (string eventId = default, string responseId = default, int outputIndex = 0, Azure.AI.VoiceLive.ResponseItem item = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseOutputItemAdded SessionUpdateResponseOutputItemAdded(string eventId, string responseId, int32 outputIndex, class Azure.AI.VoiceLive.ResponseItem item) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseOutputItemAdded(System.String,System.String,System.Int32,Azure.AI.VoiceLive.ResponseItem)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseOutputItemAdded (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional outputIndex As Integer = 0, Optional item As ResponseItem = Nothing) As SessionUpdateResponseOutputItemAdded" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseOutputItemAdded : string * string * int * Azure.AI.VoiceLive.ResponseItem -&gt; Azure.AI.VoiceLive.SessionUpdateResponseOutputItemAdded" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseOutputItemAdded (eventId, responseId, outputIndex, item)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseOutputItemAdded</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="item" Type="Azure.AI.VoiceLive.ResponseItem" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the Response to which the item belongs. </param>
        <param name="outputIndex"> The index of the output item in the Response. </param>
        <param name="item" />
        <summary> Returned when a new Item is created during Response generation. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseOutputItemAdded" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseOutputItemDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseOutputItemDone SessionUpdateResponseOutputItemDone (string eventId = default, string responseId = default, int outputIndex = 0, Azure.AI.VoiceLive.ResponseItem item = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseOutputItemDone SessionUpdateResponseOutputItemDone(string eventId, string responseId, int32 outputIndex, class Azure.AI.VoiceLive.ResponseItem item) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseOutputItemDone(System.String,System.String,System.Int32,Azure.AI.VoiceLive.ResponseItem)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseOutputItemDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional outputIndex As Integer = 0, Optional item As ResponseItem = Nothing) As SessionUpdateResponseOutputItemDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseOutputItemDone : string * string * int * Azure.AI.VoiceLive.ResponseItem -&gt; Azure.AI.VoiceLive.SessionUpdateResponseOutputItemDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseOutputItemDone (eventId, responseId, outputIndex, item)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseOutputItemDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="item" Type="Azure.AI.VoiceLive.ResponseItem" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the Response to which the item belongs. </param>
        <param name="outputIndex"> The index of the output item in the Response. </param>
        <param name="item" />
        <summary>
            Returned when an Item is done streaming. Also emitted when a Response is
            interrupted, incomplete, or cancelled.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseOutputItemDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseTextDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseTextDelta SessionUpdateResponseTextDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, string delta = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseTextDelta SessionUpdateResponseTextDelta(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, string delta) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseTextDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseTextDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional delta As String = Nothing) As SessionUpdateResponseTextDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseTextDelta : string * string * string * int * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseTextDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseTextDelta (eventId, responseId, itemId, outputIndex, contentIndex, delta)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseTextDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="delta" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="delta"> The text delta. </param>
        <summary> Returned when the text value of a "text" content part is updated. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseTextDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseTextDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseTextDone SessionUpdateResponseTextDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, string text = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseTextDone SessionUpdateResponseTextDone(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, string text) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseTextDone(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseTextDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional text As String = Nothing) As SessionUpdateResponseTextDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseTextDone : string * string * string * int * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseTextDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseTextDone (eventId, responseId, itemId, outputIndex, contentIndex, text)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseTextDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="text" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="text"> The final text content. </param>
        <summary>
            Returned when the text value of a "text" content part is done streaming. Also
            emitted when a Response is interrupted, incomplete, or cancelled.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseTextDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateSessionAvatarConnecting">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateSessionAvatarConnecting SessionUpdateSessionAvatarConnecting (string eventId = default, string serverSdp = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateSessionAvatarConnecting SessionUpdateSessionAvatarConnecting(string eventId, string serverSdp) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionAvatarConnecting(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateSessionAvatarConnecting (Optional eventId As String = Nothing, Optional serverSdp As String = Nothing) As SessionUpdateSessionAvatarConnecting" />
      <MemberSignature Language="F#" Value="static member SessionUpdateSessionAvatarConnecting : string * string -&gt; Azure.AI.VoiceLive.SessionUpdateSessionAvatarConnecting" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionAvatarConnecting (eventId, serverSdp)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateSessionAvatarConnecting</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="serverSdp" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="serverSdp"> The server's SDP answer for the avatar connection. </param>
        <summary> Sent when the server is in the process of establishing an avatar media connection and provides its SDP answer. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateSessionAvatarConnecting" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateSessionCreated">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateSessionCreated SessionUpdateSessionCreated (string eventId = default, Azure.AI.VoiceLive.VoiceLiveSessionResponse session = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateSessionCreated SessionUpdateSessionCreated(string eventId, class Azure.AI.VoiceLive.VoiceLiveSessionResponse session) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionCreated(System.String,Azure.AI.VoiceLive.VoiceLiveSessionResponse)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateSessionCreated (Optional eventId As String = Nothing, Optional session As VoiceLiveSessionResponse = Nothing) As SessionUpdateSessionCreated" />
      <MemberSignature Language="F#" Value="static member SessionUpdateSessionCreated : string * Azure.AI.VoiceLive.VoiceLiveSessionResponse -&gt; Azure.AI.VoiceLive.SessionUpdateSessionCreated" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionCreated (eventId, session)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateSessionCreated</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="session" Type="Azure.AI.VoiceLive.VoiceLiveSessionResponse" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="session" />
        <summary>
            Returned when a Session is created. Emitted automatically when a new
            connection is established as the first server event. This event will contain
            the default Session configuration.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateSessionCreated" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateSessionUpdated">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateSessionUpdated SessionUpdateSessionUpdated (string eventId = default, Azure.AI.VoiceLive.VoiceLiveSessionResponse session = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateSessionUpdated SessionUpdateSessionUpdated(string eventId, class Azure.AI.VoiceLive.VoiceLiveSessionResponse session) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionUpdated(System.String,Azure.AI.VoiceLive.VoiceLiveSessionResponse)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateSessionUpdated (Optional eventId As String = Nothing, Optional session As VoiceLiveSessionResponse = Nothing) As SessionUpdateSessionUpdated" />
      <MemberSignature Language="F#" Value="static member SessionUpdateSessionUpdated : string * Azure.AI.VoiceLive.VoiceLiveSessionResponse -&gt; Azure.AI.VoiceLive.SessionUpdateSessionUpdated" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionUpdated (eventId, session)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateSessionUpdated</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="session" Type="Azure.AI.VoiceLive.VoiceLiveSessionResponse" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="session" />
        <summary>
            Returned when a session is updated with a `session.update` event, unless
            there is an error.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateSessionUpdated" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SystemMessageItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SystemMessageItem SystemMessageItem (string id = default, Azure.AI.VoiceLive.ItemParamStatus? status = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.InputTextContentPart&gt; content = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SystemMessageItem SystemMessageItem(string id, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.ItemParamStatus&gt; status, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.InputTextContentPart&gt; content) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SystemMessageItem(System.String,System.Nullable{Azure.AI.VoiceLive.ItemParamStatus},System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.InputTextContentPart})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SystemMessageItem (Optional id As String = Nothing, Optional status As Nullable(Of ItemParamStatus) = Nothing, Optional content As IEnumerable(Of InputTextContentPart) = Nothing) As SystemMessageItem" />
      <MemberSignature Language="F#" Value="static member SystemMessageItem : string * Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt; * seq&lt;Azure.AI.VoiceLive.InputTextContentPart&gt; -&gt; Azure.AI.VoiceLive.SystemMessageItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SystemMessageItem (id, status, content)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SystemMessageItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="status" Type="System.Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt;" />
        <Parameter Name="content" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.InputTextContentPart&gt;" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="status" />
        <param name="content" />
        <summary> The SystemMessageItem. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SystemMessageItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="TurnDetection">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.TurnDetection TurnDetection (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.TurnDetection TurnDetection(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.TurnDetection(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function TurnDetection (Optional type As String = Nothing) As TurnDetection" />
      <MemberSignature Language="F#" Value="static member TurnDetection : string -&gt; Azure.AI.VoiceLive.TurnDetection" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.TurnDetection type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.TurnDetection</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <summary>
            Top-level union for turn detection configuration.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.NoTurnDetection" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ServerVad(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Boolean})" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVad(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Boolean})" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadEn(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Boolean})" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadServer(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Boolean})" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureMultilingualSemanticVad(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Boolean})" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.TurnDetection" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="UserContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.UserContentPart UserContentPart (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.UserContentPart UserContentPart(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.UserContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function UserContentPart (Optional type As String = Nothing) As UserContentPart" />
      <MemberSignature Language="F#" Value="static member UserContentPart : string -&gt; Azure.AI.VoiceLive.UserContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.UserContentPart type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.UserContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <summary>
            The UserContentPart.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.InputTextContentPart(System.String)" /> and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.InputAudioContentPart(System.String,System.String)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.UserContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="UserMessageItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.UserMessageItem UserMessageItem (string id = default, Azure.AI.VoiceLive.ItemParamStatus? status = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.UserContentPart&gt; content = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.UserMessageItem UserMessageItem(string id, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.ItemParamStatus&gt; status, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.UserContentPart&gt; content) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.UserMessageItem(System.String,System.Nullable{Azure.AI.VoiceLive.ItemParamStatus},System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.UserContentPart})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function UserMessageItem (Optional id As String = Nothing, Optional status As Nullable(Of ItemParamStatus) = Nothing, Optional content As IEnumerable(Of UserContentPart) = Nothing) As UserMessageItem" />
      <MemberSignature Language="F#" Value="static member UserMessageItem : string * Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt; * seq&lt;Azure.AI.VoiceLive.UserContentPart&gt; -&gt; Azure.AI.VoiceLive.UserMessageItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.UserMessageItem (id, status, content)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.UserMessageItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="status" Type="System.Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt;" />
        <Parameter Name="content" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.UserContentPart&gt;" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="status" />
        <param name="content" />
        <summary> The UserMessageItem. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.UserMessageItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VideoCrop">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VideoCrop VideoCrop (System.Collections.Generic.IEnumerable&lt;int&gt; topLeftInternal = default, System.Collections.Generic.IEnumerable&lt;int&gt; bottomRightInternal = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VideoCrop VideoCrop(class System.Collections.Generic.IEnumerable`1&lt;int32&gt; topLeftInternal, class System.Collections.Generic.IEnumerable`1&lt;int32&gt; bottomRightInternal) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoCrop(System.Collections.Generic.IEnumerable{System.Int32},System.Collections.Generic.IEnumerable{System.Int32})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VideoCrop (Optional topLeftInternal As IEnumerable(Of Integer) = Nothing, Optional bottomRightInternal As IEnumerable(Of Integer) = Nothing) As VideoCrop" />
      <MemberSignature Language="F#" Value="static member VideoCrop : seq&lt;int&gt; * seq&lt;int&gt; -&gt; Azure.AI.VoiceLive.VideoCrop" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoCrop (topLeftInternal, bottomRightInternal)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VideoCrop</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="topLeftInternal" Type="System.Collections.Generic.IEnumerable&lt;System.Int32&gt;" />
        <Parameter Name="bottomRightInternal" Type="System.Collections.Generic.IEnumerable&lt;System.Int32&gt;" />
      </Parameters>
      <Docs>
        <param name="topLeftInternal"> Top-left corner of the crop region. </param>
        <param name="bottomRightInternal"> Bottom-right corner of the crop region. </param>
        <summary> Defines a video crop rectangle using top-left and bottom-right coordinates. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VideoCrop" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VideoParams">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VideoParams VideoParams (int? bitrate = default, string codec = default, Azure.AI.VoiceLive.VideoCrop crop = default, Azure.AI.VoiceLive.VideoResolution resolution = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VideoParams VideoParams(valuetype System.Nullable`1&lt;int32&gt; bitrate, string codec, class Azure.AI.VoiceLive.VideoCrop crop, class Azure.AI.VoiceLive.VideoResolution resolution) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoParams(System.Nullable{System.Int32},System.String,Azure.AI.VoiceLive.VideoCrop,Azure.AI.VoiceLive.VideoResolution)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VideoParams (Optional bitrate As Nullable(Of Integer) = Nothing, Optional codec As String = Nothing, Optional crop As VideoCrop = Nothing, Optional resolution As VideoResolution = Nothing) As VideoParams" />
      <MemberSignature Language="F#" Value="static member VideoParams : Nullable&lt;int&gt; * string * Azure.AI.VoiceLive.VideoCrop * Azure.AI.VoiceLive.VideoResolution -&gt; Azure.AI.VoiceLive.VideoParams" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoParams (bitrate, codec, crop, resolution)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VideoParams</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="bitrate" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="codec" Type="System.String" />
        <Parameter Name="crop" Type="Azure.AI.VoiceLive.VideoCrop" />
        <Parameter Name="resolution" Type="Azure.AI.VoiceLive.VideoResolution" />
      </Parameters>
      <Docs>
        <param name="bitrate"> Bitrate in bits per second (e.g., 2000000 for 2 Mbps). </param>
        <param name="codec"> Codec to use for encoding. Currently only 'h264' is supported. </param>
        <param name="crop"> Optional cropping settings for the video stream. </param>
        <param name="resolution"> Optional resolution settings for the video stream. </param>
        <summary> Video streaming parameters for avatar. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VideoParams" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VideoResolution">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VideoResolution VideoResolution (int width = 0, int height = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VideoResolution VideoResolution(int32 width, int32 height) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoResolution(System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VideoResolution (Optional width As Integer = 0, Optional height As Integer = 0) As VideoResolution" />
      <MemberSignature Language="F#" Value="static member VideoResolution : int * int -&gt; Azure.AI.VoiceLive.VideoResolution" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoResolution (width, height)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VideoResolution</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="width" Type="System.Int32" />
        <Parameter Name="height" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="width"> Width of the video in pixels. Must be greater than 0. </param>
        <param name="height"> Height of the video in pixels. Must be greater than 0. </param>
        <summary> Resolution of the video feed in pixels. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VideoResolution" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VoiceLiveContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VoiceLiveContentPart VoiceLiveContentPart (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VoiceLiveContentPart VoiceLiveContentPart(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VoiceLiveContentPart (Optional type As String = Nothing) As VoiceLiveContentPart" />
      <MemberSignature Language="F#" Value="static member VoiceLiveContentPart : string -&gt; Azure.AI.VoiceLive.VoiceLiveContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveContentPart type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VoiceLiveContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <summary>
            The VoiceLiveContentPart.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.RequestTextContentPart(System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.RequestAudioContentPart(System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseTextContentPart(System.String)" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseAudioContentPart(System.String)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VoiceLiveContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VoiceLiveErrorDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VoiceLiveErrorDetails VoiceLiveErrorDetails (string code = default, string message = default, string param = default, string type = default, string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VoiceLiveErrorDetails VoiceLiveErrorDetails(string code, string message, string param, string type, string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveErrorDetails(System.String,System.String,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VoiceLiveErrorDetails (Optional code As String = Nothing, Optional message As String = Nothing, Optional param As String = Nothing, Optional type As String = Nothing, Optional eventId As String = Nothing) As VoiceLiveErrorDetails" />
      <MemberSignature Language="F#" Value="static member VoiceLiveErrorDetails : string * string * string * string * string -&gt; Azure.AI.VoiceLive.VoiceLiveErrorDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveErrorDetails (code, message, param, type, eventId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VoiceLiveErrorDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="code" Type="System.String" />
        <Parameter Name="message" Type="System.String" />
        <Parameter Name="param" Type="System.String" />
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="code"> Error code, or null if unspecified. </param>
        <param name="message"> Human-readable error message. </param>
        <param name="param"> Parameter name related to the error, if applicable. </param>
        <param name="type"> Type or category of the error. </param>
        <param name="eventId"> Event id of the error. </param>
        <summary> Error object returned in case of API failure. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VoiceLiveErrorDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VoiceLiveFunctionDefinition">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VoiceLiveFunctionDefinition VoiceLiveFunctionDefinition (string name = default, string description = default, BinaryData parameters = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VoiceLiveFunctionDefinition VoiceLiveFunctionDefinition(string name, string description, class System.BinaryData parameters) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveFunctionDefinition(System.String,System.String,System.BinaryData)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VoiceLiveFunctionDefinition (Optional name As String = Nothing, Optional description As String = Nothing, Optional parameters As BinaryData = Nothing) As VoiceLiveFunctionDefinition" />
      <MemberSignature Language="F#" Value="static member VoiceLiveFunctionDefinition : string * string * BinaryData -&gt; Azure.AI.VoiceLive.VoiceLiveFunctionDefinition" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveFunctionDefinition (name, description, parameters)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VoiceLiveFunctionDefinition</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="description" Type="System.String" />
        <Parameter Name="parameters" Type="System.BinaryData" />
      </Parameters>
      <Docs>
        <param name="name" />
        <param name="description" />
        <param name="parameters" />
        <summary> The definition of a function tool as used by the voicelive endpoint. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VoiceLiveFunctionDefinition" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VoiceLiveSessionOptions">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VoiceLiveSessionOptions VoiceLiveSessionOptions (string model = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.InputModality&gt; modalities = default, Azure.AI.VoiceLive.AnimationOptions animation = default, string instructions = default, Azure.AI.VoiceLive.InputAudio inputAudio = default, int? inputAudioSamplingRate = default, Azure.AI.VoiceLive.AudioFormat? inputAudioFormat = default, Azure.AI.VoiceLive.AudioFormat? outputAudioFormat = default, Azure.AI.VoiceLive.TurnDetection turnDetection = default, Azure.AI.VoiceLive.AudioNoiseReduction inputAudioNoiseReduction = default, Azure.AI.VoiceLive.AudioEchoCancellation inputAudioEchoCancellation = default, Azure.AI.VoiceLive.AvatarConfiguration avatar = default, Azure.AI.VoiceLive.AudioInputTranscriptionSettings inputAudioTranscription = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.AudioTimestampType&gt; outputAudioTimestampTypes = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt; tools = default, float? temperature = default, Azure.AI.VoiceLive.RespondingAgentOptions agent = default, BinaryData voiceInternal = default, BinaryData maxResponseOutputTokens = default, BinaryData toolChoice = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VoiceLiveSessionOptions VoiceLiveSessionOptions(string model, class System.Collections.Generic.IEnumerable`1&lt;valuetype Azure.AI.VoiceLive.InputModality&gt; modalities, class Azure.AI.VoiceLive.AnimationOptions animation, string instructions, class Azure.AI.VoiceLive.InputAudio inputAudio, valuetype System.Nullable`1&lt;int32&gt; inputAudioSamplingRate, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.AudioFormat&gt; inputAudioFormat, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.AudioFormat&gt; outputAudioFormat, class Azure.AI.VoiceLive.TurnDetection turnDetection, class Azure.AI.VoiceLive.AudioNoiseReduction inputAudioNoiseReduction, class Azure.AI.VoiceLive.AudioEchoCancellation inputAudioEchoCancellation, class Azure.AI.VoiceLive.AvatarConfiguration avatar, class Azure.AI.VoiceLive.AudioInputTranscriptionSettings inputAudioTranscription, class System.Collections.Generic.IEnumerable`1&lt;valuetype Azure.AI.VoiceLive.AudioTimestampType&gt; outputAudioTimestampTypes, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt; tools, valuetype System.Nullable`1&lt;float32&gt; temperature, class Azure.AI.VoiceLive.RespondingAgentOptions agent, class System.BinaryData voiceInternal, class System.BinaryData maxResponseOutputTokens, class System.BinaryData toolChoice) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveSessionOptions(System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.InputModality},Azure.AI.VoiceLive.AnimationOptions,System.String,Azure.AI.VoiceLive.InputAudio,System.Nullable{System.Int32},System.Nullable{Azure.AI.VoiceLive.AudioFormat},System.Nullable{Azure.AI.VoiceLive.AudioFormat},Azure.AI.VoiceLive.TurnDetection,Azure.AI.VoiceLive.AudioNoiseReduction,Azure.AI.VoiceLive.AudioEchoCancellation,Azure.AI.VoiceLive.AvatarConfiguration,Azure.AI.VoiceLive.AudioInputTranscriptionSettings,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.AudioTimestampType},System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.VoiceLiveToolDefinition},System.Nullable{System.Single},Azure.AI.VoiceLive.RespondingAgentOptions,System.BinaryData,System.BinaryData,System.BinaryData)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VoiceLiveSessionOptions (Optional model As String = Nothing, Optional modalities As IEnumerable(Of InputModality) = Nothing, Optional animation As AnimationOptions = Nothing, Optional instructions As String = Nothing, Optional inputAudio As InputAudio = Nothing, Optional inputAudioSamplingRate As Nullable(Of Integer) = Nothing, Optional inputAudioFormat As Nullable(Of AudioFormat) = Nothing, Optional outputAudioFormat As Nullable(Of AudioFormat) = Nothing, Optional turnDetection As TurnDetection = Nothing, Optional inputAudioNoiseReduction As AudioNoiseReduction = Nothing, Optional inputAudioEchoCancellation As AudioEchoCancellation = Nothing, Optional avatar As AvatarConfiguration = Nothing, Optional inputAudioTranscription As AudioInputTranscriptionSettings = Nothing, Optional outputAudioTimestampTypes As IEnumerable(Of AudioTimestampType) = Nothing, Optional tools As IEnumerable(Of VoiceLiveToolDefinition) = Nothing, Optional temperature As Nullable(Of Single) = Nothing, Optional agent As RespondingAgentOptions = Nothing, Optional voiceInternal As BinaryData = Nothing, Optional maxResponseOutputTokens As BinaryData = Nothing, Optional toolChoice As BinaryData = Nothing) As VoiceLiveSessionOptions" />
      <MemberSignature Language="F#" Value="static member VoiceLiveSessionOptions : string * seq&lt;Azure.AI.VoiceLive.InputModality&gt; * Azure.AI.VoiceLive.AnimationOptions * string * Azure.AI.VoiceLive.InputAudio * Nullable&lt;int&gt; * Nullable&lt;Azure.AI.VoiceLive.AudioFormat&gt; * Nullable&lt;Azure.AI.VoiceLive.AudioFormat&gt; * Azure.AI.VoiceLive.TurnDetection * Azure.AI.VoiceLive.AudioNoiseReduction * Azure.AI.VoiceLive.AudioEchoCancellation * Azure.AI.VoiceLive.AvatarConfiguration * Azure.AI.VoiceLive.AudioInputTranscriptionSettings * seq&lt;Azure.AI.VoiceLive.AudioTimestampType&gt; * seq&lt;Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt; * Nullable&lt;single&gt; * Azure.AI.VoiceLive.RespondingAgentOptions * BinaryData * BinaryData * BinaryData -&gt; Azure.AI.VoiceLive.VoiceLiveSessionOptions" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveSessionOptions (model, modalities, animation, instructions, inputAudio, inputAudioSamplingRate, inputAudioFormat, outputAudioFormat, turnDetection, inputAudioNoiseReduction, inputAudioEchoCancellation, avatar, inputAudioTranscription, outputAudioTimestampTypes, tools, temperature, agent, voiceInternal, maxResponseOutputTokens, toolChoice)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VoiceLiveSessionOptions</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="model" Type="System.String" />
        <Parameter Name="modalities" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.InputModality&gt;" />
        <Parameter Name="animation" Type="Azure.AI.VoiceLive.AnimationOptions" />
        <Parameter Name="instructions" Type="System.String" />
        <Parameter Name="inputAudio" Type="Azure.AI.VoiceLive.InputAudio" />
        <Parameter Name="inputAudioSamplingRate" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="inputAudioFormat" Type="System.Nullable&lt;Azure.AI.VoiceLive.AudioFormat&gt;" />
        <Parameter Name="outputAudioFormat" Type="System.Nullable&lt;Azure.AI.VoiceLive.AudioFormat&gt;" />
        <Parameter Name="turnDetection" Type="Azure.AI.VoiceLive.TurnDetection" />
        <Parameter Name="inputAudioNoiseReduction" Type="Azure.AI.VoiceLive.AudioNoiseReduction" />
        <Parameter Name="inputAudioEchoCancellation" Type="Azure.AI.VoiceLive.AudioEchoCancellation" />
        <Parameter Name="avatar" Type="Azure.AI.VoiceLive.AvatarConfiguration" />
        <Parameter Name="inputAudioTranscription" Type="Azure.AI.VoiceLive.AudioInputTranscriptionSettings" />
        <Parameter Name="outputAudioTimestampTypes" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.AudioTimestampType&gt;" />
        <Parameter Name="tools" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt;" />
        <Parameter Name="temperature" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="agent" Type="Azure.AI.VoiceLive.RespondingAgentOptions" />
        <Parameter Name="voiceInternal" Type="System.BinaryData" />
        <Parameter Name="maxResponseOutputTokens" Type="System.BinaryData" />
        <Parameter Name="toolChoice" Type="System.BinaryData" />
      </Parameters>
      <Docs>
        <param name="model" />
        <param name="modalities" />
        <param name="animation" />
        <param name="instructions" />
        <param name="inputAudio" />
        <param name="inputAudioSamplingRate" />
        <param name="inputAudioFormat" />
        <param name="outputAudioFormat" />
        <param name="turnDetection" />
        <param name="inputAudioNoiseReduction" />
        <param name="inputAudioEchoCancellation" />
        <param name="avatar" />
        <param name="inputAudioTranscription" />
        <param name="outputAudioTimestampTypes" />
        <param name="tools" />
        <param name="temperature" />
        <param name="agent" />
        <param name="voiceInternal" />
        <param name="maxResponseOutputTokens" />
        <param name="toolChoice" />
        <summary> The VoiceLiveSessionOptions. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VoiceLiveSessionOptions" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VoiceLiveSessionResponse">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VoiceLiveSessionResponse VoiceLiveSessionResponse (string model = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.InputModality&gt; modalities = default, Azure.AI.VoiceLive.AnimationOptions animation = default, string instructions = default, Azure.AI.VoiceLive.InputAudio inputAudio = default, int? inputAudioSamplingRate = default, Azure.AI.VoiceLive.AudioFormat? inputAudioFormat = default, Azure.AI.VoiceLive.AudioFormat? outputAudioFormat = default, Azure.AI.VoiceLive.TurnDetection turnDetection = default, Azure.AI.VoiceLive.AudioNoiseReduction inputAudioNoiseReduction = default, Azure.AI.VoiceLive.AudioEchoCancellation inputAudioEchoCancellation = default, Azure.AI.VoiceLive.AvatarConfiguration avatar = default, Azure.AI.VoiceLive.AudioInputTranscriptionSettings inputAudioTranscription = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.AudioTimestampType&gt; outputAudioTimestampTypes = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt; tools = default, float? temperature = default, Azure.AI.VoiceLive.RespondingAgentOptions agent = default, BinaryData voiceInternal = default, BinaryData maxResponseOutputTokens = default, BinaryData toolChoice = default, string id = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VoiceLiveSessionResponse VoiceLiveSessionResponse(string model, class System.Collections.Generic.IEnumerable`1&lt;valuetype Azure.AI.VoiceLive.InputModality&gt; modalities, class Azure.AI.VoiceLive.AnimationOptions animation, string instructions, class Azure.AI.VoiceLive.InputAudio inputAudio, valuetype System.Nullable`1&lt;int32&gt; inputAudioSamplingRate, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.AudioFormat&gt; inputAudioFormat, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.AudioFormat&gt; outputAudioFormat, class Azure.AI.VoiceLive.TurnDetection turnDetection, class Azure.AI.VoiceLive.AudioNoiseReduction inputAudioNoiseReduction, class Azure.AI.VoiceLive.AudioEchoCancellation inputAudioEchoCancellation, class Azure.AI.VoiceLive.AvatarConfiguration avatar, class Azure.AI.VoiceLive.AudioInputTranscriptionSettings inputAudioTranscription, class System.Collections.Generic.IEnumerable`1&lt;valuetype Azure.AI.VoiceLive.AudioTimestampType&gt; outputAudioTimestampTypes, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt; tools, valuetype System.Nullable`1&lt;float32&gt; temperature, class Azure.AI.VoiceLive.RespondingAgentOptions agent, class System.BinaryData voiceInternal, class System.BinaryData maxResponseOutputTokens, class System.BinaryData toolChoice, string id) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveSessionResponse(System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.InputModality},Azure.AI.VoiceLive.AnimationOptions,System.String,Azure.AI.VoiceLive.InputAudio,System.Nullable{System.Int32},System.Nullable{Azure.AI.VoiceLive.AudioFormat},System.Nullable{Azure.AI.VoiceLive.AudioFormat},Azure.AI.VoiceLive.TurnDetection,Azure.AI.VoiceLive.AudioNoiseReduction,Azure.AI.VoiceLive.AudioEchoCancellation,Azure.AI.VoiceLive.AvatarConfiguration,Azure.AI.VoiceLive.AudioInputTranscriptionSettings,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.AudioTimestampType},System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.VoiceLiveToolDefinition},System.Nullable{System.Single},Azure.AI.VoiceLive.RespondingAgentOptions,System.BinaryData,System.BinaryData,System.BinaryData,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VoiceLiveSessionResponse (Optional model As String = Nothing, Optional modalities As IEnumerable(Of InputModality) = Nothing, Optional animation As AnimationOptions = Nothing, Optional instructions As String = Nothing, Optional inputAudio As InputAudio = Nothing, Optional inputAudioSamplingRate As Nullable(Of Integer) = Nothing, Optional inputAudioFormat As Nullable(Of AudioFormat) = Nothing, Optional outputAudioFormat As Nullable(Of AudioFormat) = Nothing, Optional turnDetection As TurnDetection = Nothing, Optional inputAudioNoiseReduction As AudioNoiseReduction = Nothing, Optional inputAudioEchoCancellation As AudioEchoCancellation = Nothing, Optional avatar As AvatarConfiguration = Nothing, Optional inputAudioTranscription As AudioInputTranscriptionSettings = Nothing, Optional outputAudioTimestampTypes As IEnumerable(Of AudioTimestampType) = Nothing, Optional tools As IEnumerable(Of VoiceLiveToolDefinition) = Nothing, Optional temperature As Nullable(Of Single) = Nothing, Optional agent As RespondingAgentOptions = Nothing, Optional voiceInternal As BinaryData = Nothing, Optional maxResponseOutputTokens As BinaryData = Nothing, Optional toolChoice As BinaryData = Nothing, Optional id As String = Nothing) As VoiceLiveSessionResponse" />
      <MemberSignature Language="F#" Value="static member VoiceLiveSessionResponse : string * seq&lt;Azure.AI.VoiceLive.InputModality&gt; * Azure.AI.VoiceLive.AnimationOptions * string * Azure.AI.VoiceLive.InputAudio * Nullable&lt;int&gt; * Nullable&lt;Azure.AI.VoiceLive.AudioFormat&gt; * Nullable&lt;Azure.AI.VoiceLive.AudioFormat&gt; * Azure.AI.VoiceLive.TurnDetection * Azure.AI.VoiceLive.AudioNoiseReduction * Azure.AI.VoiceLive.AudioEchoCancellation * Azure.AI.VoiceLive.AvatarConfiguration * Azure.AI.VoiceLive.AudioInputTranscriptionSettings * seq&lt;Azure.AI.VoiceLive.AudioTimestampType&gt; * seq&lt;Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt; * Nullable&lt;single&gt; * Azure.AI.VoiceLive.RespondingAgentOptions * BinaryData * BinaryData * BinaryData * string -&gt; Azure.AI.VoiceLive.VoiceLiveSessionResponse" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveSessionResponse (model, modalities, animation, instructions, inputAudio, inputAudioSamplingRate, inputAudioFormat, outputAudioFormat, turnDetection, inputAudioNoiseReduction, inputAudioEchoCancellation, avatar, inputAudioTranscription, outputAudioTimestampTypes, tools, temperature, agent, voiceInternal, maxResponseOutputTokens, toolChoice, id)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VoiceLiveSessionResponse</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="model" Type="System.String" />
        <Parameter Name="modalities" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.InputModality&gt;" />
        <Parameter Name="animation" Type="Azure.AI.VoiceLive.AnimationOptions" />
        <Parameter Name="instructions" Type="System.String" />
        <Parameter Name="inputAudio" Type="Azure.AI.VoiceLive.InputAudio" />
        <Parameter Name="inputAudioSamplingRate" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="inputAudioFormat" Type="System.Nullable&lt;Azure.AI.VoiceLive.AudioFormat&gt;" />
        <Parameter Name="outputAudioFormat" Type="System.Nullable&lt;Azure.AI.VoiceLive.AudioFormat&gt;" />
        <Parameter Name="turnDetection" Type="Azure.AI.VoiceLive.TurnDetection" />
        <Parameter Name="inputAudioNoiseReduction" Type="Azure.AI.VoiceLive.AudioNoiseReduction" />
        <Parameter Name="inputAudioEchoCancellation" Type="Azure.AI.VoiceLive.AudioEchoCancellation" />
        <Parameter Name="avatar" Type="Azure.AI.VoiceLive.AvatarConfiguration" />
        <Parameter Name="inputAudioTranscription" Type="Azure.AI.VoiceLive.AudioInputTranscriptionSettings" />
        <Parameter Name="outputAudioTimestampTypes" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.AudioTimestampType&gt;" />
        <Parameter Name="tools" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt;" />
        <Parameter Name="temperature" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="agent" Type="Azure.AI.VoiceLive.RespondingAgentOptions" />
        <Parameter Name="voiceInternal" Type="System.BinaryData" />
        <Parameter Name="maxResponseOutputTokens" Type="System.BinaryData" />
        <Parameter Name="toolChoice" Type="System.BinaryData" />
        <Parameter Name="id" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="model" />
        <param name="modalities" />
        <param name="animation" />
        <param name="instructions" />
        <param name="inputAudio" />
        <param name="inputAudioSamplingRate" />
        <param name="inputAudioFormat" />
        <param name="outputAudioFormat" />
        <param name="turnDetection" />
        <param name="inputAudioNoiseReduction" />
        <param name="inputAudioEchoCancellation" />
        <param name="avatar" />
        <param name="inputAudioTranscription" />
        <param name="outputAudioTimestampTypes" />
        <param name="tools" />
        <param name="temperature" />
        <param name="agent" />
        <param name="voiceInternal" />
        <param name="maxResponseOutputTokens" />
        <param name="toolChoice" />
        <param name="id" />
        <summary> The VoiceLiveSessionResponse. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VoiceLiveSessionResponse" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VoiceLiveToolDefinition">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VoiceLiveToolDefinition VoiceLiveToolDefinition (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VoiceLiveToolDefinition VoiceLiveToolDefinition(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveToolDefinition(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VoiceLiveToolDefinition (Optional type As String = Nothing) As VoiceLiveToolDefinition" />
      <MemberSignature Language="F#" Value="static member VoiceLiveToolDefinition : string -&gt; Azure.AI.VoiceLive.VoiceLiveToolDefinition" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveToolDefinition type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VoiceLiveToolDefinition</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <summary>
            The base representation of a voicelive tool definition.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveFunctionDefinition(System.String,System.String,System.BinaryData)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VoiceLiveToolDefinition" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>
