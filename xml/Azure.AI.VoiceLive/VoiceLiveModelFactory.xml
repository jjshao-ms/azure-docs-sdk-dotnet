<Type Name="VoiceLiveModelFactory" FullName="Azure.AI.VoiceLive.VoiceLiveModelFactory">
  <TypeSignature Language="C#" Value="public static class VoiceLiveModelFactory" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi abstract sealed beforefieldinit VoiceLiveModelFactory extends System.Object" />
  <TypeSignature Language="DocId" Value="T:Azure.AI.VoiceLive.VoiceLiveModelFactory" />
  <TypeSignature Language="VB.NET" Value="Public Class VoiceLiveModelFactory" />
  <TypeSignature Language="F#" Value="type VoiceLiveModelFactory = class" />
  <AssemblyInfo>
    <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
    <AssemblyVersion>1.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary> A factory class for creating instances of the models for mocking. </summary>
    <remarks>To be added.</remarks>
  </Docs>
  <Members>
    <Member MemberName="AnimationOptions">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AnimationOptions AnimationOptions (string modelName = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.AnimationOutputType&gt; outputs = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AnimationOptions AnimationOptions(string modelName, class System.Collections.Generic.IEnumerable`1&lt;valuetype Azure.AI.VoiceLive.AnimationOutputType&gt; outputs) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AnimationOptions(System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.AnimationOutputType})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AnimationOptions (Optional modelName As String = Nothing, Optional outputs As IEnumerable(Of AnimationOutputType) = Nothing) As AnimationOptions" />
      <MemberSignature Language="F#" Value="static member AnimationOptions : string * seq&lt;Azure.AI.VoiceLive.AnimationOutputType&gt; -&gt; Azure.AI.VoiceLive.AnimationOptions" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AnimationOptions (modelName, outputs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AnimationOptions</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="modelName" Type="System.String" />
        <Parameter Name="outputs" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.AnimationOutputType&gt;" />
      </Parameters>
      <Docs>
        <param name="modelName"> The name of the animation model to use. </param>
        <param name="outputs"> Set of output data types requested from the animation system. </param>
        <summary> Configuration for animation outputs including blendshapes and visemes metadata. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AnimationOptions" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AssistantMessageItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AssistantMessageItem AssistantMessageItem (string id = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.MessageContentPart&gt; content = default, Azure.AI.VoiceLive.ItemParamStatus? status = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AssistantMessageItem AssistantMessageItem(string id, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.MessageContentPart&gt; content, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.ItemParamStatus&gt; status) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AssistantMessageItem(System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.MessageContentPart},System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AssistantMessageItem (Optional id As String = Nothing, Optional content As IEnumerable(Of MessageContentPart) = Nothing, Optional status As Nullable(Of ItemParamStatus) = Nothing) As AssistantMessageItem" />
      <MemberSignature Language="F#" Value="static member AssistantMessageItem : string * seq&lt;Azure.AI.VoiceLive.MessageContentPart&gt; * Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt; -&gt; Azure.AI.VoiceLive.AssistantMessageItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AssistantMessageItem (id, content, status)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AssistantMessageItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="content" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.MessageContentPart&gt;" />
        <Parameter Name="status" Type="System.Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt;" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="content"> The content parts of the message. </param>
        <param name="status"> Processing status of the message item. </param>
        <summary> An assistant message item within a conversation. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AssistantMessageItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioEchoCancellation">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AudioEchoCancellation AudioEchoCancellation (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AudioEchoCancellation AudioEchoCancellation(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AudioEchoCancellation(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AudioEchoCancellation (Optional type As String = Nothing) As AudioEchoCancellation" />
      <MemberSignature Language="F#" Value="static member AudioEchoCancellation : string -&gt; Azure.AI.VoiceLive.AudioEchoCancellation" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AudioEchoCancellation type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AudioEchoCancellation</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type"> The type of echo cancellation model to use. </param>
        <summary> Echo cancellation configuration for server-side audio processing. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AudioEchoCancellation" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioInputTranscriptionOptions">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AudioInputTranscriptionOptions AudioInputTranscriptionOptions (Azure.AI.VoiceLive.AudioInputTranscriptionOptionsModel model = default, string language = default, System.Collections.Generic.IDictionary&lt;string,string&gt; customSpeech = default, System.Collections.Generic.IEnumerable&lt;string&gt; phraseList = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AudioInputTranscriptionOptions AudioInputTranscriptionOptions(valuetype Azure.AI.VoiceLive.AudioInputTranscriptionOptionsModel model, string language, class System.Collections.Generic.IDictionary`2&lt;string, string&gt; customSpeech, class System.Collections.Generic.IEnumerable`1&lt;string&gt; phraseList) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AudioInputTranscriptionOptions(Azure.AI.VoiceLive.AudioInputTranscriptionOptionsModel,System.String,System.Collections.Generic.IDictionary{System.String,System.String},System.Collections.Generic.IEnumerable{System.String})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AudioInputTranscriptionOptions (Optional model As AudioInputTranscriptionOptionsModel = Nothing, Optional language As String = Nothing, Optional customSpeech As IDictionary(Of String, String) = Nothing, Optional phraseList As IEnumerable(Of String) = Nothing) As AudioInputTranscriptionOptions" />
      <MemberSignature Language="F#" Value="static member AudioInputTranscriptionOptions : Azure.AI.VoiceLive.AudioInputTranscriptionOptionsModel * string * System.Collections.Generic.IDictionary&lt;string, string&gt; * seq&lt;string&gt; -&gt; Azure.AI.VoiceLive.AudioInputTranscriptionOptions" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AudioInputTranscriptionOptions (model, language, customSpeech, phraseList)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AudioInputTranscriptionOptions</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="model" Type="Azure.AI.VoiceLive.AudioInputTranscriptionOptionsModel" />
        <Parameter Name="language" Type="System.String" />
        <Parameter Name="customSpeech" Type="System.Collections.Generic.IDictionary&lt;System.String,System.String&gt;" />
        <Parameter Name="phraseList" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
      </Parameters>
      <Docs>
        <param name="model">
            The transcription model to use. Supported values:
            'whisper-1', 'gpt-4o-transcribe', 'gpt-4o-mini-transcribe',
            'azure-speech'.
            </param>
        <param name="language"> Optional language code in BCP-47 (e.g., 'en-US'), or ISO-639-1 (e.g., 'en'), or multi languages with auto detection, (e.g., 'en,zh'). </param>
        <param name="customSpeech"> Optional configuration for custom speech models. </param>
        <param name="phraseList"> Optional list of phrase hints to bias recognition. </param>
        <summary> Configuration for input audio transcription. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AudioInputTranscriptionOptions" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioNoiseReduction">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AudioNoiseReduction AudioNoiseReduction (Azure.AI.VoiceLive.AudioNoiseReductionType type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AudioNoiseReduction AudioNoiseReduction(valuetype Azure.AI.VoiceLive.AudioNoiseReductionType type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AudioNoiseReduction(Azure.AI.VoiceLive.AudioNoiseReductionType)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AudioNoiseReduction (Optional type As AudioNoiseReductionType = Nothing) As AudioNoiseReduction" />
      <MemberSignature Language="F#" Value="static member AudioNoiseReduction : Azure.AI.VoiceLive.AudioNoiseReductionType -&gt; Azure.AI.VoiceLive.AudioNoiseReduction" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AudioNoiseReduction type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AudioNoiseReduction</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="Azure.AI.VoiceLive.AudioNoiseReductionType" />
      </Parameters>
      <Docs>
        <param name="type"> The type of noise reduction model. </param>
        <summary> Configuration for input audio noise reduction. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AudioNoiseReduction" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AvatarConfiguration">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AvatarConfiguration AvatarConfiguration (System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.IceServer&gt; iceServers = default, string character = default, string style = default, bool customized = false, Azure.AI.VoiceLive.VideoParams video = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AvatarConfiguration AvatarConfiguration(class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.IceServer&gt; iceServers, string character, string style, bool customized, class Azure.AI.VoiceLive.VideoParams video) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AvatarConfiguration(System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.IceServer},System.String,System.String,System.Boolean,Azure.AI.VoiceLive.VideoParams)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AvatarConfiguration (Optional iceServers As IEnumerable(Of IceServer) = Nothing, Optional character As String = Nothing, Optional style As String = Nothing, Optional customized As Boolean = false, Optional video As VideoParams = Nothing) As AvatarConfiguration" />
      <MemberSignature Language="F#" Value="static member AvatarConfiguration : seq&lt;Azure.AI.VoiceLive.IceServer&gt; * string * string * bool * Azure.AI.VoiceLive.VideoParams -&gt; Azure.AI.VoiceLive.AvatarConfiguration" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AvatarConfiguration (iceServers, character, style, customized, video)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AvatarConfiguration</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="iceServers" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.IceServer&gt;" />
        <Parameter Name="character" Type="System.String" />
        <Parameter Name="style" Type="System.String" />
        <Parameter Name="customized" Type="System.Boolean" />
        <Parameter Name="video" Type="Azure.AI.VoiceLive.VideoParams" />
      </Parameters>
      <Docs>
        <param name="iceServers"> Optional list of ICE servers to use for WebRTC connection establishment. </param>
        <param name="character"> The character name or ID used for the avatar. </param>
        <param name="style"> Optional avatar style, such as emotional tone or speaking style. </param>
        <param name="customized"> Indicates whether the avatar is customized or not. </param>
        <param name="video"> Optional video configuration including resolution, bitrate, and codec. </param>
        <summary> Configuration for avatar streaming and behavior during the session. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AvatarConfiguration" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureCustomVoice">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureCustomVoice AzureCustomVoice (string name = default, string endpointId = default, float? temperature = default, string customLexiconUri = default, System.Collections.Generic.IEnumerable&lt;string&gt; preferLocales = default, string locale = default, string style = default, string pitch = default, string rate = default, string volume = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureCustomVoice AzureCustomVoice(string name, string endpointId, valuetype System.Nullable`1&lt;float32&gt; temperature, string customLexiconUri, class System.Collections.Generic.IEnumerable`1&lt;string&gt; preferLocales, string locale, string style, string pitch, string rate, string volume) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureCustomVoice(System.String,System.String,System.Nullable{System.Single},System.String,System.Collections.Generic.IEnumerable{System.String},System.String,System.String,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureCustomVoice (Optional name As String = Nothing, Optional endpointId As String = Nothing, Optional temperature As Nullable(Of Single) = Nothing, Optional customLexiconUri As String = Nothing, Optional preferLocales As IEnumerable(Of String) = Nothing, Optional locale As String = Nothing, Optional style As String = Nothing, Optional pitch As String = Nothing, Optional rate As String = Nothing, Optional volume As String = Nothing) As AzureCustomVoice" />
      <MemberSignature Language="F#" Value="static member AzureCustomVoice : string * string * Nullable&lt;single&gt; * string * seq&lt;string&gt; * string * string * string * string * string -&gt; Azure.AI.VoiceLive.AzureCustomVoice" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureCustomVoice (name, endpointId, temperature, customLexiconUri, preferLocales, locale, style, pitch, rate, volume)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureCustomVoice</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="endpointId" Type="System.String" />
        <Parameter Name="temperature" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="customLexiconUri" Type="System.String" />
        <Parameter Name="preferLocales" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
        <Parameter Name="locale" Type="System.String" />
        <Parameter Name="style" Type="System.String" />
        <Parameter Name="pitch" Type="System.String" />
        <Parameter Name="rate" Type="System.String" />
        <Parameter Name="volume" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="name"> Voice name cannot be empty. </param>
        <param name="endpointId"> Endpoint ID cannot be empty. </param>
        <param name="temperature"> Temperature must be between 0.0 and 1.0. </param>
        <param name="customLexiconUri" />
        <param name="preferLocales" />
        <param name="locale" />
        <param name="style" />
        <param name="pitch" />
        <param name="rate" />
        <param name="volume" />
        <summary> Azure custom voice configuration. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureCustomVoice" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzurePersonalVoice">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzurePersonalVoice AzurePersonalVoice (string name = default, float? temperature = default, Azure.AI.VoiceLive.PersonalVoiceModels model = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzurePersonalVoice AzurePersonalVoice(string name, valuetype System.Nullable`1&lt;float32&gt; temperature, valuetype Azure.AI.VoiceLive.PersonalVoiceModels model) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzurePersonalVoice(System.String,System.Nullable{System.Single},Azure.AI.VoiceLive.PersonalVoiceModels)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzurePersonalVoice (Optional name As String = Nothing, Optional temperature As Nullable(Of Single) = Nothing, Optional model As PersonalVoiceModels = Nothing) As AzurePersonalVoice" />
      <MemberSignature Language="F#" Value="static member AzurePersonalVoice : string * Nullable&lt;single&gt; * Azure.AI.VoiceLive.PersonalVoiceModels -&gt; Azure.AI.VoiceLive.AzurePersonalVoice" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzurePersonalVoice (name, temperature, model)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzurePersonalVoice</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="temperature" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="model" Type="Azure.AI.VoiceLive.PersonalVoiceModels" />
      </Parameters>
      <Docs>
        <param name="name"> Voice name cannot be empty. </param>
        <param name="temperature"> Temperature must be between 0.0 and 1.0. </param>
        <param name="model"> Underlying neural model to use for personal voice. </param>
        <summary> Azure personal voice configuration. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzurePersonalVoice" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureSemanticEouDetection">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureSemanticEouDetection AzureSemanticEouDetection (Azure.AI.VoiceLive.EouThresholdLevel? thresholdLevel = default, float? timeoutMs = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureSemanticEouDetection AzureSemanticEouDetection(valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.EouThresholdLevel&gt; thresholdLevel, valuetype System.Nullable`1&lt;float32&gt; timeoutMs) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticEouDetection(System.Nullable{Azure.AI.VoiceLive.EouThresholdLevel},System.Nullable{System.Single})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureSemanticEouDetection (Optional thresholdLevel As Nullable(Of EouThresholdLevel) = Nothing, Optional timeoutMs As Nullable(Of Single) = Nothing) As AzureSemanticEouDetection" />
      <MemberSignature Language="F#" Value="static member AzureSemanticEouDetection : Nullable&lt;Azure.AI.VoiceLive.EouThresholdLevel&gt; * Nullable&lt;single&gt; -&gt; Azure.AI.VoiceLive.AzureSemanticEouDetection" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticEouDetection (thresholdLevel, timeoutMs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureSemanticEouDetection</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="thresholdLevel" Type="System.Nullable&lt;Azure.AI.VoiceLive.EouThresholdLevel&gt;" />
        <Parameter Name="timeoutMs" Type="System.Nullable&lt;System.Single&gt;" />
      </Parameters>
      <Docs>
        <param name="thresholdLevel"> Threshold level setting. Recommended instead of `threshold`. One of `low`, `medium`, `high`, or `default`. </param>
        <param name="timeoutMs"> Gets or sets the Timeout. </param>
        <summary> Azure semantic end-of-utterance detection (default). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureSemanticEouDetection" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureSemanticEouDetectionEn">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureSemanticEouDetectionEn AzureSemanticEouDetectionEn (Azure.AI.VoiceLive.EouThresholdLevel? thresholdLevel = default, float? timeoutMs = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureSemanticEouDetectionEn AzureSemanticEouDetectionEn(valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.EouThresholdLevel&gt; thresholdLevel, valuetype System.Nullable`1&lt;float32&gt; timeoutMs) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticEouDetectionEn(System.Nullable{Azure.AI.VoiceLive.EouThresholdLevel},System.Nullable{System.Single})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureSemanticEouDetectionEn (Optional thresholdLevel As Nullable(Of EouThresholdLevel) = Nothing, Optional timeoutMs As Nullable(Of Single) = Nothing) As AzureSemanticEouDetectionEn" />
      <MemberSignature Language="F#" Value="static member AzureSemanticEouDetectionEn : Nullable&lt;Azure.AI.VoiceLive.EouThresholdLevel&gt; * Nullable&lt;single&gt; -&gt; Azure.AI.VoiceLive.AzureSemanticEouDetectionEn" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticEouDetectionEn (thresholdLevel, timeoutMs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureSemanticEouDetectionEn</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="thresholdLevel" Type="System.Nullable&lt;Azure.AI.VoiceLive.EouThresholdLevel&gt;" />
        <Parameter Name="timeoutMs" Type="System.Nullable&lt;System.Single&gt;" />
      </Parameters>
      <Docs>
        <param name="thresholdLevel"> Threshold level setting. Recommended instead of `threshold`. One of `low`, `medium`, `high`, or `default`. </param>
        <param name="timeoutMs"> Gets or sets the Timeout. </param>
        <summary> Azure semantic end-of-utterance detection (English-optimized). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureSemanticEouDetectionEn" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureSemanticEouDetectionMultilingual">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureSemanticEouDetectionMultilingual AzureSemanticEouDetectionMultilingual (Azure.AI.VoiceLive.EouThresholdLevel? thresholdLevel = default, float? timeoutMs = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureSemanticEouDetectionMultilingual AzureSemanticEouDetectionMultilingual(valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.EouThresholdLevel&gt; thresholdLevel, valuetype System.Nullable`1&lt;float32&gt; timeoutMs) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticEouDetectionMultilingual(System.Nullable{Azure.AI.VoiceLive.EouThresholdLevel},System.Nullable{System.Single})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureSemanticEouDetectionMultilingual (Optional thresholdLevel As Nullable(Of EouThresholdLevel) = Nothing, Optional timeoutMs As Nullable(Of Single) = Nothing) As AzureSemanticEouDetectionMultilingual" />
      <MemberSignature Language="F#" Value="static member AzureSemanticEouDetectionMultilingual : Nullable&lt;Azure.AI.VoiceLive.EouThresholdLevel&gt; * Nullable&lt;single&gt; -&gt; Azure.AI.VoiceLive.AzureSemanticEouDetectionMultilingual" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticEouDetectionMultilingual (thresholdLevel, timeoutMs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureSemanticEouDetectionMultilingual</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="thresholdLevel" Type="System.Nullable&lt;Azure.AI.VoiceLive.EouThresholdLevel&gt;" />
        <Parameter Name="timeoutMs" Type="System.Nullable&lt;System.Single&gt;" />
      </Parameters>
      <Docs>
        <param name="thresholdLevel"> Threshold level setting. Recommended instead of `threshold`. One of `low`, `medium`, `high`, or `default`. </param>
        <param name="timeoutMs"> Gets or sets the Timeout. </param>
        <summary> Azure semantic end-of-utterance detection (multilingual). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureSemanticEouDetectionMultilingual" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureSemanticVadTurnDetection">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureSemanticVadTurnDetection AzureSemanticVadTurnDetection (float? threshold = default, int? prefixPaddingMs = default, int? silenceDurationMs = default, Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection = default, int? speechDurationMs = default, bool? removeFillerWords = default, System.Collections.Generic.IEnumerable&lt;string&gt; languages = default, bool? autoTruncate = default, bool? createResponse = default, bool? interruptResponse = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureSemanticVadTurnDetection AzureSemanticVadTurnDetection(valuetype System.Nullable`1&lt;float32&gt; threshold, valuetype System.Nullable`1&lt;int32&gt; prefixPaddingMs, valuetype System.Nullable`1&lt;int32&gt; silenceDurationMs, class Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection, valuetype System.Nullable`1&lt;int32&gt; speechDurationMs, valuetype System.Nullable`1&lt;bool&gt; removeFillerWords, class System.Collections.Generic.IEnumerable`1&lt;string&gt; languages, valuetype System.Nullable`1&lt;bool&gt; autoTruncate, valuetype System.Nullable`1&lt;bool&gt; createResponse, valuetype System.Nullable`1&lt;bool&gt; interruptResponse) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadTurnDetection(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureSemanticVadTurnDetection (Optional threshold As Nullable(Of Single) = Nothing, Optional prefixPaddingMs As Nullable(Of Integer) = Nothing, Optional silenceDurationMs As Nullable(Of Integer) = Nothing, Optional endOfUtteranceDetection As EouDetection = Nothing, Optional speechDurationMs As Nullable(Of Integer) = Nothing, Optional removeFillerWords As Nullable(Of Boolean) = Nothing, Optional languages As IEnumerable(Of String) = Nothing, Optional autoTruncate As Nullable(Of Boolean) = Nothing, Optional createResponse As Nullable(Of Boolean) = Nothing, Optional interruptResponse As Nullable(Of Boolean) = Nothing) As AzureSemanticVadTurnDetection" />
      <MemberSignature Language="F#" Value="static member AzureSemanticVadTurnDetection : Nullable&lt;single&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Azure.AI.VoiceLive.EouDetection * Nullable&lt;int&gt; * Nullable&lt;bool&gt; * seq&lt;string&gt; * Nullable&lt;bool&gt; * Nullable&lt;bool&gt; * Nullable&lt;bool&gt; -&gt; Azure.AI.VoiceLive.AzureSemanticVadTurnDetection" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadTurnDetection (threshold, prefixPaddingMs, silenceDurationMs, endOfUtteranceDetection, speechDurationMs, removeFillerWords, languages, autoTruncate, createResponse, interruptResponse)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureSemanticVadTurnDetection</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="threshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="prefixPaddingMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="silenceDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="endOfUtteranceDetection" Type="Azure.AI.VoiceLive.EouDetection" />
        <Parameter Name="speechDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="removeFillerWords" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="languages" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
        <Parameter Name="autoTruncate" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="createResponse" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="interruptResponse" Type="System.Nullable&lt;System.Boolean&gt;" />
      </Parameters>
      <Docs>
        <param name="threshold" />
        <param name="prefixPaddingMs"> Gets or sets the PrefixPaddingMs. </param>
        <param name="silenceDurationMs"> Gets or sets the SilenceDurationMs. </param>
        <param name="endOfUtteranceDetection" />
        <param name="speechDurationMs"> Gets or sets the SpeechDurationMs. </param>
        <param name="removeFillerWords" />
        <param name="languages" />
        <param name="autoTruncate" />
        <param name="createResponse" />
        <param name="interruptResponse" />
        <summary> Server Speech Detection (Azure semantic VAD, default variant). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureSemanticVadTurnDetection" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureSemanticVadTurnDetectionEn">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureSemanticVadTurnDetectionEn AzureSemanticVadTurnDetectionEn (float? threshold = default, int? prefixPaddingMs = default, int? silenceDurationMs = default, Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection = default, int? speechDurationMs = default, bool? removeFillerWords = default, bool? autoTruncate = default, bool? createResponse = default, bool? interruptResponse = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureSemanticVadTurnDetectionEn AzureSemanticVadTurnDetectionEn(valuetype System.Nullable`1&lt;float32&gt; threshold, valuetype System.Nullable`1&lt;int32&gt; prefixPaddingMs, valuetype System.Nullable`1&lt;int32&gt; silenceDurationMs, class Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection, valuetype System.Nullable`1&lt;int32&gt; speechDurationMs, valuetype System.Nullable`1&lt;bool&gt; removeFillerWords, valuetype System.Nullable`1&lt;bool&gt; autoTruncate, valuetype System.Nullable`1&lt;bool&gt; createResponse, valuetype System.Nullable`1&lt;bool&gt; interruptResponse) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadTurnDetectionEn(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureSemanticVadTurnDetectionEn (Optional threshold As Nullable(Of Single) = Nothing, Optional prefixPaddingMs As Nullable(Of Integer) = Nothing, Optional silenceDurationMs As Nullable(Of Integer) = Nothing, Optional endOfUtteranceDetection As EouDetection = Nothing, Optional speechDurationMs As Nullable(Of Integer) = Nothing, Optional removeFillerWords As Nullable(Of Boolean) = Nothing, Optional autoTruncate As Nullable(Of Boolean) = Nothing, Optional createResponse As Nullable(Of Boolean) = Nothing, Optional interruptResponse As Nullable(Of Boolean) = Nothing) As AzureSemanticVadTurnDetectionEn" />
      <MemberSignature Language="F#" Value="static member AzureSemanticVadTurnDetectionEn : Nullable&lt;single&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Azure.AI.VoiceLive.EouDetection * Nullable&lt;int&gt; * Nullable&lt;bool&gt; * Nullable&lt;bool&gt; * Nullable&lt;bool&gt; * Nullable&lt;bool&gt; -&gt; Azure.AI.VoiceLive.AzureSemanticVadTurnDetectionEn" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadTurnDetectionEn (threshold, prefixPaddingMs, silenceDurationMs, endOfUtteranceDetection, speechDurationMs, removeFillerWords, autoTruncate, createResponse, interruptResponse)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureSemanticVadTurnDetectionEn</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="threshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="prefixPaddingMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="silenceDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="endOfUtteranceDetection" Type="Azure.AI.VoiceLive.EouDetection" />
        <Parameter Name="speechDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="removeFillerWords" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="autoTruncate" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="createResponse" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="interruptResponse" Type="System.Nullable&lt;System.Boolean&gt;" />
      </Parameters>
      <Docs>
        <param name="threshold" />
        <param name="prefixPaddingMs"> Gets or sets the PrefixPaddingMs. </param>
        <param name="silenceDurationMs"> Gets or sets the SilenceDurationMs. </param>
        <param name="endOfUtteranceDetection" />
        <param name="speechDurationMs"> Gets or sets the SpeechDurationMs. </param>
        <param name="removeFillerWords" />
        <param name="autoTruncate" />
        <param name="createResponse" />
        <param name="interruptResponse" />
        <summary> Server Speech Detection (Azure semantic VAD, English-only). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureSemanticVadTurnDetectionEn" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureSemanticVadTurnDetectionMultilingual">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureSemanticVadTurnDetectionMultilingual AzureSemanticVadTurnDetectionMultilingual (float? threshold = default, int? prefixPaddingMs = default, int? silenceDurationMs = default, Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection = default, int? speechDurationMs = default, bool? removeFillerWords = default, System.Collections.Generic.IEnumerable&lt;string&gt; languages = default, bool? autoTruncate = default, bool? createResponse = default, bool? interruptResponse = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureSemanticVadTurnDetectionMultilingual AzureSemanticVadTurnDetectionMultilingual(valuetype System.Nullable`1&lt;float32&gt; threshold, valuetype System.Nullable`1&lt;int32&gt; prefixPaddingMs, valuetype System.Nullable`1&lt;int32&gt; silenceDurationMs, class Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection, valuetype System.Nullable`1&lt;int32&gt; speechDurationMs, valuetype System.Nullable`1&lt;bool&gt; removeFillerWords, class System.Collections.Generic.IEnumerable`1&lt;string&gt; languages, valuetype System.Nullable`1&lt;bool&gt; autoTruncate, valuetype System.Nullable`1&lt;bool&gt; createResponse, valuetype System.Nullable`1&lt;bool&gt; interruptResponse) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadTurnDetectionMultilingual(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureSemanticVadTurnDetectionMultilingual (Optional threshold As Nullable(Of Single) = Nothing, Optional prefixPaddingMs As Nullable(Of Integer) = Nothing, Optional silenceDurationMs As Nullable(Of Integer) = Nothing, Optional endOfUtteranceDetection As EouDetection = Nothing, Optional speechDurationMs As Nullable(Of Integer) = Nothing, Optional removeFillerWords As Nullable(Of Boolean) = Nothing, Optional languages As IEnumerable(Of String) = Nothing, Optional autoTruncate As Nullable(Of Boolean) = Nothing, Optional createResponse As Nullable(Of Boolean) = Nothing, Optional interruptResponse As Nullable(Of Boolean) = Nothing) As AzureSemanticVadTurnDetectionMultilingual" />
      <MemberSignature Language="F#" Value="static member AzureSemanticVadTurnDetectionMultilingual : Nullable&lt;single&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Azure.AI.VoiceLive.EouDetection * Nullable&lt;int&gt; * Nullable&lt;bool&gt; * seq&lt;string&gt; * Nullable&lt;bool&gt; * Nullable&lt;bool&gt; * Nullable&lt;bool&gt; -&gt; Azure.AI.VoiceLive.AzureSemanticVadTurnDetectionMultilingual" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadTurnDetectionMultilingual (threshold, prefixPaddingMs, silenceDurationMs, endOfUtteranceDetection, speechDurationMs, removeFillerWords, languages, autoTruncate, createResponse, interruptResponse)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureSemanticVadTurnDetectionMultilingual</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="threshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="prefixPaddingMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="silenceDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="endOfUtteranceDetection" Type="Azure.AI.VoiceLive.EouDetection" />
        <Parameter Name="speechDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="removeFillerWords" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="languages" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
        <Parameter Name="autoTruncate" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="createResponse" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="interruptResponse" Type="System.Nullable&lt;System.Boolean&gt;" />
      </Parameters>
      <Docs>
        <param name="threshold" />
        <param name="prefixPaddingMs"> Gets or sets the PrefixPaddingMs. </param>
        <param name="silenceDurationMs"> Gets or sets the SilenceDurationMs. </param>
        <param name="endOfUtteranceDetection" />
        <param name="speechDurationMs"> Gets or sets the SpeechDurationMs. </param>
        <param name="removeFillerWords" />
        <param name="languages" />
        <param name="autoTruncate" />
        <param name="createResponse" />
        <param name="interruptResponse" />
        <summary> Server Speech Detection (Azure semantic VAD). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureSemanticVadTurnDetectionMultilingual" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureStandardVoice">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureStandardVoice AzureStandardVoice (string name = default, float? temperature = default, string customLexiconUrl = default, System.Collections.Generic.IEnumerable&lt;string&gt; preferLocales = default, string locale = default, string style = default, string pitch = default, string rate = default, string volume = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureStandardVoice AzureStandardVoice(string name, valuetype System.Nullable`1&lt;float32&gt; temperature, string customLexiconUrl, class System.Collections.Generic.IEnumerable`1&lt;string&gt; preferLocales, string locale, string style, string pitch, string rate, string volume) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureStandardVoice(System.String,System.Nullable{System.Single},System.String,System.Collections.Generic.IEnumerable{System.String},System.String,System.String,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureStandardVoice (Optional name As String = Nothing, Optional temperature As Nullable(Of Single) = Nothing, Optional customLexiconUrl As String = Nothing, Optional preferLocales As IEnumerable(Of String) = Nothing, Optional locale As String = Nothing, Optional style As String = Nothing, Optional pitch As String = Nothing, Optional rate As String = Nothing, Optional volume As String = Nothing) As AzureStandardVoice" />
      <MemberSignature Language="F#" Value="static member AzureStandardVoice : string * Nullable&lt;single&gt; * string * seq&lt;string&gt; * string * string * string * string * string -&gt; Azure.AI.VoiceLive.AzureStandardVoice" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureStandardVoice (name, temperature, customLexiconUrl, preferLocales, locale, style, pitch, rate, volume)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureStandardVoice</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="temperature" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="customLexiconUrl" Type="System.String" />
        <Parameter Name="preferLocales" Type="System.Collections.Generic.IEnumerable&lt;System.String&gt;" />
        <Parameter Name="locale" Type="System.String" />
        <Parameter Name="style" Type="System.String" />
        <Parameter Name="pitch" Type="System.String" />
        <Parameter Name="rate" Type="System.String" />
        <Parameter Name="volume" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="name"> Voice name cannot be empty. </param>
        <param name="temperature"> Temperature must be between 0.0 and 1.0. </param>
        <param name="customLexiconUrl" />
        <param name="preferLocales" />
        <param name="locale" />
        <param name="style" />
        <param name="pitch" />
        <param name="rate" />
        <param name="volume" />
        <summary> Azure standard voice configuration. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureStandardVoice" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AzureVoice">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.AzureVoice AzureVoice (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.AzureVoice AzureVoice(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureVoice(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function AzureVoice (Optional type As String = Nothing) As AzureVoice" />
      <MemberSignature Language="F#" Value="static member AzureVoice : string -&gt; Azure.AI.VoiceLive.AzureVoice" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureVoice type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.AzureVoice</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type"> The type of the Azure voice. </param>
        <summary>
            Base for Azure voice configurations.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureCustomVoice(System.String,System.String,System.Nullable{System.Single},System.String,System.Collections.Generic.IEnumerable{System.String},System.String,System.String,System.String,System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureStandardVoice(System.String,System.Nullable{System.Single},System.String,System.Collections.Generic.IEnumerable{System.String},System.String,System.String,System.String,System.String,System.String)" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzurePersonalVoice(System.String,System.Nullable{System.Single},Azure.AI.VoiceLive.PersonalVoiceModels)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.AzureVoice" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="CachedTokenDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.CachedTokenDetails CachedTokenDetails (int textTokens = 0, int audioTokens = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.CachedTokenDetails CachedTokenDetails(int32 textTokens, int32 audioTokens) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.CachedTokenDetails(System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function CachedTokenDetails (Optional textTokens As Integer = 0, Optional audioTokens As Integer = 0) As CachedTokenDetails" />
      <MemberSignature Language="F#" Value="static member CachedTokenDetails : int * int -&gt; Azure.AI.VoiceLive.CachedTokenDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.CachedTokenDetails (textTokens, audioTokens)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.CachedTokenDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textTokens" Type="System.Int32" />
        <Parameter Name="audioTokens" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="textTokens"> Number of cached text tokens. </param>
        <param name="audioTokens"> Number of cached audio tokens. </param>
        <summary> Details of output token usage. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.CachedTokenDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ConversationRequestItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ConversationRequestItem ConversationRequestItem (string type = default, string id = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ConversationRequestItem ConversationRequestItem(string type, string id) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ConversationRequestItem(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ConversationRequestItem (Optional type As String = Nothing, Optional id As String = Nothing) As ConversationRequestItem" />
      <MemberSignature Language="F#" Value="static member ConversationRequestItem : string * string -&gt; Azure.AI.VoiceLive.ConversationRequestItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ConversationRequestItem (type, id)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ConversationRequestItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="id" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <param name="id" />
        <summary>
            Base for any response item; discriminated by `type`.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.MessageItem(System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.MessageContentPart},System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.FunctionCallItem(System.String,System.String,System.String,System.String,System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.FunctionCallOutputItem(System.String,System.String,System.String,System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ConversationRequestItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="EouDetection">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.EouDetection EouDetection (string model = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.EouDetection EouDetection(string model) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.EouDetection(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function EouDetection (Optional model As String = Nothing) As EouDetection" />
      <MemberSignature Language="F#" Value="static member EouDetection : string -&gt; Azure.AI.VoiceLive.EouDetection" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.EouDetection model" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.EouDetection</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="model" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="model" />
        <summary>
            Top-level union for end-of-utterance (EOU) semantic detection configuration.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticEouDetection(System.Nullable{Azure.AI.VoiceLive.EouThresholdLevel},System.Nullable{System.Single})" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticEouDetectionEn(System.Nullable{Azure.AI.VoiceLive.EouThresholdLevel},System.Nullable{System.Single})" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticEouDetectionMultilingual(System.Nullable{Azure.AI.VoiceLive.EouThresholdLevel},System.Nullable{System.Single})" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.EouDetection" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="FunctionCallItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.FunctionCallItem FunctionCallItem (string id = default, string name = default, string callId = default, string arguments = default, Azure.AI.VoiceLive.ItemParamStatus? status = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.FunctionCallItem FunctionCallItem(string id, string name, string callId, string arguments, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.ItemParamStatus&gt; status) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.FunctionCallItem(System.String,System.String,System.String,System.String,System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function FunctionCallItem (Optional id As String = Nothing, Optional name As String = Nothing, Optional callId As String = Nothing, Optional arguments As String = Nothing, Optional status As Nullable(Of ItemParamStatus) = Nothing) As FunctionCallItem" />
      <MemberSignature Language="F#" Value="static member FunctionCallItem : string * string * string * string * Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt; -&gt; Azure.AI.VoiceLive.FunctionCallItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.FunctionCallItem (id, name, callId, arguments, status)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.FunctionCallItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="callId" Type="System.String" />
        <Parameter Name="arguments" Type="System.String" />
        <Parameter Name="status" Type="System.Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt;" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="name" />
        <param name="callId" />
        <param name="arguments" />
        <param name="status" />
        <summary> A function call item within a conversation. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.FunctionCallItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="FunctionCallOutputItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.FunctionCallOutputItem FunctionCallOutputItem (string id = default, string callId = default, string output = default, Azure.AI.VoiceLive.ItemParamStatus? status = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.FunctionCallOutputItem FunctionCallOutputItem(string id, string callId, string output, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.ItemParamStatus&gt; status) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.FunctionCallOutputItem(System.String,System.String,System.String,System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function FunctionCallOutputItem (Optional id As String = Nothing, Optional callId As String = Nothing, Optional output As String = Nothing, Optional status As Nullable(Of ItemParamStatus) = Nothing) As FunctionCallOutputItem" />
      <MemberSignature Language="F#" Value="static member FunctionCallOutputItem : string * string * string * Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt; -&gt; Azure.AI.VoiceLive.FunctionCallOutputItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.FunctionCallOutputItem (id, callId, output, status)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.FunctionCallOutputItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="callId" Type="System.String" />
        <Parameter Name="output" Type="System.String" />
        <Parameter Name="status" Type="System.Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt;" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="callId" />
        <param name="output" />
        <param name="status" />
        <summary> A function call output item within a conversation. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.FunctionCallOutputItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="IceServer">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.IceServer IceServer (System.Collections.Generic.IEnumerable&lt;Uri&gt; uris = default, string username = default, string credential = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.IceServer IceServer(class System.Collections.Generic.IEnumerable`1&lt;class System.Uri&gt; uris, string username, string credential) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.IceServer(System.Collections.Generic.IEnumerable{System.Uri},System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function IceServer (Optional uris As IEnumerable(Of Uri) = Nothing, Optional username As String = Nothing, Optional credential As String = Nothing) As IceServer" />
      <MemberSignature Language="F#" Value="static member IceServer : seq&lt;Uri&gt; * string * string -&gt; Azure.AI.VoiceLive.IceServer" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.IceServer (uris, username, credential)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.IceServer</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="uris" Type="System.Collections.Generic.IEnumerable&lt;System.Uri&gt;" />
        <Parameter Name="username" Type="System.String" />
        <Parameter Name="credential" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="uris"> List of ICE server URLs (e.g., TURN or STUN endpoints). </param>
        <param name="username"> Optional username used for authentication with the ICE server. </param>
        <param name="credential"> Optional credential (e.g., password or token) used for authentication. </param>
        <summary> ICE server configuration for WebRTC connection negotiation. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.IceServer" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="InputAudioContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.InputAudioContentPart InputAudioContentPart (string audio = default, string transcript = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.InputAudioContentPart InputAudioContentPart(string audio, string transcript) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.InputAudioContentPart(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function InputAudioContentPart (Optional audio As String = Nothing, Optional transcript As String = Nothing) As InputAudioContentPart" />
      <MemberSignature Language="F#" Value="static member InputAudioContentPart : string * string -&gt; Azure.AI.VoiceLive.InputAudioContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.InputAudioContentPart (audio, transcript)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.InputAudioContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="audio" Type="System.String" />
        <Parameter Name="transcript" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="audio" />
        <param name="transcript" />
        <summary> Input audio content part. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.InputAudioContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="InputTextContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.InputTextContentPart InputTextContentPart (string text = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.InputTextContentPart InputTextContentPart(string text) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.InputTextContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function InputTextContentPart (Optional text As String = Nothing) As InputTextContentPart" />
      <MemberSignature Language="F#" Value="static member InputTextContentPart : string -&gt; Azure.AI.VoiceLive.InputTextContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.InputTextContentPart text" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.InputTextContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="text" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="text" />
        <summary> Input text content part. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.InputTextContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="InputTokenDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.InputTokenDetails InputTokenDetails (int cachedTokens = 0, int textTokens = 0, int audioTokens = 0, Azure.AI.VoiceLive.CachedTokenDetails cachedTokensDetails = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.InputTokenDetails InputTokenDetails(int32 cachedTokens, int32 textTokens, int32 audioTokens, class Azure.AI.VoiceLive.CachedTokenDetails cachedTokensDetails) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.InputTokenDetails(System.Int32,System.Int32,System.Int32,Azure.AI.VoiceLive.CachedTokenDetails)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function InputTokenDetails (Optional cachedTokens As Integer = 0, Optional textTokens As Integer = 0, Optional audioTokens As Integer = 0, Optional cachedTokensDetails As CachedTokenDetails = Nothing) As InputTokenDetails" />
      <MemberSignature Language="F#" Value="static member InputTokenDetails : int * int * int * Azure.AI.VoiceLive.CachedTokenDetails -&gt; Azure.AI.VoiceLive.InputTokenDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.InputTokenDetails (cachedTokens, textTokens, audioTokens, cachedTokensDetails)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.InputTokenDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="cachedTokens" Type="System.Int32" />
        <Parameter Name="textTokens" Type="System.Int32" />
        <Parameter Name="audioTokens" Type="System.Int32" />
        <Parameter Name="cachedTokensDetails" Type="Azure.AI.VoiceLive.CachedTokenDetails" />
      </Parameters>
      <Docs>
        <param name="cachedTokens"> Number of cached tokens used in the input. </param>
        <param name="textTokens"> Number of text tokens used in the input. </param>
        <param name="audioTokens"> Number of audio tokens used in the input. </param>
        <param name="cachedTokensDetails"> Details of cached token usage. </param>
        <summary> Details of input token usage. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.InputTokenDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="LogProbProperties">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.LogProbProperties LogProbProperties (string token = default, float logprob = 0, BinaryData bytes = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.LogProbProperties LogProbProperties(string token, float32 logprob, class System.BinaryData bytes) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.LogProbProperties(System.String,System.Single,System.BinaryData)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function LogProbProperties (Optional token As String = Nothing, Optional logprob As Single = 0, Optional bytes As BinaryData = Nothing) As LogProbProperties" />
      <MemberSignature Language="F#" Value="static member LogProbProperties : string * single * BinaryData -&gt; Azure.AI.VoiceLive.LogProbProperties" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.LogProbProperties (token, logprob, bytes)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.LogProbProperties</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="token" Type="System.String" />
        <Parameter Name="logprob" Type="System.Single" />
        <Parameter Name="bytes" Type="System.BinaryData" />
      </Parameters>
      <Docs>
        <param name="token"> The token that was used to generate the log probability. </param>
        <param name="logprob"> The log probability of the token. </param>
        <param name="bytes"> The bytes that were used to generate the log probability. </param>
        <summary> A single log probability entry for a token. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.LogProbProperties" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="MessageContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.MessageContentPart MessageContentPart (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.MessageContentPart MessageContentPart(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.MessageContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function MessageContentPart (Optional type As String = Nothing) As MessageContentPart" />
      <MemberSignature Language="F#" Value="static member MessageContentPart : string -&gt; Azure.AI.VoiceLive.MessageContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.MessageContentPart type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.MessageContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type"> The type of the content part. </param>
        <summary>
            Base for any message content part; discriminated by `type`.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.InputTextContentPart(System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.InputAudioContentPart(System.String,System.String)" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.OutputTextContentPart(System.String)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.MessageContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="MessageItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.MessageItem MessageItem (string id = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.MessageContentPart&gt; content = default, Azure.AI.VoiceLive.ItemParamStatus? status = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.MessageItem MessageItem(string id, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.MessageContentPart&gt; content, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.ItemParamStatus&gt; status) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.MessageItem(System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.MessageContentPart},System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function MessageItem (Optional id As String = Nothing, Optional content As IEnumerable(Of MessageContentPart) = Nothing, Optional status As Nullable(Of ItemParamStatus) = Nothing) As MessageItem" />
      <MemberSignature Language="F#" Value="static member MessageItem : string * seq&lt;Azure.AI.VoiceLive.MessageContentPart&gt; * Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt; -&gt; Azure.AI.VoiceLive.MessageItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.MessageItem (id, content, status)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.MessageItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="content" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.MessageContentPart&gt;" />
        <Parameter Name="status" Type="System.Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt;" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="content"> The content parts of the message. </param>
        <param name="status"> Processing status of the message item. </param>
        <summary> A message item within a conversation. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.MessageItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="OpenAIVoice">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.OpenAIVoice OpenAIVoice (string type = default, Azure.AI.VoiceLive.OAIVoice name = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.OpenAIVoice OpenAIVoice(string type, valuetype Azure.AI.VoiceLive.OAIVoice name) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.OpenAIVoice(System.String,Azure.AI.VoiceLive.OAIVoice)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function OpenAIVoice (Optional type As String = Nothing, Optional name As OAIVoice = Nothing) As OpenAIVoice" />
      <MemberSignature Language="F#" Value="static member OpenAIVoice : string * Azure.AI.VoiceLive.OAIVoice -&gt; Azure.AI.VoiceLive.OpenAIVoice" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.OpenAIVoice (type, name)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.OpenAIVoice</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="name" Type="Azure.AI.VoiceLive.OAIVoice" />
      </Parameters>
      <Docs>
        <param name="type"> The type of the voice. </param>
        <param name="name"> The name of the OpenAI voice. </param>
        <summary>
            OpenAI voice configuration with explicit type field.
            
            This provides a unified interface for OpenAI voices, complementing the
            existing string-based OAIVoice for backward compatibility.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.OpenAIVoice" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="OutputTextContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.OutputTextContentPart OutputTextContentPart (string text = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.OutputTextContentPart OutputTextContentPart(string text) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.OutputTextContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function OutputTextContentPart (Optional text As String = Nothing) As OutputTextContentPart" />
      <MemberSignature Language="F#" Value="static member OutputTextContentPart : string -&gt; Azure.AI.VoiceLive.OutputTextContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.OutputTextContentPart text" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.OutputTextContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="text" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="text"> The text content. </param>
        <summary> Output text content part. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.OutputTextContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="OutputTokenDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.OutputTokenDetails OutputTokenDetails (int textTokens = 0, int audioTokens = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.OutputTokenDetails OutputTokenDetails(int32 textTokens, int32 audioTokens) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.OutputTokenDetails(System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function OutputTokenDetails (Optional textTokens As Integer = 0, Optional audioTokens As Integer = 0) As OutputTokenDetails" />
      <MemberSignature Language="F#" Value="static member OutputTokenDetails : int * int -&gt; Azure.AI.VoiceLive.OutputTokenDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.OutputTokenDetails (textTokens, audioTokens)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.OutputTokenDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="textTokens" Type="System.Int32" />
        <Parameter Name="audioTokens" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="textTokens"> Number of text tokens generated in the output. </param>
        <param name="audioTokens"> Number of audio tokens generated in the output. </param>
        <summary> Details of output token usage. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.OutputTokenDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="RequestAudioContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.RequestAudioContentPart RequestAudioContentPart (string transcript = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.RequestAudioContentPart RequestAudioContentPart(string transcript) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.RequestAudioContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function RequestAudioContentPart (Optional transcript As String = Nothing) As RequestAudioContentPart" />
      <MemberSignature Language="F#" Value="static member RequestAudioContentPart : string -&gt; Azure.AI.VoiceLive.RequestAudioContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.RequestAudioContentPart transcript" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.RequestAudioContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="transcript" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="transcript" />
        <summary> An audio content part for a request. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.RequestAudioContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="RequestTextContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.RequestTextContentPart RequestTextContentPart (string text = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.RequestTextContentPart RequestTextContentPart(string text) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.RequestTextContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function RequestTextContentPart (Optional text As String = Nothing) As RequestTextContentPart" />
      <MemberSignature Language="F#" Value="static member RequestTextContentPart : string -&gt; Azure.AI.VoiceLive.RequestTextContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.RequestTextContentPart text" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.RequestTextContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="text" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="text" />
        <summary> A text content part for a request. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.RequestTextContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="RespondingAgentOptions">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.RespondingAgentOptions RespondingAgentOptions (string type = default, string name = default, string description = default, string agentId = default, string threadId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.RespondingAgentOptions RespondingAgentOptions(string type, string name, string description, string agentId, string threadId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.RespondingAgentOptions(System.String,System.String,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function RespondingAgentOptions (Optional type As String = Nothing, Optional name As String = Nothing, Optional description As String = Nothing, Optional agentId As String = Nothing, Optional threadId As String = Nothing) As RespondingAgentOptions" />
      <MemberSignature Language="F#" Value="static member RespondingAgentOptions : string * string * string * string * string -&gt; Azure.AI.VoiceLive.RespondingAgentOptions" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.RespondingAgentOptions (type, name, description, agentId, threadId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.RespondingAgentOptions</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="description" Type="System.String" />
        <Parameter Name="agentId" Type="System.String" />
        <Parameter Name="threadId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type"> The type of agent to use. </param>
        <param name="name"> The name of the agent. </param>
        <param name="description"> Optional description of the agent. </param>
        <param name="agentId"> The ID of the agent. </param>
        <param name="threadId"> The ID of the conversation thread. </param>
        <summary> Configuration for the agent. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.RespondingAgentOptions" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseAudioContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseAudioContentPart ResponseAudioContentPart (string transcript = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseAudioContentPart ResponseAudioContentPart(string transcript) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseAudioContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseAudioContentPart (Optional transcript As String = Nothing) As ResponseAudioContentPart" />
      <MemberSignature Language="F#" Value="static member ResponseAudioContentPart : string -&gt; Azure.AI.VoiceLive.ResponseAudioContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseAudioContentPart transcript" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseAudioContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="transcript" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="transcript" />
        <summary> An audio content part for a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseAudioContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseCancelledDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseCancelledDetails ResponseCancelledDetails (Azure.AI.VoiceLive.ResponseCancelledDetailsReason reason = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseCancelledDetails ResponseCancelledDetails(valuetype Azure.AI.VoiceLive.ResponseCancelledDetailsReason reason) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseCancelledDetails(Azure.AI.VoiceLive.ResponseCancelledDetailsReason)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseCancelledDetails (Optional reason As ResponseCancelledDetailsReason = Nothing) As ResponseCancelledDetails" />
      <MemberSignature Language="F#" Value="static member ResponseCancelledDetails : Azure.AI.VoiceLive.ResponseCancelledDetailsReason -&gt; Azure.AI.VoiceLive.ResponseCancelledDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseCancelledDetails reason" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseCancelledDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="reason" Type="Azure.AI.VoiceLive.ResponseCancelledDetailsReason" />
      </Parameters>
      <Docs>
        <param name="reason" />
        <summary> Details for a cancelled response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseCancelledDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseFailedDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseFailedDetails ResponseFailedDetails (BinaryData error = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseFailedDetails ResponseFailedDetails(class System.BinaryData error) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFailedDetails(System.BinaryData)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseFailedDetails (Optional error As BinaryData = Nothing) As ResponseFailedDetails" />
      <MemberSignature Language="F#" Value="static member ResponseFailedDetails : BinaryData -&gt; Azure.AI.VoiceLive.ResponseFailedDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFailedDetails error" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseFailedDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="error" Type="System.BinaryData" />
      </Parameters>
      <Docs>
        <param name="error" />
        <summary> Details for a failed response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseFailedDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseFunctionCallItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseFunctionCallItem ResponseFunctionCallItem (string id = default, string object = default, string name = default, string callId = default, string arguments = default, Azure.AI.VoiceLive.SessionResponseItemStatus status = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseFunctionCallItem ResponseFunctionCallItem(string id, string object, string name, string callId, string arguments, valuetype Azure.AI.VoiceLive.SessionResponseItemStatus status) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFunctionCallItem(System.String,System.String,System.String,System.String,System.String,Azure.AI.VoiceLive.SessionResponseItemStatus)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseFunctionCallItem (Optional id As String = Nothing, Optional object As String = Nothing, Optional name As String = Nothing, Optional callId As String = Nothing, Optional arguments As String = Nothing, Optional status As SessionResponseItemStatus = Nothing) As ResponseFunctionCallItem" />
      <MemberSignature Language="F#" Value="static member ResponseFunctionCallItem : string * string * string * string * string * Azure.AI.VoiceLive.SessionResponseItemStatus -&gt; Azure.AI.VoiceLive.ResponseFunctionCallItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFunctionCallItem (id, object, name, callId, arguments, status)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseFunctionCallItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="object" Type="System.String" />
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="callId" Type="System.String" />
        <Parameter Name="arguments" Type="System.String" />
        <Parameter Name="status" Type="Azure.AI.VoiceLive.SessionResponseItemStatus" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="object" />
        <param name="name" />
        <param name="callId" />
        <param name="arguments" />
        <param name="status" />
        <summary> A function call item within a conversation. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseFunctionCallItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseFunctionCallOutputItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseFunctionCallOutputItem ResponseFunctionCallOutputItem (string id = default, string object = default, string callId = default, string output = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseFunctionCallOutputItem ResponseFunctionCallOutputItem(string id, string object, string callId, string output) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFunctionCallOutputItem(System.String,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseFunctionCallOutputItem (Optional id As String = Nothing, Optional object As String = Nothing, Optional callId As String = Nothing, Optional output As String = Nothing) As ResponseFunctionCallOutputItem" />
      <MemberSignature Language="F#" Value="static member ResponseFunctionCallOutputItem : string * string * string * string -&gt; Azure.AI.VoiceLive.ResponseFunctionCallOutputItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFunctionCallOutputItem (id, object, callId, output)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseFunctionCallOutputItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="object" Type="System.String" />
        <Parameter Name="callId" Type="System.String" />
        <Parameter Name="output" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="object" />
        <param name="callId" />
        <param name="output" />
        <summary> A function call output item within a conversation. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseFunctionCallOutputItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseIncompleteDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseIncompleteDetails ResponseIncompleteDetails (Azure.AI.VoiceLive.ResponseIncompleteDetailsReason reason = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseIncompleteDetails ResponseIncompleteDetails(valuetype Azure.AI.VoiceLive.ResponseIncompleteDetailsReason reason) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseIncompleteDetails(Azure.AI.VoiceLive.ResponseIncompleteDetailsReason)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseIncompleteDetails (Optional reason As ResponseIncompleteDetailsReason = Nothing) As ResponseIncompleteDetails" />
      <MemberSignature Language="F#" Value="static member ResponseIncompleteDetails : Azure.AI.VoiceLive.ResponseIncompleteDetailsReason -&gt; Azure.AI.VoiceLive.ResponseIncompleteDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseIncompleteDetails reason" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseIncompleteDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="reason" Type="Azure.AI.VoiceLive.ResponseIncompleteDetailsReason" />
      </Parameters>
      <Docs>
        <param name="reason" />
        <summary> Details for an incomplete response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseIncompleteDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseStatusDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseStatusDetails ResponseStatusDetails (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseStatusDetails ResponseStatusDetails(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseStatusDetails(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseStatusDetails (Optional type As String = Nothing) As ResponseStatusDetails" />
      <MemberSignature Language="F#" Value="static member ResponseStatusDetails : string -&gt; Azure.AI.VoiceLive.ResponseStatusDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseStatusDetails type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseStatusDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <summary>
            Base for all non-success response details.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseCancelledDetails(Azure.AI.VoiceLive.ResponseCancelledDetailsReason)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseIncompleteDetails(Azure.AI.VoiceLive.ResponseIncompleteDetailsReason)" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFailedDetails(System.BinaryData)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseStatusDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseTextContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseTextContentPart ResponseTextContentPart (string text = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseTextContentPart ResponseTextContentPart(string text) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseTextContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseTextContentPart (Optional text As String = Nothing) As ResponseTextContentPart" />
      <MemberSignature Language="F#" Value="static member ResponseTextContentPart : string -&gt; Azure.AI.VoiceLive.ResponseTextContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseTextContentPart text" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseTextContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="text" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="text" />
        <summary> A text content part for a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseTextContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ResponseTokenStatistics">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ResponseTokenStatistics ResponseTokenStatistics (int totalTokens = 0, int inputTokens = 0, int outputTokens = 0, Azure.AI.VoiceLive.InputTokenDetails inputTokenDetails = default, Azure.AI.VoiceLive.OutputTokenDetails outputTokenDetails = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ResponseTokenStatistics ResponseTokenStatistics(int32 totalTokens, int32 inputTokens, int32 outputTokens, class Azure.AI.VoiceLive.InputTokenDetails inputTokenDetails, class Azure.AI.VoiceLive.OutputTokenDetails outputTokenDetails) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseTokenStatistics(System.Int32,System.Int32,System.Int32,Azure.AI.VoiceLive.InputTokenDetails,Azure.AI.VoiceLive.OutputTokenDetails)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ResponseTokenStatistics (Optional totalTokens As Integer = 0, Optional inputTokens As Integer = 0, Optional outputTokens As Integer = 0, Optional inputTokenDetails As InputTokenDetails = Nothing, Optional outputTokenDetails As OutputTokenDetails = Nothing) As ResponseTokenStatistics" />
      <MemberSignature Language="F#" Value="static member ResponseTokenStatistics : int * int * int * Azure.AI.VoiceLive.InputTokenDetails * Azure.AI.VoiceLive.OutputTokenDetails -&gt; Azure.AI.VoiceLive.ResponseTokenStatistics" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseTokenStatistics (totalTokens, inputTokens, outputTokens, inputTokenDetails, outputTokenDetails)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ResponseTokenStatistics</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="totalTokens" Type="System.Int32" />
        <Parameter Name="inputTokens" Type="System.Int32" />
        <Parameter Name="outputTokens" Type="System.Int32" />
        <Parameter Name="inputTokenDetails" Type="Azure.AI.VoiceLive.InputTokenDetails" />
        <Parameter Name="outputTokenDetails" Type="Azure.AI.VoiceLive.OutputTokenDetails" />
      </Parameters>
      <Docs>
        <param name="totalTokens"> Total number of tokens (input + output). </param>
        <param name="inputTokens"> Number of input tokens. </param>
        <param name="outputTokens"> Number of output tokens. </param>
        <param name="inputTokenDetails"> Detailed breakdown of input tokens. </param>
        <param name="outputTokenDetails"> Detailed breakdown of output tokens. </param>
        <summary> Overall usage statistics for a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ResponseTokenStatistics" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="ServerVadTurnDetection">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.ServerVadTurnDetection ServerVadTurnDetection (float? threshold = default, int? prefixPaddingMs = default, int? silenceDurationMs = default, Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection = default, bool? autoTruncate = default, bool? createResponse = default, bool? interruptResponse = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.ServerVadTurnDetection ServerVadTurnDetection(valuetype System.Nullable`1&lt;float32&gt; threshold, valuetype System.Nullable`1&lt;int32&gt; prefixPaddingMs, valuetype System.Nullable`1&lt;int32&gt; silenceDurationMs, class Azure.AI.VoiceLive.EouDetection endOfUtteranceDetection, valuetype System.Nullable`1&lt;bool&gt; autoTruncate, valuetype System.Nullable`1&lt;bool&gt; createResponse, valuetype System.Nullable`1&lt;bool&gt; interruptResponse) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ServerVadTurnDetection(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function ServerVadTurnDetection (Optional threshold As Nullable(Of Single) = Nothing, Optional prefixPaddingMs As Nullable(Of Integer) = Nothing, Optional silenceDurationMs As Nullable(Of Integer) = Nothing, Optional endOfUtteranceDetection As EouDetection = Nothing, Optional autoTruncate As Nullable(Of Boolean) = Nothing, Optional createResponse As Nullable(Of Boolean) = Nothing, Optional interruptResponse As Nullable(Of Boolean) = Nothing) As ServerVadTurnDetection" />
      <MemberSignature Language="F#" Value="static member ServerVadTurnDetection : Nullable&lt;single&gt; * Nullable&lt;int&gt; * Nullable&lt;int&gt; * Azure.AI.VoiceLive.EouDetection * Nullable&lt;bool&gt; * Nullable&lt;bool&gt; * Nullable&lt;bool&gt; -&gt; Azure.AI.VoiceLive.ServerVadTurnDetection" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.ServerVadTurnDetection (threshold, prefixPaddingMs, silenceDurationMs, endOfUtteranceDetection, autoTruncate, createResponse, interruptResponse)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.ServerVadTurnDetection</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="threshold" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="prefixPaddingMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="silenceDurationMs" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="endOfUtteranceDetection" Type="Azure.AI.VoiceLive.EouDetection" />
        <Parameter Name="autoTruncate" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="createResponse" Type="System.Nullable&lt;System.Boolean&gt;" />
        <Parameter Name="interruptResponse" Type="System.Nullable&lt;System.Boolean&gt;" />
      </Parameters>
      <Docs>
        <param name="threshold" />
        <param name="prefixPaddingMs"> Gets or sets the PrefixPaddingMs. </param>
        <param name="silenceDurationMs"> Gets or sets the SilenceDurationMs. </param>
        <param name="endOfUtteranceDetection" />
        <param name="autoTruncate" />
        <param name="createResponse" />
        <param name="interruptResponse" />
        <summary> Base model for VAD-based turn detection. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.ServerVadTurnDetection" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionResponse">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionResponse SessionResponse (string id = default, string object = default, Azure.AI.VoiceLive.SessionResponseStatus? status = default, Azure.AI.VoiceLive.ResponseStatusDetails statusDetails = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.SessionResponseItem&gt; output = default, Azure.AI.VoiceLive.ResponseTokenStatistics usage = default, string conversationId = default, BinaryData voice = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.InteractionModality&gt; modalitiesInternal = default, Azure.AI.VoiceLive.OutputAudioFormat? outputAudioFormat = default, float? temperature = default, BinaryData maxOutputTokens = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionResponse SessionResponse(string id, string object, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.SessionResponseStatus&gt; status, class Azure.AI.VoiceLive.ResponseStatusDetails statusDetails, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.SessionResponseItem&gt; output, class Azure.AI.VoiceLive.ResponseTokenStatistics usage, string conversationId, class System.BinaryData voice, class System.Collections.Generic.IEnumerable`1&lt;valuetype Azure.AI.VoiceLive.InteractionModality&gt; modalitiesInternal, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.OutputAudioFormat&gt; outputAudioFormat, valuetype System.Nullable`1&lt;float32&gt; temperature, class System.BinaryData maxOutputTokens) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionResponse(System.String,System.String,System.Nullable{Azure.AI.VoiceLive.SessionResponseStatus},Azure.AI.VoiceLive.ResponseStatusDetails,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.SessionResponseItem},Azure.AI.VoiceLive.ResponseTokenStatistics,System.String,System.BinaryData,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.InteractionModality},System.Nullable{Azure.AI.VoiceLive.OutputAudioFormat},System.Nullable{System.Single},System.BinaryData)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionResponse (Optional id As String = Nothing, Optional object As String = Nothing, Optional status As Nullable(Of SessionResponseStatus) = Nothing, Optional statusDetails As ResponseStatusDetails = Nothing, Optional output As IEnumerable(Of SessionResponseItem) = Nothing, Optional usage As ResponseTokenStatistics = Nothing, Optional conversationId As String = Nothing, Optional voice As BinaryData = Nothing, Optional modalitiesInternal As IEnumerable(Of InteractionModality) = Nothing, Optional outputAudioFormat As Nullable(Of OutputAudioFormat) = Nothing, Optional temperature As Nullable(Of Single) = Nothing, Optional maxOutputTokens As BinaryData = Nothing) As SessionResponse" />
      <MemberSignature Language="F#" Value="static member SessionResponse : string * string * Nullable&lt;Azure.AI.VoiceLive.SessionResponseStatus&gt; * Azure.AI.VoiceLive.ResponseStatusDetails * seq&lt;Azure.AI.VoiceLive.SessionResponseItem&gt; * Azure.AI.VoiceLive.ResponseTokenStatistics * string * BinaryData * seq&lt;Azure.AI.VoiceLive.InteractionModality&gt; * Nullable&lt;Azure.AI.VoiceLive.OutputAudioFormat&gt; * Nullable&lt;single&gt; * BinaryData -&gt; Azure.AI.VoiceLive.SessionResponse" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionResponse (id, object, status, statusDetails, output, usage, conversationId, voice, modalitiesInternal, outputAudioFormat, temperature, maxOutputTokens)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionResponse</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="object" Type="System.String" />
        <Parameter Name="status" Type="System.Nullable&lt;Azure.AI.VoiceLive.SessionResponseStatus&gt;" />
        <Parameter Name="statusDetails" Type="Azure.AI.VoiceLive.ResponseStatusDetails" />
        <Parameter Name="output" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.SessionResponseItem&gt;" />
        <Parameter Name="usage" Type="Azure.AI.VoiceLive.ResponseTokenStatistics" />
        <Parameter Name="conversationId" Type="System.String" />
        <Parameter Name="voice" Type="System.BinaryData" />
        <Parameter Name="modalitiesInternal" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.InteractionModality&gt;" />
        <Parameter Name="outputAudioFormat" Type="System.Nullable&lt;Azure.AI.VoiceLive.OutputAudioFormat&gt;" />
        <Parameter Name="temperature" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="maxOutputTokens" Type="System.BinaryData" />
      </Parameters>
      <Docs>
        <param name="id"> The unique ID of the response. </param>
        <param name="object"> The object type, must be `realtime.response`. </param>
        <param name="status">
            The final status of the response.
            One of: `completed`, `cancelled`, `failed`, `incomplete`, or `in_progress`.
            </param>
        <param name="statusDetails"> Additional details about the status. </param>
        <param name="output"> The list of output items generated by the response. </param>
        <param name="usage">
            Usage statistics for the Response, this will correspond to billing. A
            VoiceLive API session will maintain a conversation context and append new
            Items to the Conversation, thus output from previous turns (text and
            audio tokens) will become the input for later turns.
            </param>
        <param name="conversationId">
            Which conversation the response is added to, determined by the `conversation`
            field in the `response.create` event. If `auto`, the response will be added to
            the default conversation and the value of `conversation_id` will be an id like
            `conv_1234`. If `none`, the response will not be added to any conversation and
            the value of `conversation_id` will be `null`. If responses are being triggered
            by server VAD, the response will be added to the default conversation, thus
            the `conversation_id` will be an id like `conv_1234`.
            </param>
        <param name="voice"> supported voice identifiers and configurations. </param>
        <param name="modalitiesInternal">
            The set of modalities the model used to respond. If there are multiple modalities,
            the model will pick one, for example if `modalities` is `["text", "audio"]`, the model
            could be responding in either text or audio.
            </param>
        <param name="outputAudioFormat"> The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. </param>
        <param name="temperature"> Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8. </param>
        <param name="maxOutputTokens">
            Maximum number of output tokens for a single assistant response,
            inclusive of tool calls, that was used in this response.
            </param>
        <summary> The response resource. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionResponse" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionResponseItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionResponseItem SessionResponseItem (string type = default, string id = default, string object = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionResponseItem SessionResponseItem(string type, string id, string object) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionResponseItem(System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionResponseItem (Optional type As String = Nothing, Optional id As String = Nothing, Optional object As String = Nothing) As SessionResponseItem" />
      <MemberSignature Language="F#" Value="static member SessionResponseItem : string * string * string -&gt; Azure.AI.VoiceLive.SessionResponseItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionResponseItem (type, id, object)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionResponseItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="object" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <param name="id" />
        <param name="object" />
        <summary>
            Base for any response item; discriminated by `type`.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionResponseMessageItem(System.String,System.String,Azure.AI.VoiceLive.ResponseMessageRole,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.VoiceLiveContentPart},Azure.AI.VoiceLive.SessionResponseItemStatus)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFunctionCallItem(System.String,System.String,System.String,System.String,System.String,Azure.AI.VoiceLive.SessionResponseItemStatus)" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseFunctionCallOutputItem(System.String,System.String,System.String,System.String)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionResponseItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionResponseMessageItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionResponseMessageItem SessionResponseMessageItem (string id = default, string object = default, Azure.AI.VoiceLive.ResponseMessageRole role = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.VoiceLiveContentPart&gt; content = default, Azure.AI.VoiceLive.SessionResponseItemStatus status = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionResponseMessageItem SessionResponseMessageItem(string id, string object, valuetype Azure.AI.VoiceLive.ResponseMessageRole role, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.VoiceLiveContentPart&gt; content, valuetype Azure.AI.VoiceLive.SessionResponseItemStatus status) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionResponseMessageItem(System.String,System.String,Azure.AI.VoiceLive.ResponseMessageRole,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.VoiceLiveContentPart},Azure.AI.VoiceLive.SessionResponseItemStatus)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionResponseMessageItem (Optional id As String = Nothing, Optional object As String = Nothing, Optional role As ResponseMessageRole = Nothing, Optional content As IEnumerable(Of VoiceLiveContentPart) = Nothing, Optional status As SessionResponseItemStatus = Nothing) As SessionResponseMessageItem" />
      <MemberSignature Language="F#" Value="static member SessionResponseMessageItem : string * string * Azure.AI.VoiceLive.ResponseMessageRole * seq&lt;Azure.AI.VoiceLive.VoiceLiveContentPart&gt; * Azure.AI.VoiceLive.SessionResponseItemStatus -&gt; Azure.AI.VoiceLive.SessionResponseMessageItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionResponseMessageItem (id, object, role, content, status)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionResponseMessageItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="object" Type="System.String" />
        <Parameter Name="role" Type="Azure.AI.VoiceLive.ResponseMessageRole" />
        <Parameter Name="content" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.VoiceLiveContentPart&gt;" />
        <Parameter Name="status" Type="Azure.AI.VoiceLive.SessionResponseItemStatus" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="object" />
        <param name="role" />
        <param name="content" />
        <param name="status" />
        <summary> Base type for message item within a conversation. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionResponseMessageItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdate">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdate SessionUpdate (string type = default, string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdate SessionUpdate(string type, string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdate(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdate (Optional type As String = Nothing, Optional eventId As String = Nothing) As SessionUpdate" />
      <MemberSignature Language="F#" Value="static member SessionUpdate : string * string -&gt; Azure.AI.VoiceLive.SessionUpdate" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdate (type, eventId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdate</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type"> The type of event. </param>
        <param name="eventId" />
        <summary>
            A voicelive server event.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateError(System.String,Azure.AI.VoiceLive.SessionUpdateErrorDetails)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionCreated(System.String,Azure.AI.VoiceLive.VoiceLiveSessionResponse)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionUpdated(System.String,Azure.AI.VoiceLive.VoiceLiveSessionResponse)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateAvatarConnecting(System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferCommitted(System.String,System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferCleared(System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferSpeechStarted(System.String,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferSpeechStopped(System.String,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemCreated(System.String,System.String,Azure.AI.VoiceLive.SessionResponseItem)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionCompleted(System.String,System.String,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionFailed(System.String,System.String,System.Int32,Azure.AI.VoiceLive.VoiceLiveErrorDetails)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemTruncated(System.String,System.Int32,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemDeleted(System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseCreated(System.String,Azure.AI.VoiceLive.SessionResponse)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseDone(System.String,Azure.AI.VoiceLive.SessionResponse)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseOutputItemAdded(System.String,System.String,System.Int32,Azure.AI.VoiceLive.SessionResponseItem)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseOutputItemDone(System.String,System.String,System.Int32,Azure.AI.VoiceLive.SessionResponseItem)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseContentPartAdded(System.String,System.String,System.String,System.Int32,System.Int32,Azure.AI.VoiceLive.VoiceLiveContentPart)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseContentPartDone(System.String,System.String,System.String,System.Int32,System.Int32,Azure.AI.VoiceLive.VoiceLiveContentPart)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseTextDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseTextDone(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTranscriptDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTranscriptDone(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.BinaryData)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioDone(System.String,System.String,System.String,System.Int32,System.Int32)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationBlendshapeDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.BinaryData,System.Int32)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationBlendshapeDone(System.String,System.String,System.String,System.Int32)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTimestampDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.Int32,System.Int32,System.String,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTimestampDone(System.String,System.String,System.String,System.Int32,System.Int32)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationVisemeDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.Int32,System.Int32)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationVisemeDone(System.String,System.String,System.String,System.Int32,System.Int32)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionDelta(System.String,System.String,System.Nullable{System.Int32},System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.LogProbProperties})" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemRetrieved(Azure.AI.VoiceLive.SessionResponseItem,System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseFunctionCallArgumentsDelta(System.String,System.String,System.String,System.Int32,System.String,System.String)" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseFunctionCallArgumentsDone(System.String,System.String,System.String,System.Int32,System.String,System.String,System.String)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdate" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateAvatarConnecting">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateAvatarConnecting SessionUpdateAvatarConnecting (string eventId = default, string serverSdp = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateAvatarConnecting SessionUpdateAvatarConnecting(string eventId, string serverSdp) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateAvatarConnecting(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateAvatarConnecting (Optional eventId As String = Nothing, Optional serverSdp As String = Nothing) As SessionUpdateAvatarConnecting" />
      <MemberSignature Language="F#" Value="static member SessionUpdateAvatarConnecting : string * string -&gt; Azure.AI.VoiceLive.SessionUpdateAvatarConnecting" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateAvatarConnecting (eventId, serverSdp)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateAvatarConnecting</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="serverSdp" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="serverSdp"> The server's SDP answer for the avatar connection. </param>
        <summary> Sent when the server is in the process of establishing an avatar media connection and provides its SDP answer. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateAvatarConnecting" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemCreated">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemCreated SessionUpdateConversationItemCreated (string eventId = default, string previousItemId = default, Azure.AI.VoiceLive.SessionResponseItem item = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemCreated SessionUpdateConversationItemCreated(string eventId, string previousItemId, class Azure.AI.VoiceLive.SessionResponseItem item) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemCreated(System.String,System.String,Azure.AI.VoiceLive.SessionResponseItem)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemCreated (Optional eventId As String = Nothing, Optional previousItemId As String = Nothing, Optional item As SessionResponseItem = Nothing) As SessionUpdateConversationItemCreated" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemCreated : string * string * Azure.AI.VoiceLive.SessionResponseItem -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemCreated" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemCreated (eventId, previousItemId, item)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemCreated</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="previousItemId" Type="System.String" />
        <Parameter Name="item" Type="Azure.AI.VoiceLive.SessionResponseItem" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="previousItemId">
            The ID of the preceding item in the Conversation context, allows the
            client to understand the order of the conversation.
            </param>
        <param name="item" />
        <summary>
            Returned when a conversation item is created. There are several scenarios that produce this event:
              - The server is generating a Response, which if successful will produce
                either one or two Items, which will be of type `message`
                (role `assistant`) or type `function_call`.
              - The input audio buffer has been committed, either by the client or the
                server (in `server_vad` mode). The server will take the content of the
                input audio buffer and add it to a new user message Item.
              - The client has sent a `conversation.item.create` event to add a new Item
                to the Conversation.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemCreated" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemDeleted">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemDeleted SessionUpdateConversationItemDeleted (string itemId = default, string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemDeleted SessionUpdateConversationItemDeleted(string itemId, string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemDeleted(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemDeleted (Optional itemId As String = Nothing, Optional eventId As String = Nothing) As SessionUpdateConversationItemDeleted" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemDeleted : string * string -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemDeleted" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemDeleted (itemId, eventId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemDeleted</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="itemId"> The ID of the item that was deleted. </param>
        <param name="eventId" />
        <summary>
            Returned when an item in the conversation is deleted by the client with a
            `conversation.item.delete` event. This event is used to synchronize the
            server's understanding of the conversation history with the client's view.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemDeleted" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemInputAudioTranscriptionCompleted">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionCompleted SessionUpdateConversationItemInputAudioTranscriptionCompleted (string eventId = default, string itemId = default, int contentIndex = 0, string transcript = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionCompleted SessionUpdateConversationItemInputAudioTranscriptionCompleted(string eventId, string itemId, int32 contentIndex, string transcript) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionCompleted(System.String,System.String,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemInputAudioTranscriptionCompleted (Optional eventId As String = Nothing, Optional itemId As String = Nothing, Optional contentIndex As Integer = 0, Optional transcript As String = Nothing) As SessionUpdateConversationItemInputAudioTranscriptionCompleted" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemInputAudioTranscriptionCompleted : string * string * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionCompleted" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionCompleted (eventId, itemId, contentIndex, transcript)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionCompleted</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="transcript" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="itemId"> The ID of the user message item containing the audio. </param>
        <param name="contentIndex"> The index of the content part containing the audio. </param>
        <param name="transcript"> The transcribed text. </param>
        <summary>
            This event is the output of audio transcription for user audio written to the
            user audio buffer. Transcription begins when the input audio buffer is
            committed by the client or server (in `server_vad` mode). Transcription runs
            asynchronously with Response creation, so this event may come before or after
            the Response events.
            
            VoiceLive API models accept audio natively, and thus input transcription is a
            separate process run on a separate ASR (Automatic Speech Recognition) model.
            The transcript may diverge somewhat from the model's interpretation, and
            should be treated as a rough guide.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionCompleted" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemInputAudioTranscriptionDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionDelta SessionUpdateConversationItemInputAudioTranscriptionDelta (string eventId = default, string itemId = default, int? contentIndex = default, string delta = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.LogProbProperties&gt; logprobs = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionDelta SessionUpdateConversationItemInputAudioTranscriptionDelta(string eventId, string itemId, valuetype System.Nullable`1&lt;int32&gt; contentIndex, string delta, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.LogProbProperties&gt; logprobs) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionDelta(System.String,System.String,System.Nullable{System.Int32},System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.LogProbProperties})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemInputAudioTranscriptionDelta (Optional eventId As String = Nothing, Optional itemId As String = Nothing, Optional contentIndex As Nullable(Of Integer) = Nothing, Optional delta As String = Nothing, Optional logprobs As IEnumerable(Of LogProbProperties) = Nothing) As SessionUpdateConversationItemInputAudioTranscriptionDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemInputAudioTranscriptionDelta : string * string * Nullable&lt;int&gt; * string * seq&lt;Azure.AI.VoiceLive.LogProbProperties&gt; -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionDelta (eventId, itemId, contentIndex, delta, logprobs)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="contentIndex" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="delta" Type="System.String" />
        <Parameter Name="logprobs" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.LogProbProperties&gt;" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="itemId"> The ID of the item. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="delta"> The text delta. </param>
        <param name="logprobs"> The log probabilities of the transcription. </param>
        <summary> Returned when the text value of an input audio transcription content part is updated. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemInputAudioTranscriptionFailed">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionFailed SessionUpdateConversationItemInputAudioTranscriptionFailed (string eventId = default, string itemId = default, int contentIndex = 0, Azure.AI.VoiceLive.VoiceLiveErrorDetails error = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionFailed SessionUpdateConversationItemInputAudioTranscriptionFailed(string eventId, string itemId, int32 contentIndex, class Azure.AI.VoiceLive.VoiceLiveErrorDetails error) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionFailed(System.String,System.String,System.Int32,Azure.AI.VoiceLive.VoiceLiveErrorDetails)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemInputAudioTranscriptionFailed (Optional eventId As String = Nothing, Optional itemId As String = Nothing, Optional contentIndex As Integer = 0, Optional error As VoiceLiveErrorDetails = Nothing) As SessionUpdateConversationItemInputAudioTranscriptionFailed" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemInputAudioTranscriptionFailed : string * string * int * Azure.AI.VoiceLive.VoiceLiveErrorDetails -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionFailed" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemInputAudioTranscriptionFailed (eventId, itemId, contentIndex, error)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionFailed</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="error" Type="Azure.AI.VoiceLive.VoiceLiveErrorDetails" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="itemId"> The ID of the user message item. </param>
        <param name="contentIndex"> The index of the content part containing the audio. </param>
        <param name="error"> Details of the transcription error. </param>
        <summary>
            Returned when input audio transcription is configured, and a transcription
            request for a user message failed. These events are separate from other
            `error` events so that the client can identify the related Item.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemInputAudioTranscriptionFailed" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemRetrieved">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemRetrieved SessionUpdateConversationItemRetrieved (Azure.AI.VoiceLive.SessionResponseItem item = default, string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemRetrieved SessionUpdateConversationItemRetrieved(class Azure.AI.VoiceLive.SessionResponseItem item, string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemRetrieved(Azure.AI.VoiceLive.SessionResponseItem,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemRetrieved (Optional item As SessionResponseItem = Nothing, Optional eventId As String = Nothing) As SessionUpdateConversationItemRetrieved" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemRetrieved : Azure.AI.VoiceLive.SessionResponseItem * string -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemRetrieved" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemRetrieved (item, eventId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemRetrieved</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="item" Type="Azure.AI.VoiceLive.SessionResponseItem" />
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="item" />
        <param name="eventId" />
        <summary> Returned when a conversation item is retrieved with `conversation.item.retrieve`. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemRetrieved" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateConversationItemTruncated">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateConversationItemTruncated SessionUpdateConversationItemTruncated (string itemId = default, int contentIndex = 0, int audioEndMs = 0, string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateConversationItemTruncated SessionUpdateConversationItemTruncated(string itemId, int32 contentIndex, int32 audioEndMs, string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemTruncated(System.String,System.Int32,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateConversationItemTruncated (Optional itemId As String = Nothing, Optional contentIndex As Integer = 0, Optional audioEndMs As Integer = 0, Optional eventId As String = Nothing) As SessionUpdateConversationItemTruncated" />
      <MemberSignature Language="F#" Value="static member SessionUpdateConversationItemTruncated : string * int * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateConversationItemTruncated" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateConversationItemTruncated (itemId, contentIndex, audioEndMs, eventId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateConversationItemTruncated</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="audioEndMs" Type="System.Int32" />
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="itemId"> The ID of the assistant message item that was truncated. </param>
        <param name="contentIndex"> The index of the content part that was truncated. </param>
        <param name="audioEndMs"> The duration up to which the audio was truncated, in milliseconds. </param>
        <param name="eventId" />
        <summary>
            Returned when an earlier assistant audio message item is truncated by the
            client with a `conversation.item.truncate` event. This event is used to
            synchronize the server's understanding of the audio with the client's playback.
            
            This action will truncate the audio and remove the server-side text transcript
            to ensure there is no text in the context that hasn't been heard by the user.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateConversationItemTruncated" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateError">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateError SessionUpdateError (string eventId = default, Azure.AI.VoiceLive.SessionUpdateErrorDetails error = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateError SessionUpdateError(string eventId, class Azure.AI.VoiceLive.SessionUpdateErrorDetails error) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateError(System.String,Azure.AI.VoiceLive.SessionUpdateErrorDetails)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateError (Optional eventId As String = Nothing, Optional error As SessionUpdateErrorDetails = Nothing) As SessionUpdateError" />
      <MemberSignature Language="F#" Value="static member SessionUpdateError : string * Azure.AI.VoiceLive.SessionUpdateErrorDetails -&gt; Azure.AI.VoiceLive.SessionUpdateError" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateError (eventId, error)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateError</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="error" Type="Azure.AI.VoiceLive.SessionUpdateErrorDetails" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="error"> Details of the error. </param>
        <summary>
            Returned when an error occurs, which could be a client problem or a server
            problem. Most errors are recoverable and the session will stay open, we
            recommend to implementors to monitor and log error messages by default.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateError" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateErrorDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateErrorDetails SessionUpdateErrorDetails (string type = default, string code = default, string message = default, string param = default, string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateErrorDetails SessionUpdateErrorDetails(string type, string code, string message, string param, string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateErrorDetails(System.String,System.String,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateErrorDetails (Optional type As String = Nothing, Optional code As String = Nothing, Optional message As String = Nothing, Optional param As String = Nothing, Optional eventId As String = Nothing) As SessionUpdateErrorDetails" />
      <MemberSignature Language="F#" Value="static member SessionUpdateErrorDetails : string * string * string * string * string -&gt; Azure.AI.VoiceLive.SessionUpdateErrorDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateErrorDetails (type, code, message, param, eventId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateErrorDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="code" Type="System.String" />
        <Parameter Name="message" Type="System.String" />
        <Parameter Name="param" Type="System.String" />
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type"> The type of error (e.g., "invalid_request_error", "server_error"). </param>
        <param name="code"> Error code, if any. </param>
        <param name="message"> A human-readable error message. </param>
        <param name="param"> Parameter related to the error, if any. </param>
        <param name="eventId"> The event_id of the client event that caused the error, if applicable. </param>
        <summary> Details of the error. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateErrorDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateInputAudioBufferCleared">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCleared SessionUpdateInputAudioBufferCleared (string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCleared SessionUpdateInputAudioBufferCleared(string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferCleared(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateInputAudioBufferCleared (Optional eventId As String = Nothing) As SessionUpdateInputAudioBufferCleared" />
      <MemberSignature Language="F#" Value="static member SessionUpdateInputAudioBufferCleared : string -&gt; Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCleared" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferCleared eventId" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCleared</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <summary>
            Returned when the input audio buffer is cleared by the client with a
            `input_audio_buffer.clear` event.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCleared" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateInputAudioBufferCommitted">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCommitted SessionUpdateInputAudioBufferCommitted (string eventId = default, string previousItemId = default, string itemId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCommitted SessionUpdateInputAudioBufferCommitted(string eventId, string previousItemId, string itemId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferCommitted(System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateInputAudioBufferCommitted (Optional eventId As String = Nothing, Optional previousItemId As String = Nothing, Optional itemId As String = Nothing) As SessionUpdateInputAudioBufferCommitted" />
      <MemberSignature Language="F#" Value="static member SessionUpdateInputAudioBufferCommitted : string * string * string -&gt; Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCommitted" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferCommitted (eventId, previousItemId, itemId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCommitted</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="previousItemId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="previousItemId"> The ID of the preceding item after which the new item will be inserted. </param>
        <param name="itemId"> The ID of the user message item that will be created. </param>
        <summary>
            Returned when an input audio buffer is committed, either by the client or
            automatically in server VAD mode. The `item_id` property is the ID of the user
            message item that will be created, thus a `conversation.item.created` event
            will also be sent to the client.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateInputAudioBufferCommitted" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateInputAudioBufferSpeechStarted">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStarted SessionUpdateInputAudioBufferSpeechStarted (string eventId = default, int audioStartMs = 0, string itemId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStarted SessionUpdateInputAudioBufferSpeechStarted(string eventId, int32 audioStartMs, string itemId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferSpeechStarted(System.String,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateInputAudioBufferSpeechStarted (Optional eventId As String = Nothing, Optional audioStartMs As Integer = 0, Optional itemId As String = Nothing) As SessionUpdateInputAudioBufferSpeechStarted" />
      <MemberSignature Language="F#" Value="static member SessionUpdateInputAudioBufferSpeechStarted : string * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStarted" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferSpeechStarted (eventId, audioStartMs, itemId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStarted</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="audioStartMs" Type="System.Int32" />
        <Parameter Name="itemId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="audioStartMs" />
        <param name="itemId"> The ID of the user message item that will be created when speech stops. </param>
        <summary>
            Sent by the server when in `server_vad` mode to indicate that speech has been
            detected in the audio buffer. This can happen any time audio is added to the
            buffer (unless speech is already detected). The client may want to use this
            event to interrupt audio playback or provide visual feedback to the user.
            
            The client should expect to receive a `input_audio_buffer.speech_stopped` event
            when speech stops. The `item_id` property is the ID of the user message item
            that will be created when speech stops and will also be included in the
            `input_audio_buffer.speech_stopped` event (unless the client manually commits
            the audio buffer during VAD activation).
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStarted" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateInputAudioBufferSpeechStopped">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStopped SessionUpdateInputAudioBufferSpeechStopped (string eventId = default, int audioEndMs = 0, string itemId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStopped SessionUpdateInputAudioBufferSpeechStopped(string eventId, int32 audioEndMs, string itemId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferSpeechStopped(System.String,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateInputAudioBufferSpeechStopped (Optional eventId As String = Nothing, Optional audioEndMs As Integer = 0, Optional itemId As String = Nothing) As SessionUpdateInputAudioBufferSpeechStopped" />
      <MemberSignature Language="F#" Value="static member SessionUpdateInputAudioBufferSpeechStopped : string * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStopped" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateInputAudioBufferSpeechStopped (eventId, audioEndMs, itemId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStopped</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="audioEndMs" Type="System.Int32" />
        <Parameter Name="itemId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="audioEndMs" />
        <param name="itemId"> The ID of the user message item that will be created. </param>
        <summary>
            Returned in `server_vad` mode when the server detects the end of speech in
            the audio buffer. The server will also send an `conversation.item.created`
            event with the user message item that is created from the audio buffer.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateInputAudioBufferSpeechStopped" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAnimationBlendshapeDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDelta SessionUpdateResponseAnimationBlendshapeDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, BinaryData frames = default, int frameIndex = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDelta SessionUpdateResponseAnimationBlendshapeDelta(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, class System.BinaryData frames, int32 frameIndex) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationBlendshapeDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.BinaryData,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAnimationBlendshapeDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional frames As BinaryData = Nothing, Optional frameIndex As Integer = 0) As SessionUpdateResponseAnimationBlendshapeDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAnimationBlendshapeDelta : string * string * string * int * int * BinaryData * int -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationBlendshapeDelta (eventId, responseId, itemId, outputIndex, contentIndex, frames, frameIndex)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="frames" Type="System.BinaryData" />
        <Parameter Name="frameIndex" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId" />
        <param name="itemId" />
        <param name="outputIndex" />
        <param name="contentIndex" />
        <param name="frames" />
        <param name="frameIndex" />
        <summary> Represents a delta update of blendshape animation frames for a specific output of a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAnimationBlendshapeDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDone SessionUpdateResponseAnimationBlendshapeDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDone SessionUpdateResponseAnimationBlendshapeDone(string eventId, string responseId, string itemId, int32 outputIndex) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationBlendshapeDone(System.String,System.String,System.String,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAnimationBlendshapeDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0) As SessionUpdateResponseAnimationBlendshapeDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAnimationBlendshapeDone : string * string * string * int -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationBlendshapeDone (eventId, responseId, itemId, outputIndex)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId" />
        <param name="itemId" />
        <param name="outputIndex" />
        <summary> Indicates the completion of blendshape animation processing for a specific output of a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAnimationBlendshapeDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAnimationVisemeDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDelta SessionUpdateResponseAnimationVisemeDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, int audioOffsetMs = 0, int visemeId = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDelta SessionUpdateResponseAnimationVisemeDelta(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, int32 audioOffsetMs, int32 visemeId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationVisemeDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAnimationVisemeDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional audioOffsetMs As Integer = 0, Optional visemeId As Integer = 0) As SessionUpdateResponseAnimationVisemeDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAnimationVisemeDelta : string * string * string * int * int * int * int -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationVisemeDelta (eventId, responseId, itemId, outputIndex, contentIndex, audioOffsetMs, visemeId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="audioOffsetMs" Type="System.Int32" />
        <Parameter Name="visemeId" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId" />
        <param name="itemId" />
        <param name="outputIndex" />
        <param name="contentIndex" />
        <param name="audioOffsetMs"> Gets the AudioOffsetMs. </param>
        <param name="visemeId" />
        <summary> Represents a viseme ID delta update for animation based on audio. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAnimationVisemeDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDone SessionUpdateResponseAnimationVisemeDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDone SessionUpdateResponseAnimationVisemeDone(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationVisemeDone(System.String,System.String,System.String,System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAnimationVisemeDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0) As SessionUpdateResponseAnimationVisemeDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAnimationVisemeDone : string * string * string * int * int -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAnimationVisemeDone (eventId, responseId, itemId, outputIndex, contentIndex)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId" />
        <param name="itemId" />
        <param name="outputIndex" />
        <param name="contentIndex" />
        <summary> Indicates completion of viseme animation delivery for a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAnimationVisemeDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAudioDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAudioDelta SessionUpdateResponseAudioDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, BinaryData delta = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAudioDelta SessionUpdateResponseAudioDelta(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, class System.BinaryData delta) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.BinaryData)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAudioDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional delta As BinaryData = Nothing) As SessionUpdateResponseAudioDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAudioDelta : string * string * string * int * int * BinaryData -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAudioDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioDelta (eventId, responseId, itemId, outputIndex, contentIndex, delta)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAudioDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="delta" Type="System.BinaryData" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="delta"> Base64-encoded audio data delta. </param>
        <summary> Returned when the model-generated audio is updated. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAudioDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAudioDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAudioDone SessionUpdateResponseAudioDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAudioDone SessionUpdateResponseAudioDone(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioDone(System.String,System.String,System.String,System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAudioDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0) As SessionUpdateResponseAudioDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAudioDone : string * string * string * int * int -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAudioDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioDone (eventId, responseId, itemId, outputIndex, contentIndex)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAudioDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <summary>
            Returned when the model-generated audio is done. Also emitted when a Response
            is interrupted, incomplete, or cancelled.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAudioDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAudioTimestampDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDelta SessionUpdateResponseAudioTimestampDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, int audioOffsetMs = 0, int audioDurationMs = 0, string text = default, string timestampType = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDelta SessionUpdateResponseAudioTimestampDelta(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, int32 audioOffsetMs, int32 audioDurationMs, string text, string timestampType) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTimestampDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.Int32,System.Int32,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAudioTimestampDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional audioOffsetMs As Integer = 0, Optional audioDurationMs As Integer = 0, Optional text As String = Nothing, Optional timestampType As String = Nothing) As SessionUpdateResponseAudioTimestampDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAudioTimestampDelta : string * string * string * int * int * int * int * string * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTimestampDelta (eventId, responseId, itemId, outputIndex, contentIndex, audioOffsetMs, audioDurationMs, text, timestampType)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="audioOffsetMs" Type="System.Int32" />
        <Parameter Name="audioDurationMs" Type="System.Int32" />
        <Parameter Name="text" Type="System.String" />
        <Parameter Name="timestampType" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId" />
        <param name="itemId" />
        <param name="outputIndex" />
        <param name="contentIndex" />
        <param name="audioOffsetMs"> Gets the AudioOffsetMs. </param>
        <param name="audioDurationMs"> Gets the AudioDurationMs. </param>
        <param name="text" />
        <param name="timestampType" />
        <summary> Represents a word-level audio timestamp delta for a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAudioTimestampDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDone SessionUpdateResponseAudioTimestampDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDone SessionUpdateResponseAudioTimestampDone(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTimestampDone(System.String,System.String,System.String,System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAudioTimestampDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0) As SessionUpdateResponseAudioTimestampDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAudioTimestampDone : string * string * string * int * int -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTimestampDone (eventId, responseId, itemId, outputIndex, contentIndex)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId" />
        <param name="itemId" />
        <param name="outputIndex" />
        <param name="contentIndex" />
        <summary> Indicates completion of audio timestamp delivery for a response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAudioTimestampDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAudioTranscriptDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDelta SessionUpdateResponseAudioTranscriptDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, string delta = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDelta SessionUpdateResponseAudioTranscriptDelta(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, string delta) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTranscriptDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAudioTranscriptDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional delta As String = Nothing) As SessionUpdateResponseAudioTranscriptDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAudioTranscriptDelta : string * string * string * int * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTranscriptDelta (eventId, responseId, itemId, outputIndex, contentIndex, delta)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="delta" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="delta"> The transcript delta. </param>
        <summary> Returned when the model-generated transcription of audio output is updated. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseAudioTranscriptDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDone SessionUpdateResponseAudioTranscriptDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, string transcript = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDone SessionUpdateResponseAudioTranscriptDone(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, string transcript) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTranscriptDone(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseAudioTranscriptDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional transcript As String = Nothing) As SessionUpdateResponseAudioTranscriptDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseAudioTranscriptDone : string * string * string * int * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseAudioTranscriptDone (eventId, responseId, itemId, outputIndex, contentIndex, transcript)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="transcript" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="transcript"> The final transcript of the audio. </param>
        <summary>
            Returned when the model-generated transcription of audio output is done
            streaming. Also emitted when a Response is interrupted, incomplete, or
            cancelled.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseAudioTranscriptDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseContentPartAdded">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseContentPartAdded SessionUpdateResponseContentPartAdded (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, Azure.AI.VoiceLive.VoiceLiveContentPart part = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseContentPartAdded SessionUpdateResponseContentPartAdded(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, class Azure.AI.VoiceLive.VoiceLiveContentPart part) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseContentPartAdded(System.String,System.String,System.String,System.Int32,System.Int32,Azure.AI.VoiceLive.VoiceLiveContentPart)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseContentPartAdded (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional part As VoiceLiveContentPart = Nothing) As SessionUpdateResponseContentPartAdded" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseContentPartAdded : string * string * string * int * int * Azure.AI.VoiceLive.VoiceLiveContentPart -&gt; Azure.AI.VoiceLive.SessionUpdateResponseContentPartAdded" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseContentPartAdded (eventId, responseId, itemId, outputIndex, contentIndex, part)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseContentPartAdded</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="part" Type="Azure.AI.VoiceLive.VoiceLiveContentPart" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item to which the content part was added. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="part"> The content part that was added. </param>
        <summary>
            Returned when a new content part is added to an assistant message item during
            response generation.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseContentPartAdded" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseContentPartDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseContentPartDone SessionUpdateResponseContentPartDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, Azure.AI.VoiceLive.VoiceLiveContentPart part = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseContentPartDone SessionUpdateResponseContentPartDone(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, class Azure.AI.VoiceLive.VoiceLiveContentPart part) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseContentPartDone(System.String,System.String,System.String,System.Int32,System.Int32,Azure.AI.VoiceLive.VoiceLiveContentPart)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseContentPartDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional part As VoiceLiveContentPart = Nothing) As SessionUpdateResponseContentPartDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseContentPartDone : string * string * string * int * int * Azure.AI.VoiceLive.VoiceLiveContentPart -&gt; Azure.AI.VoiceLive.SessionUpdateResponseContentPartDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseContentPartDone (eventId, responseId, itemId, outputIndex, contentIndex, part)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseContentPartDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="part" Type="Azure.AI.VoiceLive.VoiceLiveContentPart" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="part"> The content part that is done. </param>
        <summary>
            Returned when a content part is done streaming in an assistant message item.
            Also emitted when a Response is interrupted, incomplete, or cancelled.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseContentPartDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseCreated">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseCreated SessionUpdateResponseCreated (string eventId = default, Azure.AI.VoiceLive.SessionResponse response = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseCreated SessionUpdateResponseCreated(string eventId, class Azure.AI.VoiceLive.SessionResponse response) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseCreated(System.String,Azure.AI.VoiceLive.SessionResponse)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseCreated (Optional eventId As String = Nothing, Optional response As SessionResponse = Nothing) As SessionUpdateResponseCreated" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseCreated : string * Azure.AI.VoiceLive.SessionResponse -&gt; Azure.AI.VoiceLive.SessionUpdateResponseCreated" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseCreated (eventId, response)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseCreated</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="response" Type="Azure.AI.VoiceLive.SessionResponse" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="response" />
        <summary>
            Returned when a new Response is created. The first event of response creation,
            where the response is in an initial state of `in_progress`.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseCreated" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseDone SessionUpdateResponseDone (string eventId = default, Azure.AI.VoiceLive.SessionResponse response = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseDone SessionUpdateResponseDone(string eventId, class Azure.AI.VoiceLive.SessionResponse response) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseDone(System.String,Azure.AI.VoiceLive.SessionResponse)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseDone (Optional eventId As String = Nothing, Optional response As SessionResponse = Nothing) As SessionUpdateResponseDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseDone : string * Azure.AI.VoiceLive.SessionResponse -&gt; Azure.AI.VoiceLive.SessionUpdateResponseDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseDone (eventId, response)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="response" Type="Azure.AI.VoiceLive.SessionResponse" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="response" />
        <summary>
            Returned when a Response is done streaming. Always emitted, no matter the
            final state. The Response object included in the `response.done` event will
            include all output Items in the Response but will omit the raw audio data.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseFunctionCallArgumentsDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDelta SessionUpdateResponseFunctionCallArgumentsDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, string callId = default, string delta = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDelta SessionUpdateResponseFunctionCallArgumentsDelta(string eventId, string responseId, string itemId, int32 outputIndex, string callId, string delta) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseFunctionCallArgumentsDelta(System.String,System.String,System.String,System.Int32,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseFunctionCallArgumentsDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional callId As String = Nothing, Optional delta As String = Nothing) As SessionUpdateResponseFunctionCallArgumentsDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseFunctionCallArgumentsDelta : string * string * string * int * string * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseFunctionCallArgumentsDelta (eventId, responseId, itemId, outputIndex, callId, delta)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="callId" Type="System.String" />
        <Parameter Name="delta" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the function call item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="callId"> The ID of the function call. </param>
        <param name="delta"> The arguments delta as a JSON string. </param>
        <summary> Returned when the model-generated function call arguments are updated. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseFunctionCallArgumentsDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDone SessionUpdateResponseFunctionCallArgumentsDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, string callId = default, string arguments = default, string name = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDone SessionUpdateResponseFunctionCallArgumentsDone(string eventId, string responseId, string itemId, int32 outputIndex, string callId, string arguments, string name) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseFunctionCallArgumentsDone(System.String,System.String,System.String,System.Int32,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseFunctionCallArgumentsDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional callId As String = Nothing, Optional arguments As String = Nothing, Optional name As String = Nothing) As SessionUpdateResponseFunctionCallArgumentsDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseFunctionCallArgumentsDone : string * string * string * int * string * string * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseFunctionCallArgumentsDone (eventId, responseId, itemId, outputIndex, callId, arguments, name)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="callId" Type="System.String" />
        <Parameter Name="arguments" Type="System.String" />
        <Parameter Name="name" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the function call item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="callId"> The ID of the function call. </param>
        <param name="arguments"> The final arguments as a JSON string. </param>
        <param name="name"> The name of the function call. </param>
        <summary>
            Returned when the model-generated function call arguments are done streaming.
            Also emitted when a Response is interrupted, incomplete, or cancelled.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseFunctionCallArgumentsDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseOutputItemAdded">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseOutputItemAdded SessionUpdateResponseOutputItemAdded (string eventId = default, string responseId = default, int outputIndex = 0, Azure.AI.VoiceLive.SessionResponseItem item = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseOutputItemAdded SessionUpdateResponseOutputItemAdded(string eventId, string responseId, int32 outputIndex, class Azure.AI.VoiceLive.SessionResponseItem item) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseOutputItemAdded(System.String,System.String,System.Int32,Azure.AI.VoiceLive.SessionResponseItem)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseOutputItemAdded (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional outputIndex As Integer = 0, Optional item As SessionResponseItem = Nothing) As SessionUpdateResponseOutputItemAdded" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseOutputItemAdded : string * string * int * Azure.AI.VoiceLive.SessionResponseItem -&gt; Azure.AI.VoiceLive.SessionUpdateResponseOutputItemAdded" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseOutputItemAdded (eventId, responseId, outputIndex, item)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseOutputItemAdded</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="item" Type="Azure.AI.VoiceLive.SessionResponseItem" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the Response to which the item belongs. </param>
        <param name="outputIndex"> The index of the output item in the Response. </param>
        <param name="item" />
        <summary> Returned when a new Item is created during Response generation. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseOutputItemAdded" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseOutputItemDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseOutputItemDone SessionUpdateResponseOutputItemDone (string eventId = default, string responseId = default, int outputIndex = 0, Azure.AI.VoiceLive.SessionResponseItem item = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseOutputItemDone SessionUpdateResponseOutputItemDone(string eventId, string responseId, int32 outputIndex, class Azure.AI.VoiceLive.SessionResponseItem item) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseOutputItemDone(System.String,System.String,System.Int32,Azure.AI.VoiceLive.SessionResponseItem)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseOutputItemDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional outputIndex As Integer = 0, Optional item As SessionResponseItem = Nothing) As SessionUpdateResponseOutputItemDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseOutputItemDone : string * string * int * Azure.AI.VoiceLive.SessionResponseItem -&gt; Azure.AI.VoiceLive.SessionUpdateResponseOutputItemDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseOutputItemDone (eventId, responseId, outputIndex, item)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseOutputItemDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="item" Type="Azure.AI.VoiceLive.SessionResponseItem" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the Response to which the item belongs. </param>
        <param name="outputIndex"> The index of the output item in the Response. </param>
        <param name="item" />
        <summary>
            Returned when an Item is done streaming. Also emitted when a Response is
            interrupted, incomplete, or cancelled.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseOutputItemDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseTextDelta">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseTextDelta SessionUpdateResponseTextDelta (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, string delta = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseTextDelta SessionUpdateResponseTextDelta(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, string delta) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseTextDelta(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseTextDelta (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional delta As String = Nothing) As SessionUpdateResponseTextDelta" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseTextDelta : string * string * string * int * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseTextDelta" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseTextDelta (eventId, responseId, itemId, outputIndex, contentIndex, delta)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseTextDelta</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="delta" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="delta"> The text delta. </param>
        <summary> Returned when the text value of a "text" content part is updated. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseTextDelta" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateResponseTextDone">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateResponseTextDone SessionUpdateResponseTextDone (string eventId = default, string responseId = default, string itemId = default, int outputIndex = 0, int contentIndex = 0, string text = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateResponseTextDone SessionUpdateResponseTextDone(string eventId, string responseId, string itemId, int32 outputIndex, int32 contentIndex, string text) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseTextDone(System.String,System.String,System.String,System.Int32,System.Int32,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateResponseTextDone (Optional eventId As String = Nothing, Optional responseId As String = Nothing, Optional itemId As String = Nothing, Optional outputIndex As Integer = 0, Optional contentIndex As Integer = 0, Optional text As String = Nothing) As SessionUpdateResponseTextDone" />
      <MemberSignature Language="F#" Value="static member SessionUpdateResponseTextDone : string * string * string * int * int * string -&gt; Azure.AI.VoiceLive.SessionUpdateResponseTextDone" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateResponseTextDone (eventId, responseId, itemId, outputIndex, contentIndex, text)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateResponseTextDone</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="responseId" Type="System.String" />
        <Parameter Name="itemId" Type="System.String" />
        <Parameter Name="outputIndex" Type="System.Int32" />
        <Parameter Name="contentIndex" Type="System.Int32" />
        <Parameter Name="text" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="responseId"> The ID of the response. </param>
        <param name="itemId"> The ID of the item. </param>
        <param name="outputIndex"> The index of the output item in the response. </param>
        <param name="contentIndex"> The index of the content part in the item's content array. </param>
        <param name="text"> The final text content. </param>
        <summary>
            Returned when the text value of a "text" content part is done streaming. Also
            emitted when a Response is interrupted, incomplete, or cancelled.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateResponseTextDone" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateSessionCreated">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateSessionCreated SessionUpdateSessionCreated (string eventId = default, Azure.AI.VoiceLive.VoiceLiveSessionResponse session = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateSessionCreated SessionUpdateSessionCreated(string eventId, class Azure.AI.VoiceLive.VoiceLiveSessionResponse session) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionCreated(System.String,Azure.AI.VoiceLive.VoiceLiveSessionResponse)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateSessionCreated (Optional eventId As String = Nothing, Optional session As VoiceLiveSessionResponse = Nothing) As SessionUpdateSessionCreated" />
      <MemberSignature Language="F#" Value="static member SessionUpdateSessionCreated : string * Azure.AI.VoiceLive.VoiceLiveSessionResponse -&gt; Azure.AI.VoiceLive.SessionUpdateSessionCreated" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionCreated (eventId, session)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateSessionCreated</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="session" Type="Azure.AI.VoiceLive.VoiceLiveSessionResponse" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="session" />
        <summary>
            Returned when a Session is created. Emitted automatically when a new
            connection is established as the first server event. This event will contain
            the default Session configuration.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateSessionCreated" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SessionUpdateSessionUpdated">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SessionUpdateSessionUpdated SessionUpdateSessionUpdated (string eventId = default, Azure.AI.VoiceLive.VoiceLiveSessionResponse session = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SessionUpdateSessionUpdated SessionUpdateSessionUpdated(string eventId, class Azure.AI.VoiceLive.VoiceLiveSessionResponse session) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionUpdated(System.String,Azure.AI.VoiceLive.VoiceLiveSessionResponse)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SessionUpdateSessionUpdated (Optional eventId As String = Nothing, Optional session As VoiceLiveSessionResponse = Nothing) As SessionUpdateSessionUpdated" />
      <MemberSignature Language="F#" Value="static member SessionUpdateSessionUpdated : string * Azure.AI.VoiceLive.VoiceLiveSessionResponse -&gt; Azure.AI.VoiceLive.SessionUpdateSessionUpdated" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SessionUpdateSessionUpdated (eventId, session)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SessionUpdateSessionUpdated</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="eventId" Type="System.String" />
        <Parameter Name="session" Type="Azure.AI.VoiceLive.VoiceLiveSessionResponse" />
      </Parameters>
      <Docs>
        <param name="eventId" />
        <param name="session" />
        <summary>
            Returned when a session is updated with a `session.update` event, unless
            there is an error.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SessionUpdateSessionUpdated" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="SystemMessageItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.SystemMessageItem SystemMessageItem (string id = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.MessageContentPart&gt; content = default, Azure.AI.VoiceLive.ItemParamStatus? status = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.SystemMessageItem SystemMessageItem(string id, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.MessageContentPart&gt; content, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.ItemParamStatus&gt; status) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.SystemMessageItem(System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.MessageContentPart},System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function SystemMessageItem (Optional id As String = Nothing, Optional content As IEnumerable(Of MessageContentPart) = Nothing, Optional status As Nullable(Of ItemParamStatus) = Nothing) As SystemMessageItem" />
      <MemberSignature Language="F#" Value="static member SystemMessageItem : string * seq&lt;Azure.AI.VoiceLive.MessageContentPart&gt; * Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt; -&gt; Azure.AI.VoiceLive.SystemMessageItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.SystemMessageItem (id, content, status)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.SystemMessageItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="content" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.MessageContentPart&gt;" />
        <Parameter Name="status" Type="System.Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt;" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="content"> The content parts of the message. </param>
        <param name="status"> Processing status of the message item. </param>
        <summary> A system message item within a conversation. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.SystemMessageItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="TurnDetection">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.TurnDetection TurnDetection (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.TurnDetection TurnDetection(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.TurnDetection(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function TurnDetection (Optional type As String = Nothing) As TurnDetection" />
      <MemberSignature Language="F#" Value="static member TurnDetection : string -&gt; Azure.AI.VoiceLive.TurnDetection" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.TurnDetection type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.TurnDetection</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <summary>
            Top-level union for turn detection configuration.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ServerVadTurnDetection(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean})" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadTurnDetection(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean})" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadTurnDetectionEn(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean})" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.AzureSemanticVadTurnDetectionMultilingual(System.Nullable{System.Single},System.Nullable{System.Int32},System.Nullable{System.Int32},Azure.AI.VoiceLive.EouDetection,System.Nullable{System.Int32},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{System.String},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Boolean})" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.TurnDetection" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="UserMessageItem">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.UserMessageItem UserMessageItem (string id = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.MessageContentPart&gt; content = default, Azure.AI.VoiceLive.ItemParamStatus? status = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.UserMessageItem UserMessageItem(string id, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.MessageContentPart&gt; content, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.ItemParamStatus&gt; status) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.UserMessageItem(System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.MessageContentPart},System.Nullable{Azure.AI.VoiceLive.ItemParamStatus})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function UserMessageItem (Optional id As String = Nothing, Optional content As IEnumerable(Of MessageContentPart) = Nothing, Optional status As Nullable(Of ItemParamStatus) = Nothing) As UserMessageItem" />
      <MemberSignature Language="F#" Value="static member UserMessageItem : string * seq&lt;Azure.AI.VoiceLive.MessageContentPart&gt; * Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt; -&gt; Azure.AI.VoiceLive.UserMessageItem" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.UserMessageItem (id, content, status)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.UserMessageItem</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="id" Type="System.String" />
        <Parameter Name="content" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.MessageContentPart&gt;" />
        <Parameter Name="status" Type="System.Nullable&lt;Azure.AI.VoiceLive.ItemParamStatus&gt;" />
      </Parameters>
      <Docs>
        <param name="id" />
        <param name="content"> The content parts of the message. </param>
        <param name="status"> Processing status of the message item. </param>
        <summary> A user message item within a conversation. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.UserMessageItem" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VideoBackground">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VideoBackground VideoBackground (string color = default, string imageUrl = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VideoBackground VideoBackground(string color, string imageUrl) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoBackground(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VideoBackground (Optional color As String = Nothing, Optional imageUrl As String = Nothing) As VideoBackground" />
      <MemberSignature Language="F#" Value="static member VideoBackground : string * string -&gt; Azure.AI.VoiceLive.VideoBackground" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoBackground (color, imageUrl)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VideoBackground</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="color" Type="System.String" />
        <Parameter Name="imageUrl" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="color"> Background color in hex format (e.g., `#00FF00FF`). Cannot be set if `image_url` is provided. </param>
        <param name="imageUrl"> Background image URL. Cannot be set if `color` is provided. </param>
        <summary> Defines a video background, either a solid color or an image URL (mutually exclusive). </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VideoBackground" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VideoCrop">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VideoCrop VideoCrop (System.Collections.Generic.IEnumerable&lt;int&gt; topLeftInternal = default, System.Collections.Generic.IEnumerable&lt;int&gt; bottomRightInternal = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VideoCrop VideoCrop(class System.Collections.Generic.IEnumerable`1&lt;int32&gt; topLeftInternal, class System.Collections.Generic.IEnumerable`1&lt;int32&gt; bottomRightInternal) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoCrop(System.Collections.Generic.IEnumerable{System.Int32},System.Collections.Generic.IEnumerable{System.Int32})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VideoCrop (Optional topLeftInternal As IEnumerable(Of Integer) = Nothing, Optional bottomRightInternal As IEnumerable(Of Integer) = Nothing) As VideoCrop" />
      <MemberSignature Language="F#" Value="static member VideoCrop : seq&lt;int&gt; * seq&lt;int&gt; -&gt; Azure.AI.VoiceLive.VideoCrop" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoCrop (topLeftInternal, bottomRightInternal)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VideoCrop</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="topLeftInternal" Type="System.Collections.Generic.IEnumerable&lt;System.Int32&gt;" />
        <Parameter Name="bottomRightInternal" Type="System.Collections.Generic.IEnumerable&lt;System.Int32&gt;" />
      </Parameters>
      <Docs>
        <param name="topLeftInternal"> Top-left corner of the crop region. </param>
        <param name="bottomRightInternal"> Bottom-right corner of the crop region. </param>
        <summary> Defines a video crop rectangle using top-left and bottom-right coordinates. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VideoCrop" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VideoParams">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VideoParams VideoParams (int? bitrate = default, string codec = default, Azure.AI.VoiceLive.VideoCrop crop = default, Azure.AI.VoiceLive.VideoResolution resolution = default, Azure.AI.VoiceLive.VideoBackground background = default, int? gopSize = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VideoParams VideoParams(valuetype System.Nullable`1&lt;int32&gt; bitrate, string codec, class Azure.AI.VoiceLive.VideoCrop crop, class Azure.AI.VoiceLive.VideoResolution resolution, class Azure.AI.VoiceLive.VideoBackground background, valuetype System.Nullable`1&lt;int32&gt; gopSize) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoParams(System.Nullable{System.Int32},System.String,Azure.AI.VoiceLive.VideoCrop,Azure.AI.VoiceLive.VideoResolution,Azure.AI.VoiceLive.VideoBackground,System.Nullable{System.Int32})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VideoParams (Optional bitrate As Nullable(Of Integer) = Nothing, Optional codec As String = Nothing, Optional crop As VideoCrop = Nothing, Optional resolution As VideoResolution = Nothing, Optional background As VideoBackground = Nothing, Optional gopSize As Nullable(Of Integer) = Nothing) As VideoParams" />
      <MemberSignature Language="F#" Value="static member VideoParams : Nullable&lt;int&gt; * string * Azure.AI.VoiceLive.VideoCrop * Azure.AI.VoiceLive.VideoResolution * Azure.AI.VoiceLive.VideoBackground * Nullable&lt;int&gt; -&gt; Azure.AI.VoiceLive.VideoParams" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoParams (bitrate, codec, crop, resolution, background, gopSize)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VideoParams</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="bitrate" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="codec" Type="System.String" />
        <Parameter Name="crop" Type="Azure.AI.VoiceLive.VideoCrop" />
        <Parameter Name="resolution" Type="Azure.AI.VoiceLive.VideoResolution" />
        <Parameter Name="background" Type="Azure.AI.VoiceLive.VideoBackground" />
        <Parameter Name="gopSize" Type="System.Nullable&lt;System.Int32&gt;" />
      </Parameters>
      <Docs>
        <param name="bitrate"> Bitrate in bits per second (e.g., 2000000 for 2 Mbps). </param>
        <param name="codec"> Codec to use for encoding. Currently only 'h264' is supported. </param>
        <param name="crop"> Optional cropping settings for the video stream. </param>
        <param name="resolution"> Optional resolution settings for the video stream. </param>
        <param name="background"> Optional background settings for the video. Allows specifying either a solid color or an image URL. </param>
        <param name="gopSize"> Group of Pictures (GOP) size for video encoding. Controls the interval between keyframes, affecting compression efficiency and seeking performance. </param>
        <summary> Video streaming parameters for avatar. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VideoParams" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VideoResolution">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VideoResolution VideoResolution (int width = 0, int height = 0);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VideoResolution VideoResolution(int32 width, int32 height) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoResolution(System.Int32,System.Int32)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VideoResolution (Optional width As Integer = 0, Optional height As Integer = 0) As VideoResolution" />
      <MemberSignature Language="F#" Value="static member VideoResolution : int * int -&gt; Azure.AI.VoiceLive.VideoResolution" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VideoResolution (width, height)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VideoResolution</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="width" Type="System.Int32" />
        <Parameter Name="height" Type="System.Int32" />
      </Parameters>
      <Docs>
        <param name="width"> Width of the video in pixels. Must be greater than 0. </param>
        <param name="height"> Height of the video in pixels. Must be greater than 0. </param>
        <summary> Resolution of the video feed in pixels. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VideoResolution" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VoiceLiveContentPart">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VoiceLiveContentPart VoiceLiveContentPart (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VoiceLiveContentPart VoiceLiveContentPart(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveContentPart(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VoiceLiveContentPart (Optional type As String = Nothing) As VoiceLiveContentPart" />
      <MemberSignature Language="F#" Value="static member VoiceLiveContentPart : string -&gt; Azure.AI.VoiceLive.VoiceLiveContentPart" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveContentPart type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VoiceLiveContentPart</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <summary>
            Base for any content part; discriminated by `type`.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.RequestTextContentPart(System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.RequestAudioContentPart(System.String)" />, <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseTextContentPart(System.String)" />, and <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.ResponseAudioContentPart(System.String)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VoiceLiveContentPart" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VoiceLiveErrorDetails">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VoiceLiveErrorDetails VoiceLiveErrorDetails (string code = default, string message = default, string param = default, string type = default, string eventId = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VoiceLiveErrorDetails VoiceLiveErrorDetails(string code, string message, string param, string type, string eventId) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveErrorDetails(System.String,System.String,System.String,System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VoiceLiveErrorDetails (Optional code As String = Nothing, Optional message As String = Nothing, Optional param As String = Nothing, Optional type As String = Nothing, Optional eventId As String = Nothing) As VoiceLiveErrorDetails" />
      <MemberSignature Language="F#" Value="static member VoiceLiveErrorDetails : string * string * string * string * string -&gt; Azure.AI.VoiceLive.VoiceLiveErrorDetails" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveErrorDetails (code, message, param, type, eventId)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VoiceLiveErrorDetails</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="code" Type="System.String" />
        <Parameter Name="message" Type="System.String" />
        <Parameter Name="param" Type="System.String" />
        <Parameter Name="type" Type="System.String" />
        <Parameter Name="eventId" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="code"> Error code, or null if unspecified. </param>
        <param name="message"> Human-readable error message. </param>
        <param name="param"> Parameter name related to the error, if applicable. </param>
        <param name="type"> Type or category of the error. </param>
        <param name="eventId"> Event id of the error. </param>
        <summary> Error object returned in case of API failure. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VoiceLiveErrorDetails" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VoiceLiveFunctionDefinition">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VoiceLiveFunctionDefinition VoiceLiveFunctionDefinition (string name = default, string description = default, BinaryData parameters = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VoiceLiveFunctionDefinition VoiceLiveFunctionDefinition(string name, string description, class System.BinaryData parameters) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveFunctionDefinition(System.String,System.String,System.BinaryData)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VoiceLiveFunctionDefinition (Optional name As String = Nothing, Optional description As String = Nothing, Optional parameters As BinaryData = Nothing) As VoiceLiveFunctionDefinition" />
      <MemberSignature Language="F#" Value="static member VoiceLiveFunctionDefinition : string * string * BinaryData -&gt; Azure.AI.VoiceLive.VoiceLiveFunctionDefinition" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveFunctionDefinition (name, description, parameters)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VoiceLiveFunctionDefinition</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="name" Type="System.String" />
        <Parameter Name="description" Type="System.String" />
        <Parameter Name="parameters" Type="System.BinaryData" />
      </Parameters>
      <Docs>
        <param name="name" />
        <param name="description" />
        <param name="parameters" />
        <summary> The definition of a function tool as used by the voicelive endpoint. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VoiceLiveFunctionDefinition" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VoiceLiveSessionOptions">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VoiceLiveSessionOptions VoiceLiveSessionOptions (string model = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.InteractionModality&gt; modalities = default, Azure.AI.VoiceLive.AnimationOptions animation = default, Azure.AI.VoiceLive.VoiceProvider voice = default, string instructions = default, int? inputAudioSamplingRate = default, Azure.AI.VoiceLive.InputAudioFormat? inputAudioFormat = default, Azure.AI.VoiceLive.OutputAudioFormat? outputAudioFormat = default, Azure.AI.VoiceLive.AudioNoiseReduction inputAudioNoiseReduction = default, Azure.AI.VoiceLive.AudioEchoCancellation inputAudioEchoCancellation = default, Azure.AI.VoiceLive.AvatarConfiguration avatar = default, Azure.AI.VoiceLive.AudioInputTranscriptionOptions inputAudioTranscription = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.AudioTimestampType&gt; outputAudioTimestampTypes = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt; tools = default, Azure.AI.VoiceLive.ToolChoiceOption toolChoice = default, float? temperature = default, Azure.AI.VoiceLive.MaxResponseOutputTokensOption maxResponseOutputTokens = default, BinaryData turnDetection = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VoiceLiveSessionOptions VoiceLiveSessionOptions(string model, class System.Collections.Generic.IEnumerable`1&lt;valuetype Azure.AI.VoiceLive.InteractionModality&gt; modalities, class Azure.AI.VoiceLive.AnimationOptions animation, class Azure.AI.VoiceLive.VoiceProvider voice, string instructions, valuetype System.Nullable`1&lt;int32&gt; inputAudioSamplingRate, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.InputAudioFormat&gt; inputAudioFormat, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.OutputAudioFormat&gt; outputAudioFormat, class Azure.AI.VoiceLive.AudioNoiseReduction inputAudioNoiseReduction, class Azure.AI.VoiceLive.AudioEchoCancellation inputAudioEchoCancellation, class Azure.AI.VoiceLive.AvatarConfiguration avatar, class Azure.AI.VoiceLive.AudioInputTranscriptionOptions inputAudioTranscription, class System.Collections.Generic.IEnumerable`1&lt;valuetype Azure.AI.VoiceLive.AudioTimestampType&gt; outputAudioTimestampTypes, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt; tools, class Azure.AI.VoiceLive.ToolChoiceOption toolChoice, valuetype System.Nullable`1&lt;float32&gt; temperature, class Azure.AI.VoiceLive.MaxResponseOutputTokensOption maxResponseOutputTokens, class System.BinaryData turnDetection) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveSessionOptions(System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.InteractionModality},Azure.AI.VoiceLive.AnimationOptions,Azure.AI.VoiceLive.VoiceProvider,System.String,System.Nullable{System.Int32},System.Nullable{Azure.AI.VoiceLive.InputAudioFormat},System.Nullable{Azure.AI.VoiceLive.OutputAudioFormat},Azure.AI.VoiceLive.AudioNoiseReduction,Azure.AI.VoiceLive.AudioEchoCancellation,Azure.AI.VoiceLive.AvatarConfiguration,Azure.AI.VoiceLive.AudioInputTranscriptionOptions,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.AudioTimestampType},System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.VoiceLiveToolDefinition},Azure.AI.VoiceLive.ToolChoiceOption,System.Nullable{System.Single},Azure.AI.VoiceLive.MaxResponseOutputTokensOption,System.BinaryData)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VoiceLiveSessionOptions (Optional model As String = Nothing, Optional modalities As IEnumerable(Of InteractionModality) = Nothing, Optional animation As AnimationOptions = Nothing, Optional voice As VoiceProvider = Nothing, Optional instructions As String = Nothing, Optional inputAudioSamplingRate As Nullable(Of Integer) = Nothing, Optional inputAudioFormat As Nullable(Of InputAudioFormat) = Nothing, Optional outputAudioFormat As Nullable(Of OutputAudioFormat) = Nothing, Optional inputAudioNoiseReduction As AudioNoiseReduction = Nothing, Optional inputAudioEchoCancellation As AudioEchoCancellation = Nothing, Optional avatar As AvatarConfiguration = Nothing, Optional inputAudioTranscription As AudioInputTranscriptionOptions = Nothing, Optional outputAudioTimestampTypes As IEnumerable(Of AudioTimestampType) = Nothing, Optional tools As IEnumerable(Of VoiceLiveToolDefinition) = Nothing, Optional toolChoice As ToolChoiceOption = Nothing, Optional temperature As Nullable(Of Single) = Nothing, Optional maxResponseOutputTokens As MaxResponseOutputTokensOption = Nothing, Optional turnDetection As BinaryData = Nothing) As VoiceLiveSessionOptions" />
      <MemberSignature Language="F#" Value="static member VoiceLiveSessionOptions : string * seq&lt;Azure.AI.VoiceLive.InteractionModality&gt; * Azure.AI.VoiceLive.AnimationOptions * Azure.AI.VoiceLive.VoiceProvider * string * Nullable&lt;int&gt; * Nullable&lt;Azure.AI.VoiceLive.InputAudioFormat&gt; * Nullable&lt;Azure.AI.VoiceLive.OutputAudioFormat&gt; * Azure.AI.VoiceLive.AudioNoiseReduction * Azure.AI.VoiceLive.AudioEchoCancellation * Azure.AI.VoiceLive.AvatarConfiguration * Azure.AI.VoiceLive.AudioInputTranscriptionOptions * seq&lt;Azure.AI.VoiceLive.AudioTimestampType&gt; * seq&lt;Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt; * Azure.AI.VoiceLive.ToolChoiceOption * Nullable&lt;single&gt; * Azure.AI.VoiceLive.MaxResponseOutputTokensOption * BinaryData -&gt; Azure.AI.VoiceLive.VoiceLiveSessionOptions" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveSessionOptions (model, modalities, animation, voice, instructions, inputAudioSamplingRate, inputAudioFormat, outputAudioFormat, inputAudioNoiseReduction, inputAudioEchoCancellation, avatar, inputAudioTranscription, outputAudioTimestampTypes, tools, toolChoice, temperature, maxResponseOutputTokens, turnDetection)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VoiceLiveSessionOptions</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="model" Type="System.String" />
        <Parameter Name="modalities" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.InteractionModality&gt;" />
        <Parameter Name="animation" Type="Azure.AI.VoiceLive.AnimationOptions" />
        <Parameter Name="voice" Type="Azure.AI.VoiceLive.VoiceProvider" />
        <Parameter Name="instructions" Type="System.String" />
        <Parameter Name="inputAudioSamplingRate" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="inputAudioFormat" Type="System.Nullable&lt;Azure.AI.VoiceLive.InputAudioFormat&gt;" />
        <Parameter Name="outputAudioFormat" Type="System.Nullable&lt;Azure.AI.VoiceLive.OutputAudioFormat&gt;" />
        <Parameter Name="inputAudioNoiseReduction" Type="Azure.AI.VoiceLive.AudioNoiseReduction" />
        <Parameter Name="inputAudioEchoCancellation" Type="Azure.AI.VoiceLive.AudioEchoCancellation" />
        <Parameter Name="avatar" Type="Azure.AI.VoiceLive.AvatarConfiguration" />
        <Parameter Name="inputAudioTranscription" Type="Azure.AI.VoiceLive.AudioInputTranscriptionOptions" />
        <Parameter Name="outputAudioTimestampTypes" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.AudioTimestampType&gt;" />
        <Parameter Name="tools" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt;" />
        <Parameter Name="toolChoice" Type="Azure.AI.VoiceLive.ToolChoiceOption" />
        <Parameter Name="temperature" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="maxResponseOutputTokens" Type="Azure.AI.VoiceLive.MaxResponseOutputTokensOption" />
        <Parameter Name="turnDetection" Type="System.BinaryData" />
      </Parameters>
      <Docs>
        <param name="model"> The model for the session. </param>
        <param name="modalities"> The modalities to be used in the session. </param>
        <param name="animation"> The animation configuration for the session. </param>
        <param name="voice"> Gets or sets the Voice. </param>
        <param name="instructions"> Optional instructions to guide the model's behavior throughout the session. </param>
        <param name="inputAudioSamplingRate">
            Input audio sampling rate in Hz. Available values:
            - For pcm16: 8000, 16000, 24000
            - For g711_alaw/g711_ulaw: 8000
            </param>
        <param name="inputAudioFormat"> Input audio format. Default is 'pcm16'. </param>
        <param name="outputAudioFormat"> Output audio format. Default is 'pcm16'. </param>
        <param name="inputAudioNoiseReduction"> Configuration for input audio noise reduction. </param>
        <param name="inputAudioEchoCancellation"> Configuration for echo cancellation during server-side audio processing. </param>
        <param name="avatar"> Configuration for avatar streaming and behavior during the session. </param>
        <param name="inputAudioTranscription"> Configuration for input audio transcription. </param>
        <param name="outputAudioTimestampTypes"> Types of timestamps to include in audio response content. </param>
        <param name="tools"> Configuration for tools to be used during the session, if applicable. </param>
        <param name="toolChoice"> Gets or sets the tool choice strategy for response generation. </param>
        <param name="temperature"> Controls the randomness of the model's output. Range: 0.0 to 1.0. Default is 0.7. </param>
        <param name="maxResponseOutputTokens"> Gets or sets the maximum number of tokens to generate in the response. </param>
        <param name="turnDetection" />
        <summary> Base for session configuration shared between request and response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VoiceLiveSessionOptions" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VoiceLiveSessionResponse">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VoiceLiveSessionResponse VoiceLiveSessionResponse (string model = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.InteractionModality&gt; modalities = default, Azure.AI.VoiceLive.AnimationOptions animation = default, Azure.AI.VoiceLive.VoiceProvider voice = default, string instructions = default, int? inputAudioSamplingRate = default, Azure.AI.VoiceLive.InputAudioFormat? inputAudioFormat = default, Azure.AI.VoiceLive.OutputAudioFormat? outputAudioFormat = default, Azure.AI.VoiceLive.AudioNoiseReduction inputAudioNoiseReduction = default, Azure.AI.VoiceLive.AudioEchoCancellation inputAudioEchoCancellation = default, Azure.AI.VoiceLive.AvatarConfiguration avatar = default, Azure.AI.VoiceLive.AudioInputTranscriptionOptions inputAudioTranscription = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.AudioTimestampType&gt; outputAudioTimestampTypes = default, System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt; tools = default, Azure.AI.VoiceLive.ToolChoiceOption toolChoice = default, float? temperature = default, Azure.AI.VoiceLive.MaxResponseOutputTokensOption maxResponseOutputTokens = default, BinaryData turnDetection = default, Azure.AI.VoiceLive.RespondingAgentOptions agent = default, string id = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VoiceLiveSessionResponse VoiceLiveSessionResponse(string model, class System.Collections.Generic.IEnumerable`1&lt;valuetype Azure.AI.VoiceLive.InteractionModality&gt; modalities, class Azure.AI.VoiceLive.AnimationOptions animation, class Azure.AI.VoiceLive.VoiceProvider voice, string instructions, valuetype System.Nullable`1&lt;int32&gt; inputAudioSamplingRate, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.InputAudioFormat&gt; inputAudioFormat, valuetype System.Nullable`1&lt;valuetype Azure.AI.VoiceLive.OutputAudioFormat&gt; outputAudioFormat, class Azure.AI.VoiceLive.AudioNoiseReduction inputAudioNoiseReduction, class Azure.AI.VoiceLive.AudioEchoCancellation inputAudioEchoCancellation, class Azure.AI.VoiceLive.AvatarConfiguration avatar, class Azure.AI.VoiceLive.AudioInputTranscriptionOptions inputAudioTranscription, class System.Collections.Generic.IEnumerable`1&lt;valuetype Azure.AI.VoiceLive.AudioTimestampType&gt; outputAudioTimestampTypes, class System.Collections.Generic.IEnumerable`1&lt;class Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt; tools, class Azure.AI.VoiceLive.ToolChoiceOption toolChoice, valuetype System.Nullable`1&lt;float32&gt; temperature, class Azure.AI.VoiceLive.MaxResponseOutputTokensOption maxResponseOutputTokens, class System.BinaryData turnDetection, class Azure.AI.VoiceLive.RespondingAgentOptions agent, string id) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveSessionResponse(System.String,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.InteractionModality},Azure.AI.VoiceLive.AnimationOptions,Azure.AI.VoiceLive.VoiceProvider,System.String,System.Nullable{System.Int32},System.Nullable{Azure.AI.VoiceLive.InputAudioFormat},System.Nullable{Azure.AI.VoiceLive.OutputAudioFormat},Azure.AI.VoiceLive.AudioNoiseReduction,Azure.AI.VoiceLive.AudioEchoCancellation,Azure.AI.VoiceLive.AvatarConfiguration,Azure.AI.VoiceLive.AudioInputTranscriptionOptions,System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.AudioTimestampType},System.Collections.Generic.IEnumerable{Azure.AI.VoiceLive.VoiceLiveToolDefinition},Azure.AI.VoiceLive.ToolChoiceOption,System.Nullable{System.Single},Azure.AI.VoiceLive.MaxResponseOutputTokensOption,System.BinaryData,Azure.AI.VoiceLive.RespondingAgentOptions,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VoiceLiveSessionResponse (Optional model As String = Nothing, Optional modalities As IEnumerable(Of InteractionModality) = Nothing, Optional animation As AnimationOptions = Nothing, Optional voice As VoiceProvider = Nothing, Optional instructions As String = Nothing, Optional inputAudioSamplingRate As Nullable(Of Integer) = Nothing, Optional inputAudioFormat As Nullable(Of InputAudioFormat) = Nothing, Optional outputAudioFormat As Nullable(Of OutputAudioFormat) = Nothing, Optional inputAudioNoiseReduction As AudioNoiseReduction = Nothing, Optional inputAudioEchoCancellation As AudioEchoCancellation = Nothing, Optional avatar As AvatarConfiguration = Nothing, Optional inputAudioTranscription As AudioInputTranscriptionOptions = Nothing, Optional outputAudioTimestampTypes As IEnumerable(Of AudioTimestampType) = Nothing, Optional tools As IEnumerable(Of VoiceLiveToolDefinition) = Nothing, Optional toolChoice As ToolChoiceOption = Nothing, Optional temperature As Nullable(Of Single) = Nothing, Optional maxResponseOutputTokens As MaxResponseOutputTokensOption = Nothing, Optional turnDetection As BinaryData = Nothing, Optional agent As RespondingAgentOptions = Nothing, Optional id As String = Nothing) As VoiceLiveSessionResponse" />
      <MemberSignature Language="F#" Value="static member VoiceLiveSessionResponse : string * seq&lt;Azure.AI.VoiceLive.InteractionModality&gt; * Azure.AI.VoiceLive.AnimationOptions * Azure.AI.VoiceLive.VoiceProvider * string * Nullable&lt;int&gt; * Nullable&lt;Azure.AI.VoiceLive.InputAudioFormat&gt; * Nullable&lt;Azure.AI.VoiceLive.OutputAudioFormat&gt; * Azure.AI.VoiceLive.AudioNoiseReduction * Azure.AI.VoiceLive.AudioEchoCancellation * Azure.AI.VoiceLive.AvatarConfiguration * Azure.AI.VoiceLive.AudioInputTranscriptionOptions * seq&lt;Azure.AI.VoiceLive.AudioTimestampType&gt; * seq&lt;Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt; * Azure.AI.VoiceLive.ToolChoiceOption * Nullable&lt;single&gt; * Azure.AI.VoiceLive.MaxResponseOutputTokensOption * BinaryData * Azure.AI.VoiceLive.RespondingAgentOptions * string -&gt; Azure.AI.VoiceLive.VoiceLiveSessionResponse" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveSessionResponse (model, modalities, animation, voice, instructions, inputAudioSamplingRate, inputAudioFormat, outputAudioFormat, inputAudioNoiseReduction, inputAudioEchoCancellation, avatar, inputAudioTranscription, outputAudioTimestampTypes, tools, toolChoice, temperature, maxResponseOutputTokens, turnDetection, agent, id)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VoiceLiveSessionResponse</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="model" Type="System.String" />
        <Parameter Name="modalities" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.InteractionModality&gt;" />
        <Parameter Name="animation" Type="Azure.AI.VoiceLive.AnimationOptions" />
        <Parameter Name="voice" Type="Azure.AI.VoiceLive.VoiceProvider" />
        <Parameter Name="instructions" Type="System.String" />
        <Parameter Name="inputAudioSamplingRate" Type="System.Nullable&lt;System.Int32&gt;" />
        <Parameter Name="inputAudioFormat" Type="System.Nullable&lt;Azure.AI.VoiceLive.InputAudioFormat&gt;" />
        <Parameter Name="outputAudioFormat" Type="System.Nullable&lt;Azure.AI.VoiceLive.OutputAudioFormat&gt;" />
        <Parameter Name="inputAudioNoiseReduction" Type="Azure.AI.VoiceLive.AudioNoiseReduction" />
        <Parameter Name="inputAudioEchoCancellation" Type="Azure.AI.VoiceLive.AudioEchoCancellation" />
        <Parameter Name="avatar" Type="Azure.AI.VoiceLive.AvatarConfiguration" />
        <Parameter Name="inputAudioTranscription" Type="Azure.AI.VoiceLive.AudioInputTranscriptionOptions" />
        <Parameter Name="outputAudioTimestampTypes" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.AudioTimestampType&gt;" />
        <Parameter Name="tools" Type="System.Collections.Generic.IEnumerable&lt;Azure.AI.VoiceLive.VoiceLiveToolDefinition&gt;" />
        <Parameter Name="toolChoice" Type="Azure.AI.VoiceLive.ToolChoiceOption" />
        <Parameter Name="temperature" Type="System.Nullable&lt;System.Single&gt;" />
        <Parameter Name="maxResponseOutputTokens" Type="Azure.AI.VoiceLive.MaxResponseOutputTokensOption" />
        <Parameter Name="turnDetection" Type="System.BinaryData" />
        <Parameter Name="agent" Type="Azure.AI.VoiceLive.RespondingAgentOptions" />
        <Parameter Name="id" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="model"> The model for the session. </param>
        <param name="modalities"> The modalities to be used in the session. </param>
        <param name="animation"> The animation configuration for the session. </param>
        <param name="voice"> Gets or sets the Voice. </param>
        <param name="instructions"> Optional instructions to guide the model's behavior throughout the session. </param>
        <param name="inputAudioSamplingRate">
            Input audio sampling rate in Hz. Available values:
            - For pcm16: 8000, 16000, 24000
            - For g711_alaw/g711_ulaw: 8000
            </param>
        <param name="inputAudioFormat"> Input audio format. Default is 'pcm16'. </param>
        <param name="outputAudioFormat"> Output audio format. Default is 'pcm16'. </param>
        <param name="inputAudioNoiseReduction"> Configuration for input audio noise reduction. </param>
        <param name="inputAudioEchoCancellation"> Configuration for echo cancellation during server-side audio processing. </param>
        <param name="avatar"> Configuration for avatar streaming and behavior during the session. </param>
        <param name="inputAudioTranscription"> Configuration for input audio transcription. </param>
        <param name="outputAudioTimestampTypes"> Types of timestamps to include in audio response content. </param>
        <param name="tools"> Configuration for tools to be used during the session, if applicable. </param>
        <param name="toolChoice"> Gets or sets the tool choice strategy for response generation. </param>
        <param name="temperature"> Controls the randomness of the model's output. Range: 0.0 to 1.0. Default is 0.7. </param>
        <param name="maxResponseOutputTokens"> Gets or sets the maximum number of tokens to generate in the response. </param>
        <param name="turnDetection" />
        <param name="agent"> The agent configuration for the session, if applicable. </param>
        <param name="id"> The unique identifier for the session. </param>
        <summary> Base for session configuration in the response. </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VoiceLiveSessionResponse" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="VoiceLiveToolDefinition">
      <MemberSignature Language="C#" Value="public static Azure.AI.VoiceLive.VoiceLiveToolDefinition VoiceLiveToolDefinition (string type = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Azure.AI.VoiceLive.VoiceLiveToolDefinition VoiceLiveToolDefinition(string type) cil managed" />
      <MemberSignature Language="DocId" Value="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveToolDefinition(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function VoiceLiveToolDefinition (Optional type As String = Nothing) As VoiceLiveToolDefinition" />
      <MemberSignature Language="F#" Value="static member VoiceLiveToolDefinition : string -&gt; Azure.AI.VoiceLive.VoiceLiveToolDefinition" Usage="Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveToolDefinition type" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Azure.AI.VoiceLive</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Azure.AI.VoiceLive.VoiceLiveToolDefinition</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="type" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="type" />
        <summary>
            The base representation of a voicelive tool definition.
            Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="M:Azure.AI.VoiceLive.VoiceLiveModelFactory.VoiceLiveFunctionDefinition(System.String,System.String,System.BinaryData)" />.
            </summary>
        <returns> A new <see cref="T:Azure.AI.VoiceLive.VoiceLiveToolDefinition" /> instance for mocking. </returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>
